<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="动态规划 #  动态规划适合用来求解最优化问题。与分治法类似，通过递归地求解子问题来解决原问题。区别是，分治法可能会重复地多次解决同一个小问题，而动态规划选择将这些小问题的结果保存起来，避免重复多次地求解它们。
钢条切割问题 #  不同长度的钢条有不同的价格，求最优解。使用递归思想的算法是，长度为 $n$ 的钢条的最优解是：
CUT_ROD(prices, n) q = 0 for i = i to n q = max(q, prices[i] + CUT_ROD(prices, n - i)) return q 将函数的每次调用作为钢条的一次切割，则最优解为所有可能的切割方法中的最大值。显然，这种方法会大量地重复计算短钢条的最优价格。每当 n 增加 1，程序所用时间差不多增加一倍。
有两种方法实现动态规划。第一种是带备忘的自顶向下法（top-down with memoization）。额外维护一个数组，记录每个子问题的解即可。另一种是自底向上法。自顶向下通常可以避免一些不需要的子问题计算，但自底向上不需要递归开销，通常具有更小的系数。两种算法的复杂度均为 $O(n^2)$。自底向上的算法是这样的：
let r[0..n] be a new array r[0] = 0 for j = 1 to n q = -1 for i = 1 to j q = max(q, prices[i] + r[j - i]) r[k] = q return r[n] 除此之外，对于钢条最优解问题，还需要额外存储最优解的切割方案。"><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content="6. Dynamic Programming, Greedy, Amortize"><meta property="og:description" content="动态规划 #  动态规划适合用来求解最优化问题。与分治法类似，通过递归地求解子问题来解决原问题。区别是，分治法可能会重复地多次解决同一个小问题，而动态规划选择将这些小问题的结果保存起来，避免重复多次地求解它们。
钢条切割问题 #  不同长度的钢条有不同的价格，求最优解。使用递归思想的算法是，长度为 $n$ 的钢条的最优解是：
CUT_ROD(prices, n) q = 0 for i = i to n q = max(q, prices[i] + CUT_ROD(prices, n - i)) return q 将函数的每次调用作为钢条的一次切割，则最优解为所有可能的切割方法中的最大值。显然，这种方法会大量地重复计算短钢条的最优价格。每当 n 增加 1，程序所用时间差不多增加一倍。
有两种方法实现动态规划。第一种是带备忘的自顶向下法（top-down with memoization）。额外维护一个数组，记录每个子问题的解即可。另一种是自底向上法。自顶向下通常可以避免一些不需要的子问题计算，但自底向上不需要递归开销，通常具有更小的系数。两种算法的复杂度均为 $O(n^2)$。自底向上的算法是这样的：
let r[0..n] be a new array r[0] = 0 for j = 1 to n q = -1 for i = 1 to j q = max(q, prices[i] + r[j - i]) r[k] = q return r[n] 除此之外，对于钢条最优解问题，还需要额外存储最优解的切割方案。"><meta property="og:type" content="article"><meta property="og:url" content="/notes/intro-algo/6/"><meta property="article:section" content="notes"><title>6. Dynamic Programming, Greedy, Amortize | czdm75 Blog</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.97cfda4f5e3c9fa49a2bf8d401f4ddc0eec576c99cdcf6afbec19173200c37db.css><script defer src=/flexsearch.min.js></script>
<script defer src=/en.search.min.60f5c0362a1b15384bf6fbb748ad6fb49d79819ad4313fc4618ffb6d1f645f15.js></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>czdm75 Blog</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><input type=checkbox id=section-25b8c894ab868b34ecd6cce0ce4c79c7 class=toggle>
<label for=section-25b8c894ab868b34ecd6cce0ce4c79c7 class="flex justify-between"><a href=/cs/>Computer Science</a></label><ul><li><a href=/cs/linux-io-multiplex/>Linux IO Multiplexing</a></li></ul></li><li><input type=checkbox id=section-d5643d9c227c9fc0bfaa81dc6e0249af class=toggle>
<label for=section-d5643d9c227c9fc0bfaa81dc6e0249af class="flex justify-between"><a href=/distributed/>Distributed Systems</a></label><ul><li><a href=/distributed/hadoop-basic/>Hadoop Basic Concepts</a></li><li><a href=/distributed/spark-rdd/>Spark RDD Programming</a></li><li><a href=/distributed/spark-sql/>Spark SQL Programming</a></li></ul></li><li><a href=/notes/>Notes on Books</a><ul><li><input type=checkbox id=section-f9c54ee28ad742882651b9afb106f923 class=toggle>
<label for=section-f9c54ee28ad742882651b9afb106f923 class="flex justify-between"><a href=/notes/core-java-impatient/>Core Java for Impatients</a></label><ul><li><a href=/notes/core-java-impatient/1/>1. Basic OOP</a></li><li><a href=/notes/core-java-impatient/2/>2. Interface, Lambda</a></li><li><a href=/notes/core-java-impatient/3/>3. Inheritance, Reflection</a></li><li><a href=/notes/core-java-impatient/4/>4. Exception, Logging</a></li><li><a href=/notes/core-java-impatient/5/>5. Generics</a></li><li><a href=/notes/core-java-impatient/6/>6. Collections, Streams</a></li><li><a href=/notes/core-java-impatient/7/>7. IO, Regexp, Serialization</a></li><li><a href=/notes/core-java-impatient/8/>8. Threading</a></li><li><a href=/notes/core-java-impatient/9/>9. Notations</a></li></ul></li><li><input type=checkbox id=section-9d0fb26a4934bb77406a56b94138590b class=toggle>
<label for=section-9d0fb26a4934bb77406a56b94138590b class="flex justify-between"><a href=/notes/in-depth-jvm/>In-depth Understanding JVM</a></label><ul><li><a href=/notes/in-depth-jvm/gc/>Garbage Collection</a></li><li><a href=/notes/in-depth-jvm/synchronization/>Java Synchronization</a></li><li><a href=/notes/in-depth-jvm/memory-model/>JVM Memory Model</a></li><li><a href=/notes/in-depth-jvm/memory-region/>JVM Memory Regions</a></li><li><a href=/notes/in-depth-jvm/threadlocal-reference/>ThreadLocal and Reference</a></li></ul></li><li><input type=checkbox id=section-4d028229be962782539eef651433109e class=toggle checked>
<label for=section-4d028229be962782539eef651433109e class="flex justify-between"><a href=/notes/intro-algo/>Introduction to Algorithms</a></label><ul><li><a href=/notes/intro-algo/1/>1. Compexity, Divide</a></li><li><a href=/notes/intro-algo/2/>2. Sorting, Order Statistic</a></li><li><a href=/notes/intro-algo/3/>3. LinkedList, HashTable</a></li><li><a href=/notes/intro-algo/4/>4. BST, Balanced BSTs</a></li><li><a href=/notes/intro-algo/5/>5. Trie-Tree, Extending Data Structures</a></li><li><a href=/notes/intro-algo/6/ class=active>6. Dynamic Programming, Greedy, Amortize</a></li><li><a href=/notes/intro-algo/7/>7. B-Tree, Fibonacci Heap, vEB Tree</a></li><li><a href=/notes/intro-algo/8/>8. Graphs</a></li></ul></li><li><input type=checkbox id=section-76be9453a58f37863458b83352d3ff3c class=toggle>
<label for=section-76be9453a58f37863458b83352d3ff3c class="flex justify-between"><a href=/notes/programming-scala/>Programming in Scala</a></label><ul><li><a href=/notes/programming-scala/1/>1. Basics</a></li><li><a href=/notes/programming-scala/2/>2. Functions</a></li><li><a href=/notes/programming-scala/3/>3 .Inheritance, Package, Assertion</a></li><li><a href=/notes/programming-scala/4/>4. Pattern Matching, Collections</a></li><li><a href=/notes/programming-scala/5/>5. Generics, Abstract, Implicits</a></li><li><a href=/notes/programming-scala/6/>6. Collections, Extractor, etc</a></li></ul></li></ul></li><li><input type=checkbox id=section-9784d97422a8bbe41d06f74a08150515 class=toggle>
<label for=section-9784d97422a8bbe41d06f74a08150515 class="flex justify-between"><a href=/pl/>Programming Languages</a></label><ul><li><a href=/pl/java-nio-2/>Java NIO Internal</a></li><li><a href=/pl/java-nio-1/>Java NIO Usage</a></li><li><a href=/pl/lambda/>Lambda Calculus and Y Combinator</a></li><li><a href=/pl/curry/>Scala: Currying, Partially Applied, Partial</a></li><li><a href=/pl/monad/>Scala: Monad, from Scala Perspective</a></li></ul></li></ul><ul><li><a href=https://github.com/czdm75 target=_blank rel=noopener>GitHub</a></li><li><a href=https://themes.gohugo.io/hugo-book/ target=_blank rel=noopener>Theme</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label>
<strong>6. Dynamic Programming, Greedy, Amortize</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#动态规划>动态规划</a><ul><li><a href=#钢条切割问题>钢条切割问题</a></li><li><a href=#矩阵链乘法>矩阵链乘法</a></li><li><a href=#动态规划原理>动态规划原理</a></li><li><a href=#最长公共子序列问题>最长公共子序列问题</a></li><li><a href=#最优二叉树>最优二叉树</a></li></ul></li><li><a href=#贪心算法>贪心算法</a><ul><li><a href=#活动选择问题>活动选择问题</a></li><li><a href=#背包问题>背包问题</a></li></ul></li><li><a href=#摊还分析>摊还分析</a><ul><li><a href=#聚合分析>聚合分析</a></li><li><a href=#核算法>核算法</a></li><li><a href=#势能法>势能法</a></li><li><a href=#表的扩张和收缩>表的扩张和收缩</a></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=动态规划>动态规划
<a class=anchor href=#%e5%8a%a8%e6%80%81%e8%a7%84%e5%88%92>#</a></h1><p>动态规划适合用来求解最优化问题。与分治法类似，通过递归地求解子问题来解决原问题。区别是，分治法可能会重复地多次解决同一个小问题，而动态规划选择将这些小问题的结果保存起来，避免重复多次地求解它们。</p><h2 id=钢条切割问题>钢条切割问题
<a class=anchor href=#%e9%92%a2%e6%9d%a1%e5%88%87%e5%89%b2%e9%97%ae%e9%a2%98>#</a></h2><p>不同长度的钢条有不同的价格，求最优解。使用递归思想的算法是，长度为 $n$ 的钢条的最优解是：</p><pre tabindex=0><code class=language-pseudocode data-lang=pseudocode>CUT_ROD(prices, n)
q = 0
for i = i to n
    q = max(q, prices[i] + CUT_ROD(prices, n - i))
return q
</code></pre><p>将函数的每次调用作为钢条的一次切割，则最优解为所有可能的切割方法中的最大值。显然，这种方法会大量地重复计算短钢条的最优价格。每当 n 增加 1，程序所用时间差不多增加一倍。</p><p>有两种方法实现动态规划。第一种是带备忘的自顶向下法（top-down with memoization）。额外维护一个数组，记录每个子问题的解即可。另一种是自底向上法。自顶向下通常可以避免一些不需要的子问题计算，但自底向上不需要递归开销，通常具有更小的系数。两种算法的复杂度均为 $O(n^2)$。自底向上的算法是这样的：</p><pre tabindex=0><code class=language-pseudocode data-lang=pseudocode>let r[0..n] be a new array
r[0] = 0
for j = 1 to n
    q = -1
    for i = 1 to j
        q = max(q, prices[i] + r[j - i])
    r[k] = q
return r[n]
</code></pre><p>除此之外，对于钢条最优解问题，还需要额外存储最优解的切割方案。</p><h2 id=矩阵链乘法>矩阵链乘法
<a class=anchor href=#%e7%9f%a9%e9%98%b5%e9%93%be%e4%b9%98%e6%b3%95>#</a></h2><p>由于多个矩阵相乘满足结合律，且矩阵相乘的代价和矩阵的阶相关，改变加括号的方式可能大大改变矩阵乘法的复杂度。尽量降低每一次乘法的阶数可以大大改善性能。因此，我们将矩阵链乘法问题描述为：求完全括号化方案，使得计算所需的标量乘法次数最少。暴力搜索的复杂度为 $\Omega(2^n)$。</p><p>与钢条问题类似，把每一次括号化作为一次递归调用。设从 $i$ 到 $j$ 的矩阵链的最优解为 $m[i,j]$，则：</p><p>$$
m[i,j] =
\begin{cases}
0 & \text{if } i=j \cr
\min_{i \leqslant k &lt; j} \{m[i,k]+m[k+1,j]+p_{i-1}p_kp_j\} & \text{if } i &lt; j
\end{cases}
$$</p><p>于是，对于 $m[i,j]$，我们需要所有长度小于这个序列的矩阵链的最优解。对于自底向上算法，可以使用三层嵌套循环，分别代表矩阵链长度、位置和递归式中对括号化方式的的遍历操作。可以证明，递归的运行时间是 $\Theta(n^3)$，并需要 $\Theta(n^2)$ 的额外空间，比暴力穷举高效得多。</p><h2 id=动态规划原理>动态规划原理
<a class=anchor href=#%e5%8a%a8%e6%80%81%e8%a7%84%e5%88%92%e5%8e%9f%e7%90%86>#</a></h2><p>一个问题的最优解包含其子问题的最优解。比如，一个长钢条的最佳切割方案是两段钢条的最优切割方案构成的。这种性质称为最优子结构。具有这种性质的问题通常也适用于贪心算法。</p><p>求无权最短路径的问题是最优子结构的。这条路径必然是无环的。将路径分解成两半，那么两条路径一定分别是最优解。然而，最长简单路径问题并不符合最优子结构性质。这是因为，在最长简单路径问题中，由于简单路径不能存在环，这两个子问题实际上是相关的，而最短路径问题是无关的。实际上，最长简单路径的问题是 NP 完全的，不太可能在多项式时间内求解。</p><p>除此之外，显然，适合动态规划解决的问题还应该满足重叠子问题的性质。这个性质的核心是，子问题的数量应该是有限的。只有在递归过程中重复地求解同一个问题，才能体现出动态规划的优势。</p><p>另外，算法设计中还需要考虑重构最优解的问题。</p><h2 id=最长公共子序列问题>最长公共子序列问题
<a class=anchor href=#%e6%9c%80%e9%95%bf%e5%85%ac%e5%85%b1%e5%ad%90%e5%ba%8f%e5%88%97%e9%97%ae%e9%a2%98>#</a></h2><p>注意，这个问题与最长公共子串不同：在这里，子序列可以不是连续的。这个属性更多地刻画了两个序列的相似性。</p><p>这个问题的最优子结构是这样的：设 $X_m = \langle x_1, x_2, \cdots, x_m \rangle$ 和 $Y_n = \langle y_1, y_2, \cdots, y_n \rangle$ 是两个序列，其最长公共子序列为 $Z_k = \langle z_1, z_2, \cdots, z_k \rangle$</p><ol><li>若 $x_m=y_n$，则 $z_k~x_m~y_n$，$Z_k-1$ 是 $X_{m-1}$ 和 $Y_{n-1}$ 的最长公共子序列。</li><li>若 $x_m\neq y_n$，$z_k\neq x_m$ 意味着 $Z$ 是 $X_{m-1}$ 和 $Y$ 的最长公共子序列。</li><li>若 $x_m\neq y_n$，$z_k\neq y_n$ 意味着 $Z$ 是 $X$ 和 $Y_{n-1}$ 的最长公共子序列。</li></ol><p>于是，我们定义 $c[i,j]$ 为 $X_i$ 和 $Y_j$ 的最大公共子序列的长度，得到递归式：</p><p>$$
c[i,j] =
\begin{cases}
0 & \text{if $i=0$ or $j=0$} \cr
c[i-1,j-1] + 1 & \text{if $i,j>0$ and $x_i=y_i$} \cr
\max(c[i,j-1], c[i-1,j]) & \text{if $i,j>0$ and $x_i\neq y_j$}
\end{cases}
$$</p><p>如果递归求解这个问题，复杂度同样为指数。</p><p>使用动态规划，除了代价矩阵 $c$ 之外，还可以另外维护一个最优解矩阵 $b$。$b$ 中的元素指向算法在这一步选择的最优解。</p><p>也可以不使用 $b$。由于我们已经有了各个子问题的代价值和递归式，也可以根据这个位置的代价值反推选择最优解的路径。甚至，由于这个过程并不需要 $c$ 中所有的代价值，可以进一步缩减这个操作的复杂度。</p><h2 id=最优二叉树>最优二叉树
<a class=anchor href=#%e6%9c%80%e4%bc%98%e4%ba%8c%e5%8f%89%e6%a0%91>#</a></h2><p>对于已知概率的结点的查找，构建一颗二叉搜索树，使得总的访问结点树最小。这实际上就是 Huffman 树解决的问题。Huffman 编码过程属于贪心算法，如上所述，贪心算法和动态规划可以使用的范畴基本重合，动态规划也可以用于这个问题。具体实现省略。</p><h1 id=贪心算法>贪心算法
<a class=anchor href=#%e8%b4%aa%e5%bf%83%e7%ae%97%e6%b3%95>#</a></h1><p>贪心算法的基础是，不断选择当前看起来最优的解，并希望所有这些局部最优解综合起来成为全局最优解。这个性质并不一定总能保证。后面我们将讨论贪心算法的适用问题。</p><h2 id=活动选择问题>活动选择问题
<a class=anchor href=#%e6%b4%bb%e5%8a%a8%e9%80%89%e6%8b%a9%e9%97%ae%e9%a2%98>#</a></h2><p>有一批活动需要使用同一个资源，比如一个阶梯教室。每个活动有一定的时间区间。问题的目的是找到一个活动子集，使得所有活动兼容且集合最大。</p><p>首先从递归动态规划方向来考虑问题。有 $n$ 个活动的集合 $\{a_1, a_2, \cdots, aa_n\}$，并已经按照结束时间排序好。设 $c[i,j]$ 是最优解的大小，$S_{ij}$ 是所有在 $a_i$ 活动结束后开始，在 $a_j$ 活动开始前结束的活动的集合，即所有这两个活动之间的活动的集合，则：</p><p>$$
c[i,j] =
\begin{cases}
0 & \text{if } S_{ij} = \emptyset \cr
\max_{a_k\in S_{ij}} \{c[i,k]+c[k,j]+1\} & \text{if } S_{ij} \neq \emptyset
\end{cases}
$$</p><p>这时我们就可以设计动态规划算法。不过，在选择最优解的过程中，直觉告诉我们，选择最先结束的活动，即 $a_1$ 可能就是最好的选择。这样，就只剩下一个子问题需要解决，而不需要遍历各种子问题。这个选择可以被证明是最优的。于是，我们可以使用递归算法来解决这个问题，也很容易将其转化为迭代形式，变成不断加入最早结束的兼容活动的算法。</p><h2 id=背包问题>背包问题
<a class=anchor href=#%e8%83%8c%e5%8c%85%e9%97%ae%e9%a2%98>#</a></h2><p>0-1 背包问题这样定义：每种商品有不同的重量和价格，希望得到在限定重量下商品的最大价值。另一种变体是分数背包问题。在这里，物品不再是整数，而是可以任意分割携带。两个问题都具有最优子结构性质，但分数背包问题可以用贪心策略来完成，0-1 背包问题只能用普通的动态规划来完成。</p><p>分数背包问题的答案比较明显，根据贪心策略，只需要尽量往背包里装满平均价值最高的商品就可以了。但在 0-1 背包问题中，由于背包可能无法装满，相当于影响了商品的单位价值。因此，这个问题不适用于贪心策略。</p><h1 id=摊还分析>摊还分析
<a class=anchor href=#%e6%91%8a%e8%bf%98%e5%88%86%e6%9e%90>#</a></h1><p>在摊还分析中，我们求一个操作序列中所有操作的平均时间，来评价操作的代价。摊还分析并不涉及概率。我们将介绍三种摊还分析的方法：</p><ul><li>聚合分析，确定一个 $n$ 个操作的序列的总代价的上界 $T(n)$，则每个操作的摊还代价为 $T(n)/n$。</li><li>核算法，用来分别分析每个操作各自的摊还代价。核算法将序列中较早的操作的 “余额” 与数据结构中的特定对象相关联，在序列中随后的部分，用来为那些缴费少于书记代价的操作支付差额。</li><li>势能法，同样用于分析各个操作的摊还代价。与核算法的区别是，将 “势能” 作为一个整体储存起来，而不与单个对象关联分开储存。</li></ul><h2 id=聚合分析>聚合分析
<a class=anchor href=#%e8%81%9a%e5%90%88%e5%88%86%e6%9e%90>#</a></h2><p>以一个栈为例。我们为栈新定义一种操作 <code>MUILTIPOP</code>，弹出指定数量的元素。如果超过栈内存储的元素的量，就停止弹出而不报错。于是，对于一个长度为 $n$ 的操作序列，原来的入栈和出栈操作的代价均为 $O(1)$，而新的多重出栈的最坏情况代价为 $O(n)$。对于整个序列，最坏情况看起来应当为 $O(n^2)$，即所有操作都是参数为 $n$ 的多重出栈操作，然而，这并不是一个确界。</p><p>下面我们利用聚合分析。虽然多重出栈的代价可能很高，但是对于一个初始为空的栈，可以执行的出栈次数最多与入栈次数相同，无论是不是多重出栈。因此，整个操作序列的最坏运行时间事实上是 $O(n)$，所以三种栈操作的摊还代价都是 $O(1)$。</p><p>类似地，考虑一个二进制计数器。每次计数器加一时需要反转的位数是不同的。01 变成 10 需要改变 2 位，011 变成 100 需要反转 3 位。以自增操作的数量为 $n$，需要反转次数似乎正在随着计数器内值的大小而增长。然而实际上需要反转大量的位的情况是少见的，而且越是高位，需要反转的情况就越少见。对一个从 0 开始的计数器，需要进行的反转次数的总数为：</p><p>$$
\sum_{i=0}^{k-1} \lfloor \frac n {2^i} \rfloor
&lt; n \sum_{i=0}^\infty \frac 1 {2^i}
= 2n
$$</p><p>因此，最坏情况时间为 $O(n)$，摊还代价为 $O(1)$。</p><p>如果加入多重入栈操作，就可以压入任意多的数字。或者对计数器加入自减操作，使计数器内的值有可能在需要大量改变位数的位置颠簸，如 7-8 之间，显然，复杂度又会升高到原来的水平。</p><h2 id=核算法>核算法
<a class=anchor href=#%e6%a0%b8%e7%ae%97%e6%b3%95>#</a></h2><p>对不同操作赋予不同的费用，称为他们的摊还代价。当摊还代价超过实际代价时，将差额存入数据结构中的特定对象，称为信用。对于后续摊还代价小于实际代价的情况，可以用信用来支付差额。</p><p>回顾前面的栈问题。可以认为，<code>PUSH</code> 操作的实际代价为 1，<code>POP</code> 的代价为 1，<code>MULTIPOP</code> 的代价是 $\min(k,s)$，$k$ 是参数，$s$ 是栈内元素的数量。然后，我们为这些操作分别赋予摊还代价，<code>PUSH</code> 为 2，<code>POP</code> 和 <code>MULTIPOP</code> 为 0。显然，<code>PUSH</code> 为后来的两种 <code>POP</code> 操作预存了代价费用。于是，长度为 $n$ 的操作序列的总代价为 $O(n)$。</p><h2 id=势能法>势能法
<a class=anchor href=#%e5%8a%bf%e8%83%bd%e6%b3%95>#</a></h2><p>令 $c_i$ 为第 $i$ 个操作的实际代价，$D_i$ 为执行第 $i$ 个操作后得到的结果数据结构，则第 $i$ 个操作的摊还代价 $\hat{c_i}$ 用势函数 $\Phi$ 定义为：</p><p>$$
\hat{c_i} = c_i + \Phi(D_i) - \Phi(D_{i-1})
$$</p><p>例如，对于之前的栈操作，以栈内元素的数量为势函数。于是，PUSH 操作的摊还代价为 2，另外两种为 0，结论与上一种方法相同。</p><p>又如，对于之前的二进制计数器，将计数器内 1 的个数作为势能。同样可以得出，$n$ 个操作的最坏时间情况为 $O(n)$。</p><h2 id=表的扩张和收缩>表的扩张和收缩
<a class=anchor href=#%e8%a1%a8%e7%9a%84%e6%89%a9%e5%bc%a0%e5%92%8c%e6%94%b6%e7%bc%a9>#</a></h2><p>摊还分析适合于这一类操作：一个长度可以动态变化的线性表，如 Java 中的 <code>ArrayList</code>。当数组空间不足以存储所有的元素时，需要重新分配一个数组，并将目前所有的元素移动到新的数组里。虽然每一次操作的代价是不同的，将势函数定义为：</p><p>$$
\Phi(T) = 2T.num-T.size
$$</p><p>这样定义的目的是，让每一次扩张之后，数据结构的势能为 0。如果每个元素插入、删除和移动的代价都是 1，那么插入操作的摊还代价为 3。也就是说，整个长度为 $n$ 的操作序列的代价为 $O(n)$。</p><p>涉及到收缩的情况比较复杂。如果我们让表的容量达到 1/2 时立刻收缩，那么在特定值附近的颠簸将会使表不停地扩张和收缩，带来大量的复制和内存分配，将每个操作的代价拉回到 $O(n)$。所以，我们规定容量达到 1/4 时才发生收缩，使表的装载因子变回 1/2。这时，就需要这样定义势能：</p><p>$$
\Phi(T) =
\begin{cases}
2T.num-T.size & \text{if } \alpha \geqslant \frac 1 2 \cr
T.size/2 - T.num & \text{if } \alpha &lt; \frac 1 2
\end{cases}
$$</p><p>这样，就相当于分别定义了收缩情况的势能和扩张情况的势能。摊还代价收缩回 3，整个操作序列的代价回到 $O(n)$。</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(n){const e=window.getSelection(),t=document.createRange();t.selectNodeContents(n),e.removeAllRanges(),e.addRange(t)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#动态规划>动态规划</a><ul><li><a href=#钢条切割问题>钢条切割问题</a></li><li><a href=#矩阵链乘法>矩阵链乘法</a></li><li><a href=#动态规划原理>动态规划原理</a></li><li><a href=#最长公共子序列问题>最长公共子序列问题</a></li><li><a href=#最优二叉树>最优二叉树</a></li></ul></li><li><a href=#贪心算法>贪心算法</a><ul><li><a href=#活动选择问题>活动选择问题</a></li><li><a href=#背包问题>背包问题</a></li></ul></li><li><a href=#摊还分析>摊还分析</a><ul><li><a href=#聚合分析>聚合分析</a></li><li><a href=#核算法>核算法</a></li><li><a href=#势能法>势能法</a></li><li><a href=#表的扩张和收缩>表的扩张和收缩</a></li></ul></li></ul></nav></div></aside></main><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css><script src=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js></script>
<script>renderMathInElement(document.querySelector("article.markdown"),{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})</script></body></html>