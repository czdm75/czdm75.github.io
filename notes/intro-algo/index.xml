<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Introduction to Algorithms on czdm75 Blog</title><link>/notes/intro-algo/</link><description>Recent content in Introduction to Algorithms on czdm75 Blog</description><generator>Hugo -- gohugo.io</generator><atom:link href="/notes/intro-algo/index.xml" rel="self" type="application/rss+xml"/><item><title>1. Compexity, Divide</title><link>/notes/intro-algo/1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/notes/intro-algo/1/</guid><description>代价分析和复杂度 # 示例与概念 # 例子：插入排序 例子：归并排序 最坏情况分析 vs 平均情况分析 函数增长的渐进记号 # $O(n)$, $\Theta(n)$, $\Omega(n)$ 表示函数增长的上界、上下界、下界 $o(n)$, $\omega(n)$ 表示不紧确的上下界 常用 $T(n)$ 表示所需的实际时间的函数 分析分治算法，以归并排序为例 # 归并排序最坏运行时间的递归式：
$$ T(n)= \begin{cases} \Theta(1) &amp;amp; \text{if } n=1 \cr 2T(n/2) + \Theta(n) &amp;amp; \text{if } n&amp;gt;1 \end{cases} $$
除使用主定理外，还可以这样理解递归式的值：将递归过程看做一个二叉树。递归调用中的每一层的总代价均为 $cn$，其中 $c$ 为常数。而二叉树的层数应为 $\log_2n+1$，故整个算法的代价期望为 $\Theta(n\log_2n)$。
分治法 # 分治法求最大和的子数组 # 分解。将数组划分为两个子数组。此时，只存在三种子数组：
全部位于中点左侧的子数组 全部位于中点右侧的子数组 跨越中点的子数组 解决。</description></item><item><title>2. Sorting, Order Statistic</title><link>/notes/intro-algo/2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/notes/intro-algo/2/</guid><description>排序算法 # 原地排序 (in place) ：仅需要常数的额外存储空间
堆排序：$O(n\log_2n)$ 的原地排序算法
快速排序：期望为 $\Theta(n\log_2n)$，最坏情况为 $\Theta(n^2)$，实际应用中通常比堆排序快。同时，其常数系数很小，是排序大数组时的常用算法。
比较排序：通过对元素进行比较来决定，快排、归并、堆排序都是比较排序。比较排序的代价下界为 $\Omega(n\log_2n)$。
线性时间排序：计数排序、基数排序、桶排序，在一定条件下，可以取得线性时间代价。
算法 最坏情况代价 代价期望 插入排序 $\Theta(n^2)$ $\Theta(n^2)$ 归并排序 $\Theta(n\log_2n)$ $\Theta(n\log_2n)$ 堆排序 $O(n\log_2n)$ 快速排序 $\Theta(n^2)$ $\Theta(n\log_2n)$ 计数排序 $\Theta(k+n)$ $\Theta(k+n)$ 基数排序 $\Theta(d(k+n))$ $\Theta(d(k+n))$ 桶排序 $\Theta(n^2)$ $\Theta(n)$ 堆排序 # 复杂度为 $O(n\log_2n)$，常数个额外空间（原地排序）。</description></item><item><title>3. LinkedList, HashTable</title><link>/notes/intro-algo/3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/notes/intro-algo/3/</guid><description>链表 # 链表的哨兵结点 # 链表的哨兵结点表示 nil 值，其 prev 属性指向表尾，next 属性指向表头。这样，就可以省略掉 head 属性，并简化边界条件的处理。如果我们使用的是很多个很短的链表，哨兵结点就会造成比较严重的存储浪费。
不使用指针的链表 # 多数组的实现：对于双向链表，至少使用 3 个数组，分别为 prev、key、next，其值即为所指向对象的数组下标。每个数组相同下标的值合起来是一个完整的结点对象。
单数组的实现：以一整个数组连续存储对象，使用下标代表指针。当需要访问对象的成员时，在指针上加一个偏移量。相对于多数组的实现，这种方式就可以支持不同长度的对象构成的链表。
自由表：未被使用的，可能是之前被释放的内存单元组成的链表。。数组表示中的每一个对象不是在链表中，就一定在自由表中。实现上，自由表常常是一个链表栈。刚刚被释放的空间，在下一次插入中就会被用来存储新的对象。显然，多个链表也可以共用同一个自由表。使用自由表的释放操作和插入操作运行代价仍然是 $O(1)$，因此非常实用。
有根树的表示 # 对于分叉数量未知的树，我们难以使用数组来储存孩子结点的指针。或者，如果最大孩子数很大，那么使用相同数量的指针空间将会浪费大量的存储空间。因此，在这里引入左孩子右兄弟表示法。
在这样表示的树中，每一个结点有三个指针：父结点，左孩子指针和一个兄弟指针，兄弟指针指向它右侧的具有同一个父结点的结点。同一个父结点的所有孩子结点实际上相当于构成一个链表。如果是最右子结点，就把兄弟指针设置为 nil。
散列函数 # 散列函数所需要的最基本性质是，尽量让 key 进入各个槽的概率平均。除此之外，还可能需要一些其他的性质。比如，可能希望相接近的关键字的散列值差距较大，在开放寻址法进行线性探查时需要这种性质，而这种性质由全域散列提供。此外，还可能需要把其他种类的关键字，或负数、浮点数等转换成自然数等。
除法散列 # 最简单的除法散列适用于平均分布的自然数序列。被除数选择不接近 2 的整数幂的较大的质数有利于散列。如对于一个预备存储 2000 个元素的散列表，可取 $h(k) = k \mod 701$。
乘法散列 # 用关键字乘一个常数，通常为一个无理数，取小数部分，再乘上一个值，取整变回自然数。如：
$$ h(k) = \lfloor m(kA \mod 1) \rfloor $$</description></item><item><title>4. BST, Balanced BSTs</title><link>/notes/intro-algo/4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/notes/intro-algo/4/</guid><description>二叉搜索树 # 对一个二叉搜索树，任何一个结点的左子结点不大于它本身，右子结点不小于它本身。这样，就可以简单地使用中序遍历查找元素。中序遍历打印出来的序列，就是已经排序完成的序列。中序遍历的时间代价为 $\Theta(n)$。
二叉搜索树的基本操作 # 在高 $h$ 的树上，以下操作的时间代价均为 $O(h)$。
查找：比较和当前结点的大小，选择子树。 最大和最小：不断取左子结点或右子结点。 深度优先遍历的方式：
前序遍历 中序遍历 后序遍历 后继前驱 # 如果关键字不重复，那么一个结点的中序遍历后继为大于这个结点的最小者，即升序序列中的下一个。如果结点的右子树非空，那么右树中的最左结点即为后继结点，不断向左寻找即可。
如果右子树为空，说明这个结点是某个左子树的最右结点，而这个左子树的父结点即为后继结点。这意味着，遍历这个结点之后，这个左子树遍历完成，进入某个遍历过程的根结点部分。于是，不断向上寻找，如果当前结点不再是右结点，说明已经找到了这个根结点。如果找到了 $nil$，则说明没有后继，这个结点是整个树的最右结点。
前驱和后继的过程对称，时间代价均为 $O(h)$。
插入和删除 # 插入过程比较简单。寻找结点的关键字应该在的位置，并修改父结点的指针即可。
删除结点可分为三种情况：
没有子结点，直接删除并修改父结点的指针即可。 只有一个孩子，则用这个孩子来替代这个结点。 两个孩子，则使用后继结点来替代这个结点。由于被删除的这个后继结点是右子树的最左结点，其一定没有左子节点。因此，使用其右子节点代替它的位置，并用这个节点代替待删除的结点。于是，删除完成。 显然，这两种操作的时间代价也是 $O(h)$。
随机构建二叉搜索树 # 二叉搜索树的构建由插入和删除操作完成。显然，实际情况中，这是一个随机过程。在最坏情况下，当元素严格升序或降序插入，二叉搜索树将成为一个链表。十分显而易见的是，在完全随机的情况下，元素均匀插入，二叉树接近完全，其高度的期望为 $O(\log_2n)$。
红黑树 # 性质 # 一个基于二叉搜索树增加一个颜色属性的树，保证没有任何路径会比另一条路径长出二倍的近似平衡树。
每个结点是红色或黑色的 根结点是黑色的 每个叶子结点都是黑色的 如果一个结点是红色的，则其两个子结点都是黑色的 对每个结点，从该结点到其所有后代叶结点的简单路径上，均包含相同树木的黑色结点。 性质 5 是红黑树的核心：红黑树是一颗近似平衡二叉树。
为了避免叶子结点的空间浪费，可以指定一个哨兵结点为 NIL，并使所有叶子都指向这一个结点。通常忽略叶子结点，因为其并不储存 key 值。
定义任何一个结点的黑高为从该结点到其后代叶子结点的路径上黑色结点的数目。根据性质 5，任何一条简单路径的黑高都相同。一颗有 $n$ 个内部结点的红黑树的高度至多为 $2\log_2(n+1)$。</description></item><item><title>5. Trie-Tree, Extending Data Structures</title><link>/notes/intro-algo/5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/notes/intro-algo/5/</guid><description>Trie 树（前缀树） # 前缀树的结构是这样的：每个结点的一个分支代表一位数据。这里的一位不一定是一个 bit，也可以是一个字符等，因为前缀树经常被用在字符串处理，如输入时的提示。在这里，节点内部并不需要保存 key，因为其所有位都已经表示在了路径上。
如果每一个分支不只保存一个位，将唯一子树与其父节点合并，就变成了基数树。基数树需要保存的路径信息变多了，但不再使用无用的结点。
Huffman 编码 # Huffman 编码就是一种使用前缀的编码方法，其核心是前缀树的构建。Huffman 编码采用这样的基于概率的前缀构建：将所有可能的值作为叶子，并不断合并频率和最小的两个节点，最终构成一颗二叉前缀树。
树构建完成之后，在每一个节点，以左侧为 0，右侧为 1，构建前缀编码。Huffman 编码是最优的前缀编码。类似地，自顶向下构建前缀树，在每一步尽量使两侧概率相等的编码方式称为 Shannon-Fano 编码，这种方法不一定总能得到最优编码。
数据结构的扩展 # 在这里，数据结构的扩展指的是在原有数据结构上做出一些修改，使得其能够支持更多的特性。这些修改包括设计新的操作，以及增加可能的域。
动态顺序统计 # 为了获得一个集合里每个元素的次序，在红黑树结点的基础上增加一个域 size，用于保存以这个节点为根的子树的总结点数。即顺序统计量。定义中序遍历的顺序为这个元素的秩。
给定秩，寻找相应的元素。从根出发，左子树的 size+1 就是这个节点所在的位置。判断和输入的大小关系，选择子树继续寻找。
给定元素寻找秩的过程与之相反。从这个节点回溯到根，将所有的左子树 size+1 加起来，就是这个结点的秩。两种查找的复杂度均为 $O(\log_2n)$。
为了维护 size 域的值，在每一次插入和删除时，都需要回溯至根来修改，复杂度为 $O(\log_2n)$。此外，当发生旋转时，也要分别修改 size。修改的复杂度为 $O(1)$，所以插入和删除的复杂度不变，仍为 $O(\log_2n)$。
区间树 # 接下来，我们以红黑树为基础，构建一个可以保存区间对象的数据结构，以展示如何进行数据结构的扩展。
基础数据结构：每个节点包含一个区间信息，并以区间的低端点作为其关键字。
附加信息：每个节点额外维护一个值 max，它是以这个节点为根的子树中的所有区间端点的最大值。
对信息的维护：每个结点的 max 为 max(x.int.high, x.left.max, x.right.max)。于是，更新这个属性的复杂度为 $O(\log_2n)$。实际上，操作的复杂度只有 $O(1)$。
设计新的操作：查找与指定区间相交的区间。在查找时，如果左子结点的 max 大于查找目标的左端点，说明左子树中有重叠的部分，则进入左子树继续查找。</description></item><item><title>6. Dynamic Programming, Greedy, Amortize</title><link>/notes/intro-algo/6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/notes/intro-algo/6/</guid><description>动态规划 # 动态规划适合用来求解最优化问题。与分治法类似，通过递归地求解子问题来解决原问题。区别是，分治法可能会重复地多次解决同一个小问题，而动态规划选择将这些小问题的结果保存起来，避免重复多次地求解它们。
钢条切割问题 # 不同长度的钢条有不同的价格，求最优解。使用递归思想的算法是，长度为 $n$ 的钢条的最优解是：
CUT_ROD(prices, n) q = 0 for i = i to n q = max(q, prices[i] + CUT_ROD(prices, n - i)) return q 将函数的每次调用作为钢条的一次切割，则最优解为所有可能的切割方法中的最大值。显然，这种方法会大量地重复计算短钢条的最优价格。每当 n 增加 1，程序所用时间差不多增加一倍。
有两种方法实现动态规划。第一种是带备忘的自顶向下法（top-down with memoization）。额外维护一个数组，记录每个子问题的解即可。另一种是自底向上法。自顶向下通常可以避免一些不需要的子问题计算，但自底向上不需要递归开销，通常具有更小的系数。两种算法的复杂度均为 $O(n^2)$。自底向上的算法是这样的：
let r[0..n] be a new array r[0] = 0 for j = 1 to n q = -1 for i = 1 to j q = max(q, prices[i] + r[j - i]) r[k] = q return r[n] 除此之外，对于钢条最优解问题，还需要额外存储最优解的切割方案。</description></item><item><title>7. B-Tree, Fibonacci Heap, vEB Tree</title><link>/notes/intro-algo/7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/notes/intro-algo/7/</guid><description>B 树 # B 树的基本思想是这样的：设想一个树，每个节点都被储存在磁盘里，我们每次取出一个结点，这是很自然的。在进入下一层时，需要访问一个新的结点，这常常意味着新的磁盘访问。相应地，在节点内部进行的比较操作，也就是寻找前进方向的操作，只需要在主存里进行。
显然，主存中的操作的时间代价要低得多。所以，我们让每个节点持有众多的关键字和众多的结点，从而尽量降低树的高度。这意味着，相比于二叉树，使用 B 树将会带来更多的比较操作和更少的磁盘访问。因此，这种数据结构适合大块的数据访问。典型的例子如 BtrFS。
和其他各种树一样，B 树上操作的时间复杂度同样为 $O(\log_tn)$，只是这里的 $t$ 比二叉树中的 2 通常要大得多。
B 树的操作 # B 树的基本操作在之前的 2-3 树已经介绍过。在插入关键字时，如果结点的大小超过了限制，就 “挤出” 一个最中间的关键字给父节点，并分裂当前结点。由于被挤出的是中间关键字，分类得到的两个新节点的长度应该相近。随后我们需要递归地对父节点进行判断，直到根节点分裂，这是 B 树高度增长的唯一方式。
在回顾了分裂结点的操作后，我们就可以理解 B 树定义中 $t$ 的意义：每个节点内关键字的数量在 $t$ 和 $2t$ 之间，这分别是刚刚分裂过的结点和即将要分裂的结点。
这里有一个不错的 B 树操作的可视化演示。
B+ 树 # B+ 树是 B 树的一个变种，其所有的关键字都储存在叶子节点当中。由于 B 树中所有的结点高度相同，其查找的时间复杂度非常稳定。B+ 树可以接受重复关键字，将实际数据存储在叶子节点中，内部结点只用来指示存储位置即可。
斐波那契堆 # 可合并堆 # 一个可合并堆应当支持以下的操作：
创建空堆 插入关键字 取得最小值 删除最小值 合并两个堆 除此之外，斐波那契堆还可以支持减小已有元素的关键字和删除关键字的操作。
之前出现过的二叉堆在前四个操作上效果都不错，时间代价为 $O(\log_2n)$。然而，在合并堆的操作上，二叉堆的速度非常慢。可以这样实现：将两个堆直接合并起来，再执行建堆操作。这样，复杂度会达到 $\Theta(n)$。斐波那契堆通常相比二叉堆具有更好的摊还代价。</description></item><item><title>8. Graphs</title><link>/notes/intro-algo/8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/notes/intro-algo/8/</guid><description>图的表示与基本算法 # $G(V,E)$ 其中 $G$ 为 Graph 图，$V$ 为 Verticle 结点，$E$ 为 Edge 边。 邻接链表 邻接矩阵 BFS 广度优先遍历（队列） # 在 BFS 中，把未发现的结点和边标记为白色，发现但未完成的为灰色，已完成的为黑色。在 BFS 中，不需要对灰色和黑色进行区分。这个颜色用法也适用于 DFS 的结点。边只分为黑白两种。
BFS 可以发现两个结点间的最短路径。
DFS 深度优先遍历（栈） # 让 DFS 中一个节点的发现时间和完成时间分别为 $u.d$ 和 $u.f$。那么，对于任意两个节点，它们的 $[d,f]$ 时间区间要么完全分离，要么互相包含。被包含的在 DFS 树中是另一个节点的后代。
结点 $v$ 是 $u$ 的后代，当且仅当发现 $u$ 时，存在一条白色（完全未发现的）路径连接二者。
在 DFS 中将边分类。DFS 树中的称为树边，从一个节点连接到其祖先的为后向边，连接到其子孙的为前向边，其余的为横向边。于是，当且仅当图中无后向边，有向图无环。
当第一次查看边 $(u,v)$ 时，若 $v$ 为白色，说明这是一条树边。若为灰色，说明是一条后向边（栈中的都是当前结点的祖先）。若为黑色，是前向或横向边（结点已经被访问过）
拓扑排序 # 拓扑排序可以看做把图排列成一条直线，让所有的边都指向同一个方向。显然，有环图不能被线性排序。拓扑排序可以这样被简单实现：在 DFS 中，每完成一个结点，就将其排列到直线的最前面第一个位置。
强连通分量 # 强连通分量是指任何两个节点都能从正逆两个方向连通的一个分量。可以由 DFS 获得。在下面的算法中，我们以这样一个图为例：</description></item></channel></rss>