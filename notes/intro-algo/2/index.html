<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="排序算法 #    原地排序 (in place) ：仅需要常数的额外存储空间
  堆排序：$O(n\log_2n)$ 的原地排序算法
  快速排序：期望为 $\Theta(n\log_2n)$，最坏情况为 $\Theta(n^2)$，实际应用中通常比堆排序快。同时，其常数系数很小，是排序大数组时的常用算法。
  比较排序：通过对元素进行比较来决定，快排、归并、堆排序都是比较排序。比较排序的代价下界为 $\Omega(n\log_2n)$。
  线性时间排序：计数排序、基数排序、桶排序，在一定条件下，可以取得线性时间代价。
     算法 最坏情况代价 代价期望     插入排序 $\Theta(n^2)$ $\Theta(n^2)$   归并排序 $\Theta(n\log_2n)$ $\Theta(n\log_2n)$   堆排序 $O(n\log_2n)$    快速排序 $\Theta(n^2)$ $\Theta(n\log_2n)$   计数排序 $\Theta(k+n)$ $\Theta(k+n)$   基数排序 $\Theta(d(k+n))$ $\Theta(d(k+n))$   桶排序 $\Theta(n^2)$ $\Theta(n)$    堆排序 #  复杂度为 $O(n\log_2n)$，常数个额外空间（原地排序）。"><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content="2. Sorting, Order Statistic"><meta property="og:description" content="排序算法 #    原地排序 (in place) ：仅需要常数的额外存储空间
  堆排序：$O(n\log_2n)$ 的原地排序算法
  快速排序：期望为 $\Theta(n\log_2n)$，最坏情况为 $\Theta(n^2)$，实际应用中通常比堆排序快。同时，其常数系数很小，是排序大数组时的常用算法。
  比较排序：通过对元素进行比较来决定，快排、归并、堆排序都是比较排序。比较排序的代价下界为 $\Omega(n\log_2n)$。
  线性时间排序：计数排序、基数排序、桶排序，在一定条件下，可以取得线性时间代价。
     算法 最坏情况代价 代价期望     插入排序 $\Theta(n^2)$ $\Theta(n^2)$   归并排序 $\Theta(n\log_2n)$ $\Theta(n\log_2n)$   堆排序 $O(n\log_2n)$    快速排序 $\Theta(n^2)$ $\Theta(n\log_2n)$   计数排序 $\Theta(k+n)$ $\Theta(k+n)$   基数排序 $\Theta(d(k+n))$ $\Theta(d(k+n))$   桶排序 $\Theta(n^2)$ $\Theta(n)$    堆排序 #  复杂度为 $O(n\log_2n)$，常数个额外空间（原地排序）。"><meta property="og:type" content="article"><meta property="og:url" content="/notes/intro-algo/2/"><meta property="article:section" content="notes"><title>2. Sorting, Order Statistic | czdm75 Blog</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.97cfda4f5e3c9fa49a2bf8d401f4ddc0eec576c99cdcf6afbec19173200c37db.css><script defer src=/flexsearch.min.js></script>
<script defer src=/en.search.min.60f5c0362a1b15384bf6fbb748ad6fb49d79819ad4313fc4618ffb6d1f645f15.js></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>czdm75 Blog</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><input type=checkbox id=section-25b8c894ab868b34ecd6cce0ce4c79c7 class=toggle>
<label for=section-25b8c894ab868b34ecd6cce0ce4c79c7 class="flex justify-between"><a href=/cs/>Computer Science</a></label><ul><li><a href=/cs/linux-io-multiplex/>Linux IO Multiplexing</a></li></ul></li><li><input type=checkbox id=section-d5643d9c227c9fc0bfaa81dc6e0249af class=toggle>
<label for=section-d5643d9c227c9fc0bfaa81dc6e0249af class="flex justify-between"><a href=/distributed/>Distributed Systems</a></label><ul><li><a href=/distributed/hadoop-basic/>Hadoop Basic Concepts</a></li><li><a href=/distributed/spark-rdd/>Spark RDD Programming</a></li><li><a href=/distributed/spark-sql/>Spark SQL Programming</a></li></ul></li><li><a href=/notes/>Notes on Books</a><ul><li><input type=checkbox id=section-f9c54ee28ad742882651b9afb106f923 class=toggle>
<label for=section-f9c54ee28ad742882651b9afb106f923 class="flex justify-between"><a href=/notes/core-java-impatient/>Core Java for Impatients</a></label><ul><li><a href=/notes/core-java-impatient/1/>1. Basic OOP</a></li><li><a href=/notes/core-java-impatient/2/>2. Interface, Lambda</a></li><li><a href=/notes/core-java-impatient/3/>3. Inheritance, Reflection</a></li><li><a href=/notes/core-java-impatient/4/>4. Exception, Logging</a></li><li><a href=/notes/core-java-impatient/5/>5. Generics</a></li><li><a href=/notes/core-java-impatient/6/>6. Collections, Streams</a></li><li><a href=/notes/core-java-impatient/7/>7. IO, Regexp, Serialization</a></li><li><a href=/notes/core-java-impatient/8/>8. Threading</a></li><li><a href=/notes/core-java-impatient/9/>9. Notations</a></li></ul></li><li><input type=checkbox id=section-9d0fb26a4934bb77406a56b94138590b class=toggle>
<label for=section-9d0fb26a4934bb77406a56b94138590b class="flex justify-between"><a href=/notes/in-depth-jvm/>In-depth Understanding JVM</a></label><ul><li><a href=/notes/in-depth-jvm/gc/>Garbage Collection</a></li><li><a href=/notes/in-depth-jvm/synchronization/>Java Synchronization</a></li><li><a href=/notes/in-depth-jvm/memory-model/>JVM Memory Model</a></li><li><a href=/notes/in-depth-jvm/memory-region/>JVM Memory Regions</a></li><li><a href=/notes/in-depth-jvm/threadlocal-reference/>ThreadLocal and Reference</a></li></ul></li><li><input type=checkbox id=section-4d028229be962782539eef651433109e class=toggle checked>
<label for=section-4d028229be962782539eef651433109e class="flex justify-between"><a href=/notes/intro-algo/>Introduction to Algorithms</a></label><ul><li><a href=/notes/intro-algo/1/>1. Compexity, Divide</a></li><li><a href=/notes/intro-algo/2/ class=active>2. Sorting, Order Statistic</a></li><li><a href=/notes/intro-algo/3/>3. LinkedList, HashTable</a></li><li><a href=/notes/intro-algo/4/>4. BST, Balanced BSTs</a></li><li><a href=/notes/intro-algo/5/>5. Trie-Tree, Extending Data Structures</a></li><li><a href=/notes/intro-algo/6/>6. Dynamic Programming, Greedy, Amortize</a></li><li><a href=/notes/intro-algo/7/>7. B-Tree, Fibonacci Heap, vEB Tree</a></li><li><a href=/notes/intro-algo/8/>8. Graphs</a></li></ul></li><li><input type=checkbox id=section-76be9453a58f37863458b83352d3ff3c class=toggle>
<label for=section-76be9453a58f37863458b83352d3ff3c class="flex justify-between"><a href=/notes/programming-scala/>Programming in Scala</a></label><ul><li><a href=/notes/programming-scala/1/>1. Basics</a></li><li><a href=/notes/programming-scala/2/>2. Functions</a></li><li><a href=/notes/programming-scala/3/>3 .Inheritance, Package, Assertion</a></li><li><a href=/notes/programming-scala/4/>4. Pattern Matching, Collections</a></li><li><a href=/notes/programming-scala/5/>5. Generics, Abstract, Implicits</a></li><li><a href=/notes/programming-scala/6/>6. Collections, Extractor, etc</a></li></ul></li></ul></li><li><input type=checkbox id=section-9784d97422a8bbe41d06f74a08150515 class=toggle>
<label for=section-9784d97422a8bbe41d06f74a08150515 class="flex justify-between"><a href=/pl/>Programming Languages</a></label><ul><li><a href=/pl/java-nio-2/>Java NIO Internal</a></li><li><a href=/pl/java-nio-1/>Java NIO Usage</a></li><li><a href=/pl/lambda/>Lambda Calculus and Y Combinator</a></li><li><a href=/pl/curry/>Scala: Currying, Partially Applied, Partial</a></li><li><a href=/pl/monad/>Scala: Monad, from Scala Perspective</a></li></ul></li></ul><ul><li><a href=https://github.com/czdm75 target=_blank rel=noopener>GitHub</a></li><li><a href=https://themes.gohugo.io/hugo-book/ target=_blank rel=noopener>Theme</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label>
<strong>2. Sorting, Order Statistic</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#排序算法>排序算法</a></li><li><a href=#堆排序>堆排序</a><ul><li><a href=#最大堆结构>最大堆结构</a></li><li><a href=#维护堆的性质最大堆化>维护堆的性质：最大堆化</a></li><li><a href=#建堆>建堆</a></li><li><a href=#堆排序-1>堆排序</a></li><li><a href=#优先队列>优先队列</a></li></ul></li><li><a href=#快速排序>快速排序</a><ul><li><a href=#算法描述>算法描述</a></li><li><a href=#性能分析>性能分析</a></li><li><a href=#快速排序的概率分析>快速排序的概率分析</a></li></ul></li><li><a href=#非比较排序>非比较排序</a><ul><li><a href=#比较排序的下界>比较排序的下界</a></li><li><a href=#计数排序>计数排序</a></li><li><a href=#基数排序>基数排序</a><ul><li><a href=#算法描述-1>算法描述</a></li><li><a href=#代价分析>代价分析</a></li><li><a href=#与比较排序的对比>与比较排序的对比</a></li></ul></li><li><a href=#桶排序>桶排序</a></li></ul></li><li><a href=#顺序统计量>顺序统计量</a><ul><li><a href=#顺序统计量-1>顺序统计量</a></li><li><a href=#最大值和最小值>最大值和最小值</a></li><li><a href=#选择算法>选择算法</a><ul><li><a href=#期望为线性时间的分治选择算法>期望为线性时间的分治选择算法</a></li><li><a href=#最坏情况下代价为线性时间的选择算法>最坏情况下代价为线性时间的选择算法</a></li></ul></li></ul></li><li><a href=#扩展其他常见排序方法>扩展：其他常见排序方法</a><ul><li><a href=#鸡尾酒排序>鸡尾酒排序</a></li><li><a href=#梳排序>梳排序</a></li><li><a href=#其他排序方法>其他排序方法</a></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=排序算法>排序算法
<a class=anchor href=#%e6%8e%92%e5%ba%8f%e7%ae%97%e6%b3%95>#</a></h1><ul><li><p>原地排序 (in place) ：仅需要常数的额外存储空间</p></li><li><p>堆排序：$O(n\log_2n)$ 的原地排序算法</p></li><li><p>快速排序：期望为 $\Theta(n\log_2n)$，最坏情况为 $\Theta(n^2)$，实际应用中通常比堆排序快。同时，其常数系数很小，是排序大数组时的常用算法。</p></li><li><p>比较排序：通过对元素进行比较来决定，快排、归并、堆排序都是比较排序。比较排序的代价下界为 $\Omega(n\log_2n)$。</p></li><li><p>线性时间排序：计数排序、基数排序、桶排序，在一定条件下，可以取得线性时间代价。</p></li></ul><table><thead><tr><th>算法</th><th>最坏情况代价</th><th>代价期望</th></tr></thead><tbody><tr><td>插入排序</td><td>$\Theta(n^2)$</td><td>$\Theta(n^2)$</td></tr><tr><td>归并排序</td><td>$\Theta(n\log_2n)$</td><td>$\Theta(n\log_2n)$</td></tr><tr><td>堆排序</td><td>$O(n\log_2n)$</td><td></td></tr><tr><td>快速排序</td><td>$\Theta(n^2)$</td><td>$\Theta(n\log_2n)$</td></tr><tr><td>计数排序</td><td>$\Theta(k+n)$</td><td>$\Theta(k+n)$</td></tr><tr><td>基数排序</td><td>$\Theta(d(k+n))$</td><td>$\Theta(d(k+n))$</td></tr><tr><td>桶排序</td><td>$\Theta(n^2)$</td><td>$\Theta(n)$</td></tr></tbody></table><h1 id=堆排序>堆排序
<a class=anchor href=#%e5%a0%86%e6%8e%92%e5%ba%8f>#</a></h1><p>复杂度为 $O(n\log_2n)$，常数个额外空间（原地排序）。</p><h2 id=最大堆结构>最大堆结构
<a class=anchor href=#%e6%9c%80%e5%a4%a7%e5%a0%86%e7%bb%93%e6%9e%84>#</a></h2><p>最大堆是一个完全二叉树，且对于每一个结点，其子结点都比这个结点的值更小。通常使用数组来存储。这样，如果数组的下标从 1 开始，那么任意一个结点 $n$ 的左子结点为 $2n$，右子结点为 $2n+1$，父结点为 $\lfloor i/2\rfloor$（向下取整）。这样，我们可以轻松地利用移位指令来取得结点下标，获得比较高的性能。显然，二叉树的高度为 $\Theta(\log_2n)$。于是，我们能得到一些堆上的基本操作的复杂度：</p><ul><li><p>最大堆化（Max-heapify），复杂度为 $\Theta(\log_2n)$。</p></li><li><p>构建最大堆（Build-max-heap），线性时间复杂度，将无序数据转化为最大堆。</p></li><li><p>堆排序（Heapsort），复杂度为 $O(n\log_2n)$，对一个数组进行原地排序。</p></li><li><p>插入（Max-Heap-Insert）、删除最大（Heap-Extract-Max）、增长 key（Heap-Increase-Key）、取得最大（Heap-Maximum），时间复杂度为 $O(\log_2n)$，功能是利用堆实现一个优先队列。</p></li></ul><h2 id=维护堆的性质最大堆化>维护堆的性质：最大堆化
<a class=anchor href=#%e7%bb%b4%e6%8a%a4%e5%a0%86%e7%9a%84%e6%80%a7%e8%b4%a8%e6%9c%80%e5%a4%a7%e5%a0%86%e5%8c%96>#</a></h2><p>最大堆化（Max-heapify）的输入是一个数组 $A$ 和一个下标 $i$。其中，$i$ 结点的左右子树都是已经构建完成的最大堆，而 $A[i]$ 不一定是。然后，我们通过 “逐级下降” 过程，将 $A[i]$ 插入到适当的位置，使得以 $A[i]$ 为根结点的子树是一个最大堆。</p><p>算法如下：在程序的每一步，判断当前结点和其左右子结点的大小关系。如果父结点最大，显然最大堆已经完成。否则，将父结点与更大的一个子结点交换，并下降到交换的位置，重复这个流程。通过这样的不断与子结点交换的过程，目标将下降到适当的位置，使整个二叉树成为一个最大堆。</p><p>这个过程中的代价包括：判断和调整三个结点的过程，代价为 $\Theta(1)$，加上递归调用的代价。每个子树的大小最多为 $\frac{2n}3$（当树的最底层半满时），那么我们可以用递归式 $T(n) \leqslant T(\frac{2n}3 + \Theta(1))$ 来描述这个递归调用。使用主定理解得 $T(n) = O(\log_2n)$。也就是说，对于一个树高为 $h$ 的结点，最大堆化的时间复杂度为 $O(h)$。</p><h2 id=建堆>建堆
<a class=anchor href=#%e5%bb%ba%e5%a0%86>#</a></h2><pre tabindex=0><code class=language-pseudocode data-lang=pseudocode>for i = A.length/2 downto 1
    MAX-HEAPIFY(A,i)
</code></pre><p>将数组当成一个二叉树，从第一个非叶子结点开始，直到堆顶，不断进行最大堆化。在这个过程中，二叉树底部的结点，实行最大堆化的代价越小，而数量越多。结合上一部分得到的最大堆化的时间复杂度为 $O(h)$ 的结论，这个过程的代价为：</p><p>$$
\sum_{h=0}^{\lfloor \log_2n \rfloor} \lceil \frac n {2^{k+1}} \rceil O(h)
= O(n) \sum_{h=0}^{\lfloor \log_2n \rfloor} \frac h {2^h}
$$</p><p>又有公式：</p><p>$$
\sum_{k=0}^{\infty} x^k = \frac x {(1-x)^2}
$$</p><p>令 $x = \frac12$ 可以得到：</p><p>$$
\sum_{k=0}^{\infty} \frac h {2^h}
= \frac {\frac12} {(1-\frac12)^2} = 2
$$</p><p>于是：</p><p>$$
O(n)\sum_{h=0}^{\lfloor \log_2n \rfloor} \frac h{2^h}
= O(n)\sum_{h=0}^{\infty} \frac h {2^h}
= O(n)
$$</p><p>因此，我们可以在线性时间内构建一个最大堆。</p><h2 id=堆排序-1>堆排序
<a class=anchor href=#%e5%a0%86%e6%8e%92%e5%ba%8f-1>#</a></h2><p>最大堆只能保证父子结点之间的大小关系，而不能保证同一层之间的关系，因此，排序尚未完成。为此，我们可以不断取出最大堆的根结点，并放置在堆后面。这样，所有元素将以升序摆放好。</p><p>首先，将最大堆的根结点与最后一个结点互换。随后，对这个被换上来的结点执行最大堆化。在它被放置在正确的位置之后，整个序列中最大的值就被放置在了适当的位置，即数组的末尾，而其余值则仍然组成一个大小为 $n-1$ 的最大堆（这也是从最大堆中取出最大值的方法）。不断重复这个过程，缩小最大堆，就能够将所有元素摆放在适当的位置。</p><h2 id=优先队列>优先队列
<a class=anchor href=#%e4%bc%98%e5%85%88%e9%98%9f%e5%88%97>#</a></h2><p>决定优先队列的顺序的值称为关键字（key）。一个最大优先队列可以：</p><ul><li>插入元素</li><li>取最大元素</li><li>删除最大元素</li><li>增大 key：将序列中一个元素的 key 修改为一个更大的值</li></ul><p>最大优先队列可用于批处理式计算机系统的作业调度，用来寻找当前所有任务中优先级最高的开始执行。</p><p>显然，取得最大元素的时间复杂度为 $\Theta(1)$，删除最大元素的时间复杂度为 $O(\log_2n)$（相当于堆排序的第一步）。增大某个元素的 key，可以在修改之后将其不断与其父结点比较并交换，直到这个结点小于其父结点，意味着它来到了适合的位置上。这个过程的复杂度为 $O(\log_2n)$。在队列中增加结点，可以先在末尾加入一个 key 为 $-\infty$ 的结点（此时二叉树仍然是一个最大堆），再将其 key 增加为需要的值，并应用上面的算法。显然，复杂度为 $O(\log_2n)$。</p><h1 id=快速排序>快速排序
<a class=anchor href=#%e5%bf%ab%e9%80%9f%e6%8e%92%e5%ba%8f>#</a></h1><h2 id=算法描述>算法描述
<a class=anchor href=#%e7%ae%97%e6%b3%95%e6%8f%8f%e8%bf%b0>#</a></h2><ul><li>分解：将数组划分为两个子数组和一个分界，并使所有左侧数组的值小于右侧数组。</li><li>解决：对两个子数组递归调用快速排序</li><li>合并：数组已经排序完成。</li></ul><p>当数组长度为 1 时，可以直接认为这个子数组排序已完成。</p><p>快速排序划分算法的一种实现是：以数组末尾为主元（pivot），在内存中维护两个指针，分别代表两个数组的分界和右侧数组的末尾，初始化到数组头部。向右扫描，如果当前元素大于 pivot，说明其应该被放置在右侧数组，于是增长右侧指针的值。如果小于，则将其与右侧数组的第一个元素交换，并增长左侧指针的值。如下：</p><table><thead><tr><th>step</th><th></th><th></th><th></th><th></th><th></th><th>i</th><th>j</th></tr></thead><tbody><tr><td>1</td><td>2</td><td>8</td><td>7</td><td>1</td><td>4</td><td>-1</td><td>0</td></tr><tr><td>2</td><td>2</td><td>8</td><td>7</td><td>1</td><td>4</td><td>0</td><td>1</td></tr><tr><td>3</td><td>2</td><td>8</td><td>7</td><td>1</td><td>4</td><td>0</td><td>2</td></tr><tr><td>4</td><td>2</td><td>8</td><td>7</td><td>1</td><td>4</td><td>0</td><td>3</td></tr><tr><td>5</td><td>2</td><td>1</td><td>7</td><td>8</td><td>4</td><td>1</td><td>4</td></tr><tr><td>6</td><td>2</td><td>1</td><td>4</td><td>8</td><td>7</td><td>-</td><td>-</td></tr></tbody></table><p>在第 5 步，由于 j 遇到了应该被放在左侧数组的元素，所以进行一次交换。最后，将 pivot 交换到合适位置。</p><p>数组划分的另一种实现，使用分别向左和向右的两个指针，交替进行扫描。取第一个元素为 pivot，开始从右向左扫描。当遇到小于 pivot，应该放在左侧的元素时，将其放在之前取 pivot 留下的空位，即左指针指向的位置。相应的，此时右侧指针指向的位置即为空位。并开始从左向右扫描，交替进行，直到两个指针重合（此时应同时指向空位），将 pivot 放置在空位上。过程如下：</p><table><thead><tr><th>step</th><th></th><th></th><th></th><th></th><th></th><th>l</th><th>r</th></tr></thead><tbody><tr><td>1</td><td>2</td><td>8</td><td>7</td><td>1</td><td>4</td><td>0</td><td>4</td></tr><tr><td>2</td><td>-</td><td>8</td><td>7</td><td>1</td><td>4</td><td>0</td><td>4</td></tr><tr><td>3</td><td>-</td><td>8</td><td>7</td><td>1</td><td>4</td><td>0</td><td>3</td></tr><tr><td>4</td><td>1</td><td>8</td><td>7</td><td>-</td><td>4</td><td>1</td><td>3</td></tr><tr><td>5</td><td>1</td><td>-</td><td>7</td><td>8</td><td>4</td><td>1</td><td>2</td></tr><tr><td>6</td><td>1</td><td>2</td><td>7</td><td>8</td><td>4</td><td>1</td><td>1</td></tr></tbody></table><p>这种情况下，两个指针时刻有一个执行扫描任务，一个指向空位，预备交换。</p><h2 id=性能分析>性能分析
<a class=anchor href=#%e6%80%a7%e8%83%bd%e5%88%86%e6%9e%90>#</a></h2><p>最坏情况下，对于每次划分，都把数组划分为一个单独的元素与一个长度为 $n-1$ 的数组。或者说，分解成一个长度为 0 的数组和另一个数组。此时，可以用递归式：</p><p>$$
T(n) = T(n-1) + T(0) + \Theta(n) = \Theta(n^2)
$$</p><p>来表示算法的代价。</p><p>最好情况下，所有的划分都是平均的。此时，代价的递归式为：</p><p>$$
T(n) = 2T(\frac n 2) + \Theta(n) = \Theta(n\log_2n)
$$</p><p>可以证明，任何一种<strong>常数</strong>比例的划分，即使相当不均衡，都会得到 $\Theta(n\log_2n)$ 的结果。</p><p>除此之外，我们还可以在划分中取随机的 pivot，并经过一次交换后再开始正常的流程。通过这种方式，可以在算法中引入随机性，避免最差情况的出现。</p><h2 id=快速排序的概率分析>快速排序的概率分析
<a class=anchor href=#%e5%bf%ab%e9%80%9f%e6%8e%92%e5%ba%8f%e7%9a%84%e6%a6%82%e7%8e%87%e5%88%86%e6%9e%90>#</a></h2><p>快速排序的运行时间取决于划分过程中进行比较的次数。定义一个随机指示器变量 $X_{ij}=\mathrm I\{\text{compare $z_i$ with $z_j$}\}$，那么总的比较次数的期望为：</p><p>$$
\begin{aligned}
\mathrm E(X)
& = \mathrm E[ \sum_{i=1}^{n-1} \sum_{j=i+1}^{n} X_{ij} ] \cr
& = \sum_{i=1}^{n-1} \sum_{j=i+1}^{n} \mathrm E[X_{ij}] \cr
& = \sum_{i=1}^{n-1} \sum_{j=i+1}^{n} \Pr\{\text{compare $z_i$ with $z_j$}\}
\end{aligned}
$$</p><p>考虑划分过程中的情况：所有元素都要与主元比较，且划分得到的两个数组之间不会发生比较。于是：</p><p>$$
\begin{aligned}
& \Pr\{\text{compare $z_i$ with $z_j$}\} \cr
= & \Pr\{\text{$z_i$ is first pivot of set $Z_{ij}$}\} + \Pr\{\text{$z_j$ if first pivot of set $Z_{ij}$}\} \cr
= & \frac 2 {j-i+1}
\end{aligned}
$$</p><p>代入得到：</p><p>$$
\begin{aligned}
\mathrm E(X)
& = \sum_{i=1}^{n-1} \sum_{j=i+1}^{n} \frac 2 {j-i+1} \cr
& = \sum_{i=1}^{n-1} \sum_{j=i+1}^{n} \frac2{k+1} \cr
& &lt; \sum_{i=1}^{n-1} \sum_{j=i+1}^{n} \frac2k \cr
& = O(n\log_2n)
\end{aligned}
$$</p><p>快速排序的主要课题是防止最坏情况攻击。一种常用的方法是随机取三个数，并以其中位数为 pivot。</p><h1 id=非比较排序>非比较排序
<a class=anchor href=#%e9%9d%9e%e6%af%94%e8%be%83%e6%8e%92%e5%ba%8f>#</a></h1><h2 id=比较排序的下界>比较排序的下界
<a class=anchor href=#%e6%af%94%e8%be%83%e6%8e%92%e5%ba%8f%e7%9a%84%e4%b8%8b%e7%95%8c>#</a></h2><p>之前介绍的归并排序、堆排序、快速排序都属于比较排序。比较排序在最坏情况下都为 $\Omega(n\log_2n)$ 的。因此，复杂度为 $\Theta(n\log_2n)$ 的归并排序和堆排序是渐进最优的，其他所有算法都只是在常数项上比它们更优。</p><p>一个比较排序可以抽象为一颗决策树。如，对于序列 $a,b$ 的决策树为，根节点判断两个元素的大小，左叶子节点是 $a\leqslant b$ 的结果，右叶子节点是 $a>b$ 的结果。相应地，对于长度为 3 的序列，树将有三层，六个叶子节点。决策树的最大层数既是我们在得到结果之前必须做的比较的次数。</p><p>对于一个长度为 $n$ 的待排序序列，让决策树有 $l$ 个可达节点，即这些个可能的排列，树的高度为 $h$。那么将有：</p><p>$$
n! \leqslant l \leqslant 2^h
$$</p><p>两边取对数得到：</p><p>$$
h \geqslant \log_2(n!) = \Omega(n\log_2n)
$$</p><h2 id=计数排序>计数排序
<a class=anchor href=#%e8%ae%a1%e6%95%b0%e6%8e%92%e5%ba%8f>#</a></h2><p>计数排序的基本思想是：对每一个元素，数出有多少个元素小于它，则这个元素应该被放在相应数量后面的下一个位置。假设 $n$ 个输入元素均为 $0$ 到 $k$ 区间内的一个整数，那么当 $k = O(n)$ 时，排序的运行时间为 $\Theta(n)$。</p><p>计数排序的实现是这样的：初始化一个长度为 $k$ 的数组 $C$ 用来计数，扫描原数组，对每个元素，如果值为 $i$，就在 $C[i]$ 位置加一。扫描完成之后，就得到了每个值的元素数量。随后，在 $C$ 数组上进行一次 $C[i] = C[i] + C[i-1]$ 的扫描，这时 $C$ 数组中储存的就是小于该下标值的元素的数量。最后，扫描原数组，根据 $C$ 数组中的数据，将这些元素放置在另一个数组中合适的位置。</p><p>显然，整个算法经历了一次 $\Theta(n)$ 的扫描，一次 $\Theta(k)$ 的累加和一次 $\Theta(n)$ 的复制，整个算法的复杂度为 $\Theta(n+k)$。当 $k = O(n)$ 时，复杂度就是 $\Theta(n)$。</p><p>在复制过程中，如果存在两个元素的值相等，就放到下一个位置，之前的技过程已经为它留计数了位置。因此，计数排序是稳定的。下面我们将看到，这个性质在其作为基数排序的一部分时，相当有用。</p><h2 id=基数排序>基数排序
<a class=anchor href=#%e5%9f%ba%e6%95%b0%e6%8e%92%e5%ba%8f>#</a></h2><h3 id=算法描述-1>算法描述
<a class=anchor href=#%e7%ae%97%e6%b3%95%e6%8f%8f%e8%bf%b0-1>#</a></h3><p>基数排序（radix sort）来源于卡片排序机。卡片计算机一次只能判断一列孔，即只能判断一位数字。直觉上，我们倾向于从最高位开始，递归向下地进行排序。但是，这种方法在卡片计算机上使用时将会需要临时保存好另外 9 种数字的卡片，在数字位数较多时使用的容器和标签就会相当可观。</p><p>因此，实际上我们是从最低位开始进行排序的。在排序好最低位之后，可以直接把所有卡片按顺序叠在一起，开始进行第二位的排序。这样就不需要把卡片另行保存，直接排序完成就能使用。</p><p>所以，基数排序实际上是从低到高按位进行其他排序方法的算法。由于低位在之前的循环中已经排好，使用的其他排序方法必须是稳定的，否则低位的顺序就会被打乱。除了按十进制的位之外，还可以对日期按日 - 月 - 年进行排序等很多类似方式。</p><h3 id=代价分析>代价分析
<a class=anchor href=#%e4%bb%a3%e4%bb%b7%e5%88%86%e6%9e%90>#</a></h3><p>给定 $n$ 个 $d$ 位数，其中每个位有 $k$ 个可能的取值，由于 $k$ 有限且不大，计数排序十分合适，复杂度为 $\Theta(n+k)$。显然，总的复杂度为 $\Theta(d(n+k))$。</p><p>接下来讨论 “划分” 位的策略。如果把子排序中使用的位数从 1 位扩展到 $r$ 位，而 整个数字一共有 $b$ 位。那么，上式的 $d$ 就是 $b/r$，$k$ 就是 $2^r-1$。例如，对于一个 32 位的整数，我们将其分解为 4 个字节，于是 $b = 32$，$r = 8$，对每个字节进行计数排序。在相似的条件下，排序的复杂度就变成了 $\Theta(\frac b r (n+2^r))$。</p><p>如果 $b &lt; \lfloor \log_2n \rfloor$，那么对于任何 $r \leqslant b$，都有 $(n+2^r) = \Theta(n)$，算法的复杂度取决于 $b/r$。显然，当 $r = b$，复杂度取得最小值 $\Theta(n)$。</p><p>如果 $b \geqslant \lfloor \log_2n \rfloor$，对 $r$ 的值分情况来讨论。如果 $r = \lfloor \log_2n \rfloor$，可以得到最优时间代价 $\Theta(bn/\log_2n)$。如果 $r&lt;\lfloor\log_2n\rfloor$，值越小，$b/r$ 项的值就越大，$(n+2^r)$ 仍然为 $\Theta(n)$。反之，$r$ 越大，分子中的 $2^r$ 项比分母中的 $r$ 项增长得更快。因此，时间代价为 $\Omega(bn/\log_2n)$。</p><h3 id=与比较排序的对比>与比较排序的对比
<a class=anchor href=#%e4%b8%8e%e6%af%94%e8%be%83%e6%8e%92%e5%ba%8f%e7%9a%84%e5%af%b9%e6%af%94>#</a></h3><p>虽然基数排序的复杂度比较小，其中的常数项相对于比较排序来说哪一个更大，要取决于机器具体的实现和数据的特点。例如，通常来说快排可以更加有效地利用机器的缓存。另外，计数排序是一个非原地排序。当机器主存紧缺的时候，原地排序的优势就更大一些。</p><h2 id=桶排序>桶排序
<a class=anchor href=#%e6%a1%b6%e6%8e%92%e5%ba%8f>#</a></h2><p>桶排序同样有一个假设：数据服从均匀分布，且有一定的范围。桶排序的流程是：将区间 $[0,1)$ 划分为若干个桶，将数据投入到各个桶中（实现上，可以用整数除法等操作实现）。在数据分布比较平均的情况下，各个桶里数据的量也比较平均。随后，对每个桶进行排序。最后，把所有的桶拼合起来即可。如果桶内的排序是稳定的，这个算法也是稳定的。</p><p>现在来分析时间代价。假设使用插入排序，那么时间代价 $T(n) = \Theta(n) + \sum_{i=0}^{n-1} O(n_i^2)$。对这个式子两边取期望，得到：</p><p>$$
\mathrm E[T(n)]
= \mathrm[ \Theta(n) + \sum_{i=0}^{n-1} O(n_i^2) ]
= \Theta(n) + \sum_{i=0}^{n-1} O(\mathrm E[n_i^2])
$$</p><p>我们断言 $\mathrm E[n_i^2] = 2 - \frac 1 n$，这个值可以利用随机指示器证明。最终，得到桶排序的时间复杂度：$\Theta(n) + n \cdot O(2-\frac 1 n) = \Theta(n)$。</p><h1 id=顺序统计量>顺序统计量
<a class=anchor href=#%e9%a1%ba%e5%ba%8f%e7%bb%9f%e8%ae%a1%e9%87%8f>#</a></h1><h2 id=顺序统计量-1>顺序统计量
<a class=anchor href=#%e9%a1%ba%e5%ba%8f%e7%bb%9f%e8%ae%a1%e9%87%8f-1>#</a></h2><p>一个 $n$ 个数的集合的第 $i$ 个顺序统计量表示集合中第 $i$ 小的数。寻找顺序统计量的算法称为选择算法。显然，可以通过排序以 $O(n\log_2n)$ 的代价寻找到该统计量。</p><h2 id=最大值和最小值>最大值和最小值
<a class=anchor href=#%e6%9c%80%e5%a4%a7%e5%80%bc%e5%92%8c%e6%9c%80%e5%b0%8f%e5%80%bc>#</a></h2><p>显然，最大值和最小值都属于顺序统计量的一种，可以通过代价为线性时间的一次扫描获得。一种同时取得最小值和最大值的方法是，对于每两个元素，先对这两个元素互相进行比较。随后，将较大者和最大值比较，较小者和最小值比较。这样，每两个元素只需要进行三次比较。比较次数从 $2n-2$ 次减少到 $\frac 3 2 n$ 次。</p><h2 id=选择算法>选择算法
<a class=anchor href=#%e9%80%89%e6%8b%a9%e7%ae%97%e6%b3%95>#</a></h2><h3 id=期望为线性时间的分治选择算法>期望为线性时间的分治选择算法
<a class=anchor href=#%e6%9c%9f%e6%9c%9b%e4%b8%ba%e7%ba%bf%e6%80%a7%e6%97%b6%e9%97%b4%e7%9a%84%e5%88%86%e6%b2%bb%e9%80%89%e6%8b%a9%e7%ae%97%e6%b3%95>#</a></h3><p>randomized-select 算法是以快速排序为原型的。区别在于，作为选择算法，这个算法只需要对划分的一边进行递归处理。randomized 的意思是，它采用了和随机化快排中使用的相同的划分算法：随机挑选一个值作为主元 pivot。随后，我们从目标所在的那个分区继续递归调用，寻找顺序统计量。显然，这个算法的最坏情况代价和快速排序一样，为 $\Theta(n^2)$。当所有元素都是互异的，这个算法的期望复杂度能够达到线性水平。证明过程比较繁复，按下不表。</p><h3 id=最坏情况下代价为线性时间的选择算法>最坏情况下代价为线性时间的选择算法
<a class=anchor href=#%e6%9c%80%e5%9d%8f%e6%83%85%e5%86%b5%e4%b8%8b%e4%bb%a3%e4%bb%b7%e4%b8%ba%e7%ba%bf%e6%80%a7%e6%97%b6%e9%97%b4%e7%9a%84%e9%80%89%e6%8b%a9%e7%ae%97%e6%b3%95>#</a></h3><p>这种选择算法是这样的：将输入按照每五个一组分组，并通过插入排序找到每一组的中位数，随后，递归调用本算法，找到中位数的中位数。如果这个中位数就是目标，此时就可以返回。然后，以这个中位数为 pivot 进行划分。随后，对目标所在的子数组再次递归调用。</p><p>显然，分组、插入排序和划分都是线性代价的。递归寻找中位数的中位数这个过程的代价是 $T(\frac n5)$，递归进行最后一步的代价最多是 $T(\frac 7{10}n+6)$。于是有递归式：</p><p>$$
T(n) \leqslant
\begin{cases}
O(1) & \text{if } n&lt;140 \cr
T(\frac n5) + T(\frac 7{10}n) + O(n) & \text{if } n \geqslant 140
\end{cases}
$$</p><p>结果为 $O(n)$。不过，这个算法更加具有理论性质，它的常数项过大，大部分情况下都不适用。</p><h1 id=扩展其他常见排序方法>扩展：其他常见排序方法
<a class=anchor href=#%e6%89%a9%e5%b1%95%e5%85%b6%e4%bb%96%e5%b8%b8%e8%a7%81%e6%8e%92%e5%ba%8f%e6%96%b9%e6%b3%95>#</a></h1><p>希尔排序是这样一种算法：规定一个步长，从第一个元素开始，把所有间隔这个步长的元素作为一个子数组，对所有子数组进行原地的插入排序。随后缩小步长，继续进行类似的操作。直到步长为 1，经过插入排序的一遍扫描之后，序列即被排序好。</p><p>希尔排序的核心思想是通过步长和分组使前期排序的 $n$ 变小，而后期排序的序列处于 “基本排好” 的状态，以避免插入排序中面临的大量元素移动操作。一次典型的希尔排序过程如下：</p><table><thead><tr><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th>step</th></tr></thead><tbody><tr><td>49</td><td>38</td><td>65</td><td>97</td><td>76</td><td>131</td><td>27</td><td>49</td><td>55</td><td>04</td><td>5</td></tr><tr><td>13</td><td>27</td><td>49</td><td>55</td><td>04</td><td>49</td><td>38</td><td>65</td><td>97</td><td>76</td><td>3</td></tr><tr><td>13</td><td>04</td><td>49</td><td>38</td><td>27</td><td>49</td><td>55</td><td>65</td><td>97</td><td>76</td><td>1</td></tr><tr><td>04</td><td>13</td><td>27</td><td>38</td><td>49</td><td>49</td><td>55</td><td>65</td><td>76</td><td>97</td><td>-</td></tr></tbody></table><p>如，在算法的第一轮，以 5 为步长，则 (49, 13) 为一组，进行插入排序后二者被交换。第二轮以 3 为步长，则 (13, 55, 38, 76) 为一组，进行插入排序。</p><p>朴素的希尔排序最差情况下的复杂度与插入排序相同，为 $O(n^2)$。不过，在精心设计的步长序列下，希尔排序在小数组上的效率甚至可能比快排更好。与冒泡排序比较，希尔排序相当于使用步长这个特点来使元素一次跳过比较长的距离。由于希尔排序的各轮之间是独立的，这个算法是不稳定的。</p><h2 id=鸡尾酒排序>鸡尾酒排序
<a class=anchor href=#%e9%b8%a1%e5%b0%be%e9%85%92%e6%8e%92%e5%ba%8f>#</a></h2><p>原始的冒泡排序是这样的：每进行完一轮扫描，就回到序列头部重新开始。而鸡尾酒排序在进行完一次从左到右的排序后，继续进行从右到左的排序。鸡尾酒排序的双向冒泡可能会带来更好的性能，例如对于序列 (2, 3, 4, 5, 1)，鸡尾酒排序只需要一个来回，而冒泡排序需要 4 轮。但大部分情况下提升不大。平均时间代价仍然为 $O(n^2)$。</p><h2 id=梳排序>梳排序
<a class=anchor href=#%e6%a2%b3%e6%8e%92%e5%ba%8f>#</a></h2><p>梳排序的想法有些类似于希尔排序：同样是使用一个步长，不过这个步长不用来划分出数组，而是仍然从头扫描，两两比较交换。如对于序列 (a, b, c, d, e)，取步长为 3，将会对 a 和 d 比较交换，再对 b 和 e 比较交换。缩小步长为 2，则对 (a, c)、(b, d)、(c, e) 比较和交换。因为每一轮不是完整的排序过程，所以步长只能以 1 为单位递减。梳排序的最差复杂度为 $O(n^2)$，期望为 $\Theta(n\log_2n)$。</p><h2 id=其他排序方法>其他排序方法
<a class=anchor href=#%e5%85%b6%e4%bb%96%e6%8e%92%e5%ba%8f%e6%96%b9%e6%b3%95>#</a></h2><p>除此之外，还可以使用二叉搜索树构造有序序列，这种结构非常适合插入和查找一定大小的值，复杂度为 $O(n\log_2n)$。选择排序是不断取顺序统计量，也就是不断从后部分序列中寻找最小者并放在头部的算法，复杂度为 $O(n^2)$。内省排序是快排的一种改进，当递归达到一定的深度之后改用堆排序，以兼有二者的优势，将最差代价控制在 $O(n\log_2n)$。</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(n){const e=window.getSelection(),t=document.createRange();t.selectNodeContents(n),e.removeAllRanges(),e.addRange(t)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#排序算法>排序算法</a></li><li><a href=#堆排序>堆排序</a><ul><li><a href=#最大堆结构>最大堆结构</a></li><li><a href=#维护堆的性质最大堆化>维护堆的性质：最大堆化</a></li><li><a href=#建堆>建堆</a></li><li><a href=#堆排序-1>堆排序</a></li><li><a href=#优先队列>优先队列</a></li></ul></li><li><a href=#快速排序>快速排序</a><ul><li><a href=#算法描述>算法描述</a></li><li><a href=#性能分析>性能分析</a></li><li><a href=#快速排序的概率分析>快速排序的概率分析</a></li></ul></li><li><a href=#非比较排序>非比较排序</a><ul><li><a href=#比较排序的下界>比较排序的下界</a></li><li><a href=#计数排序>计数排序</a></li><li><a href=#基数排序>基数排序</a><ul><li><a href=#算法描述-1>算法描述</a></li><li><a href=#代价分析>代价分析</a></li><li><a href=#与比较排序的对比>与比较排序的对比</a></li></ul></li><li><a href=#桶排序>桶排序</a></li></ul></li><li><a href=#顺序统计量>顺序统计量</a><ul><li><a href=#顺序统计量-1>顺序统计量</a></li><li><a href=#最大值和最小值>最大值和最小值</a></li><li><a href=#选择算法>选择算法</a><ul><li><a href=#期望为线性时间的分治选择算法>期望为线性时间的分治选择算法</a></li><li><a href=#最坏情况下代价为线性时间的选择算法>最坏情况下代价为线性时间的选择算法</a></li></ul></li></ul></li><li><a href=#扩展其他常见排序方法>扩展：其他常见排序方法</a><ul><li><a href=#鸡尾酒排序>鸡尾酒排序</a></li><li><a href=#梳排序>梳排序</a></li><li><a href=#其他排序方法>其他排序方法</a></li></ul></li></ul></nav></div></aside></main><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css><script src=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js></script>
<script>renderMathInElement(document.querySelector("article.markdown"),{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})</script></body></html>