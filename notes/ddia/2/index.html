<!doctype html><html lang=en dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="数据存储与检索 # 数据结构 # 最基本的数据结构：线性的 k-v 对，增加/更新时直接 append，查询时搜索整个日志找到最晚的。
哈希索引 # 在上面的日志基础上，增加一个 hashmap，记录每个 key 的最晚位置。插入更新仍然是线性的，查找的速度也接近线性。需要所有 key 能够放在内存中，适合所有 key 都经常更新的情况。
为避免用尽磁盘，将日志文件切分为段。对每个已经写完的文件段，可以进行压缩合并，即仅保留其中同一个 key 最晚的记录。这个过程可以异步，不影响正在进行的读写。注意，压缩后每个 key 的 offset 会变化，所以对每个压缩后的段需要保存新的 hashmap。读数据时，从新到旧依次查找每一个 hashmap。这是 Riak 中的 BitCask 的默认做法。
文件存储：使用二进制格式 删除记录：使用特殊的已删除标记代替 value，进行插入 崩溃恢复：可以从文件中直接还原出 hashmap，可能较慢；也可以在磁盘上保留 hashmap 的快照，减少还原时间 写入时崩溃：使用校验位，确保不会认可不完整的数据 并发控制：单线程追加，多线程读 优点：写入快，并发和崩溃恢复简单，并发能力强 缺点：哈希表需要全部放在内存，区间查询效率差（WHERE BETWEEN） SSTable 和 LSM-Tree # 在上述基础上，对于压缩合并后的段文件，对 key 进行排序；对正在写入的文件，使用平衡二叉树。LevelDB、RocksDB、HBase、Cassandra 都是基于 SSTable。SSTable术语来自 BigTable 论文。整个方法也称 LSM-Tree（Log-Structured Merge Tree)
合并段变成归并，更加高效 段文件的 hashmap 可以是稀疏的，因为可以通过排序来查找，稀疏程度参考文件块，文件块可以进行通用压缩（区分于上述的取最晚操作，而是 gzip 等通用压缩） 平衡二叉树变成已排序段文件（SS-Table）的效率较高（中序遍历） 为防止崩溃时正在写入的文件丢失，可以双写到二叉树和日志，日志用于恢复，二叉树用于查询。 当 key 完全不存在时，需要访问所有的 hashmap，可能有多次磁盘 IO；为此使用 bloomfilter 做预过滤 压缩合并的方式：LevelDB 和 RocksDB 使用分层压缩，旧数据采用更高的压缩等级；HBase 使用大小分级压缩，较新的段文件较小，被合并到较旧、较大的段文件去。Cassandra 两种都支持。TODO B 树 # 关系型数据库的标准实现，思路是 1."><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:url" content="/notes/ddia/2/"><meta property="og:site_name" content="czdm75 Blog"><meta property="og:title" content="2. Storage, Query, Encoding"><meta property="og:description" content="数据存储与检索 # 数据结构 # 最基本的数据结构：线性的 k-v 对，增加/更新时直接 append，查询时搜索整个日志找到最晚的。
哈希索引 # 在上面的日志基础上，增加一个 hashmap，记录每个 key 的最晚位置。插入更新仍然是线性的，查找的速度也接近线性。需要所有 key 能够放在内存中，适合所有 key 都经常更新的情况。
为避免用尽磁盘，将日志文件切分为段。对每个已经写完的文件段，可以进行压缩合并，即仅保留其中同一个 key 最晚的记录。这个过程可以异步，不影响正在进行的读写。注意，压缩后每个 key 的 offset 会变化，所以对每个压缩后的段需要保存新的 hashmap。读数据时，从新到旧依次查找每一个 hashmap。这是 Riak 中的 BitCask 的默认做法。
文件存储：使用二进制格式 删除记录：使用特殊的已删除标记代替 value，进行插入 崩溃恢复：可以从文件中直接还原出 hashmap，可能较慢；也可以在磁盘上保留 hashmap 的快照，减少还原时间 写入时崩溃：使用校验位，确保不会认可不完整的数据 并发控制：单线程追加，多线程读 优点：写入快，并发和崩溃恢复简单，并发能力强 缺点：哈希表需要全部放在内存，区间查询效率差（WHERE BETWEEN） SSTable 和 LSM-Tree # 在上述基础上，对于压缩合并后的段文件，对 key 进行排序；对正在写入的文件，使用平衡二叉树。LevelDB、RocksDB、HBase、Cassandra 都是基于 SSTable。SSTable术语来自 BigTable 论文。整个方法也称 LSM-Tree（Log-Structured Merge Tree)
合并段变成归并，更加高效 段文件的 hashmap 可以是稀疏的，因为可以通过排序来查找，稀疏程度参考文件块，文件块可以进行通用压缩（区分于上述的取最晚操作，而是 gzip 等通用压缩） 平衡二叉树变成已排序段文件（SS-Table）的效率较高（中序遍历） 为防止崩溃时正在写入的文件丢失，可以双写到二叉树和日志，日志用于恢复，二叉树用于查询。 当 key 完全不存在时，需要访问所有的 hashmap，可能有多次磁盘 IO；为此使用 bloomfilter 做预过滤 压缩合并的方式：LevelDB 和 RocksDB 使用分层压缩，旧数据采用更高的压缩等级；HBase 使用大小分级压缩，较新的段文件较小，被合并到较旧、较大的段文件去。Cassandra 两种都支持。TODO B 树 # 关系型数据库的标准实现，思路是 1."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="notes"><title>2. Storage, Query, Encoding | czdm75 Blog</title>
<link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.97cfda4f5e3c9fa49a2bf8d401f4ddc0eec576c99cdcf6afbec19173200c37db.css><script defer src=/flexsearch.min.js></script><script defer src=/en.search.min.f7e98004e6b8d1bafd93b9d4b053644c96b18c50c1205ec6db396c209e97a5a3.js></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>czdm75 Blog</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><input type=checkbox id=section-7258d8e1fea5a0c302a6de537a7b6f57 class=toggle>
<label for=section-7258d8e1fea5a0c302a6de537a7b6f57 class="flex justify-between"><a href=/cs/>Computer Science</a></label><ul><li><a href=/cs/linux-io-multiplex/>Linux IO Multiplexing</a></li></ul></li><li><input type=checkbox id=section-6c3d93bc59df31a703231f35ad75d678 class=toggle>
<label for=section-6c3d93bc59df31a703231f35ad75d678 class="flex justify-between"><a href=/distributed/>Distributed Systems</a></label><ul><li><a href=/distributed/hadoop-basic/>Hadoop Basic Concepts</a></li><li><a href=/distributed/spark-rdd/>Spark RDD Programming</a></li><li><a href=/distributed/spark-sql/>Spark SQL Programming</a></li></ul></li><li><a href=/notes/>Notes on Books</a><ul><li><input type=checkbox id=section-75aaf2c83c6ed8e1f079c5418c19dad4 class=toggle>
<label for=section-75aaf2c83c6ed8e1f079c5418c19dad4 class="flex justify-between"><a href=/notes/core-java-impatient/>Core Java for Impatients</a></label><ul><li><a href=/notes/core-java-impatient/1/>1. Basic OOP</a></li><li><a href=/notes/core-java-impatient/2/>2. Interface, Lambda</a></li><li><a href=/notes/core-java-impatient/3/>3. Inheritance, Reflection</a></li><li><a href=/notes/core-java-impatient/4/>4. Exception, Logging</a></li><li><a href=/notes/core-java-impatient/5/>5. Generics</a></li><li><a href=/notes/core-java-impatient/6/>6. Collections, Streams</a></li><li><a href=/notes/core-java-impatient/7/>7. IO, Regexp, Serialization</a></li><li><a href=/notes/core-java-impatient/8/>8. Threading</a></li><li><a href=/notes/core-java-impatient/9/>9. Notations</a></li></ul></li><li><input type=checkbox id=section-b2f01d2b22c35e214487b845322f7a58 class=toggle checked>
<label for=section-b2f01d2b22c35e214487b845322f7a58 class="flex justify-between"><a href=/notes/ddia/>Designing Data-Intensive Applications</a></label><ul><li><a href=/notes/ddia/1/>1. Data System and Data Model</a></li><li><a href=/notes/ddia/2/ class=active>2. Storage, Query, Encoding</a></li><li><a href=/notes/ddia/3/>3. Replication and Partition</a></li></ul></li><li><input type=checkbox id=section-8c64db930c5b756022bf5d3ba1af6015 class=toggle>
<label for=section-8c64db930c5b756022bf5d3ba1af6015 class="flex justify-between"><a href=/notes/in-depth-jvm/>In-depth Understanding JVM</a></label><ul><li><a href=/notes/in-depth-jvm/gc/>Garbage Collection</a></li><li><a href=/notes/in-depth-jvm/synchronization/>Java Synchronization</a></li><li><a href=/notes/in-depth-jvm/memory-model/>JVM Memory Model</a></li><li><a href=/notes/in-depth-jvm/memory-region/>JVM Memory Regions</a></li><li><a href=/notes/in-depth-jvm/threadlocal-reference/>ThreadLocal and Reference</a></li></ul></li><li><input type=checkbox id=section-15259ec15aa2cb7859c77500905f6b03 class=toggle>
<label for=section-15259ec15aa2cb7859c77500905f6b03 class="flex justify-between"><a href=/notes/intro-algo/>Introduction to Algorithms</a></label><ul><li><a href=/notes/intro-algo/1/>1. Compexity, Divide</a></li><li><a href=/notes/intro-algo/2/>2. Sorting, Order Statistic</a></li><li><a href=/notes/intro-algo/3/>3. LinkedList, HashTable</a></li><li><a href=/notes/intro-algo/4/>4. BST, Balanced BSTs</a></li><li><a href=/notes/intro-algo/5/>5. Trie-Tree, Extending Data Structures</a></li><li><a href=/notes/intro-algo/6/>6. Dynamic Programming, Greedy, Amortize</a></li><li><a href=/notes/intro-algo/7/>7. B-Tree, Fibonacci Heap, vEB Tree</a></li><li><a href=/notes/intro-algo/8/>8. Graphs</a></li></ul></li><li><input type=checkbox id=section-3efdc8e38ef7f47959bf45f30a9dec98 class=toggle>
<label for=section-3efdc8e38ef7f47959bf45f30a9dec98 class="flex justify-between"><a href=/notes/programming-scala/>Programming in Scala</a></label><ul><li><a href=/notes/programming-scala/1/>1. Basics</a></li><li><a href=/notes/programming-scala/2/>2. Functions</a></li><li><a href=/notes/programming-scala/3/>3 .Inheritance, Package, Assertion</a></li><li><a href=/notes/programming-scala/4/>4. Pattern Matching, Collections</a></li><li><a href=/notes/programming-scala/5/>5. Generics, Abstract, Implicits</a></li><li><a href=/notes/programming-scala/6/>6. Collections, Extractor, etc</a></li></ul></li></ul></li><li><input type=checkbox id=section-ebdb83a62411872593631ee1e4ab41d9 class=toggle>
<label for=section-ebdb83a62411872593631ee1e4ab41d9 class="flex justify-between"><a href=/pl/>Programming Languages</a></label><ul><li><a href=/pl/java-nio-2/>Java NIO Internal</a></li><li><a href=/pl/java-nio-1/>Java NIO Usage</a></li><li><a href=/pl/lambda/>Lambda Calculus and Y Combinator</a></li><li><a href=/pl/curry/>Scala: Currying, Partially Applied, Partial</a></li><li><a href=/pl/monad/>Scala: Monad, from Scala Perspective</a></li></ul></li></ul><ul><li><a href=https://github.com/czdm75 target=_blank rel=noopener>GitHub</a></li><li><a href=https://themes.gohugo.io/hugo-book/ target=_blank rel=noopener>Theme</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu>
</label><strong>2. Storage, Query, Encoding</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#数据存储与检索>数据存储与检索</a><ul><li><a href=#数据结构>数据结构</a><ul><li><a href=#哈希索引>哈希索引</a></li><li><a href=#sstable-和-lsm-tree>SSTable 和 LSM-Tree</a></li><li><a href=#b-树>B 树</a></li><li><a href=#b-树和-lsm-树对比>B 树和 LSM 树对比</a></li><li><a href=#其他索引>其他索引</a><ul><li><a href=#聚集索引>聚集索引</a></li><li><a href=#多列索引>多列索引</a></li><li><a href=#全文搜索和模糊索引>全文搜索和模糊索引</a></li><li><a href=#在内存中保存所有内容>在内存中保存所有内容</a></li></ul></li></ul></li><li><a href=#事务处理与分析处理>事务处理与分析处理</a><ul><li><a href=#星型模式--维度建模--雪花模式>星型模式 / 维度建模 / 雪花模式</a></li></ul></li><li><a href=#列存>列存</a><ul><li><a href=#列压缩>列压缩</a></li><li><a href=#内存带宽和矢量化>内存带宽和矢量化</a></li><li><a href=#列存与排序>列存与排序</a></li><li><a href=#列存的写操作>列存的写操作</a></li><li><a href=#聚合数据-cube-与物化视图>聚合：数据 CUBE 与物化视图</a></li></ul></li></ul></li><li><a href=#数据编码与演化>数据编码与演化</a><ul><li><a href=#数据编码格式>数据编码格式</a><ul><li><a href=#language-specific-formats>Language-Specific formats</a></li><li><a href=#jsonxmlcsv-与其二进制变体>JSON、XML、CSV 与其二进制变体</a></li><li><a href=#thrift-与-protobuf>Thrift 与 ProtoBuf</a></li><li><a href=#avro>Avro</a></li><li><a href=#动态模式--模式的优点>动态模式 / 模式的优点</a></li></ul></li><li><a href=#数据流格式>数据流格式</a><ul><li><a href=#通过数据库>通过数据库</a></li><li><a href=#通过-rest--rpc>通过 REST / RPC</a></li><li><a href=#通过消息队列>通过消息队列</a></li></ul></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=数据存储与检索>数据存储与检索
<a class=anchor href=#%e6%95%b0%e6%8d%ae%e5%ad%98%e5%82%a8%e4%b8%8e%e6%a3%80%e7%b4%a2>#</a></h1><h2 id=数据结构>数据结构
<a class=anchor href=#%e6%95%b0%e6%8d%ae%e7%bb%93%e6%9e%84>#</a></h2><p>最基本的数据结构：线性的 k-v 对，增加/更新时直接 append，查询时搜索整个日志找到最晚的。</p><h3 id=哈希索引>哈希索引
<a class=anchor href=#%e5%93%88%e5%b8%8c%e7%b4%a2%e5%bc%95>#</a></h3><p>在上面的日志基础上，增加一个 hashmap，记录每个 key 的最晚位置。插入更新仍然是线性的，查找的速度也接近线性。需要所有 key 能够放在内存中，适合所有 key 都经常更新的情况。</p><p>为避免用尽磁盘，将日志文件切分为段。对每个已经写完的文件段，可以进行压缩合并，即仅保留其中同一个 key 最晚的记录。这个过程可以异步，不影响正在进行的读写。注意，压缩后每个 key 的 offset 会变化，所以对每个压缩后的段需要保存新的 hashmap。读数据时，从新到旧依次查找每一个 hashmap。这是 Riak 中的 BitCask 的默认做法。</p><ol><li>文件存储：使用二进制格式</li><li>删除记录：使用特殊的已删除标记代替 value，进行插入</li><li>崩溃恢复：可以从文件中直接还原出 hashmap，可能较慢；也可以在磁盘上保留 hashmap 的快照，减少还原时间</li><li>写入时崩溃：使用校验位，确保不会认可不完整的数据</li><li>并发控制：单线程追加，多线程读</li><li>优点：写入快，并发和崩溃恢复简单，并发能力强</li><li>缺点：哈希表需要全部放在内存，区间查询效率差（WHERE BETWEEN）</li></ol><h3 id=sstable-和-lsm-tree>SSTable 和 LSM-Tree
<a class=anchor href=#sstable-%e5%92%8c-lsm-tree>#</a></h3><p>在上述基础上，对于压缩合并后的段文件，对 key 进行排序；对正在写入的文件，使用平衡二叉树。LevelDB、RocksDB、HBase、Cassandra 都是基于 SSTable。SSTable术语来自 BigTable 论文。整个方法也称 LSM-Tree（Log-Structured Merge Tree)</p><ol><li>合并段变成归并，更加高效</li><li>段文件的 hashmap 可以是稀疏的，因为可以通过排序来查找，稀疏程度参考文件块，文件块可以进行通用压缩（区分于上述的取最晚操作，而是 gzip 等通用压缩）</li><li>平衡二叉树变成已排序段文件（SS-Table）的效率较高（中序遍历）</li><li>为防止崩溃时正在写入的文件丢失，可以双写到二叉树和日志，日志用于恢复，二叉树用于查询。</li><li>当 key 完全不存在时，需要访问所有的 hashmap，可能有多次磁盘 IO；为此使用 bloomfilter 做预过滤</li><li>压缩合并的方式：LevelDB 和 RocksDB 使用分层压缩，旧数据采用更高的压缩等级；HBase 使用大小分级压缩，较新的段文件较小，被合并到较旧、较大的段文件去。Cassandra 两种都支持。TODO</li></ol><h3 id=b-树>B 树
<a class=anchor href=#b-%e6%a0%91>#</a></h3><p>关系型数据库的标准实现，思路是 1. 每个节点是一个磁盘块 2. 让树尽量平衡且矮。</p><p>B 树的可靠性保证比较复杂，因为它是直接替换磁盘上的文件，而非简单的追加的。如果是在节点分裂的过程中发生崩溃就更加危险。一般采用 WAL（Write-Ahead Log）先记录每一次 B 树的修改，再进行真正的改动。崩溃后可以从 WAL 恢复 B 树的状态。</p><ol><li>有些引擎不使用 WAL，而是用 copy-on-write 的方式更新节点。这样的缺点是，除了节点本身之外还要更新一系列指针；优点是崩溃恢复更容易，且比较容易支持并发事务。</li><li>对于比较高层的节点并不需要存储完整的 key，而是给出能够描述子节点范围的部分就可以，有利于提高分叉数</li><li>考虑到范围查询的需要，很多引擎尽量把相邻的节点在磁盘上相邻存储。但这一点随着数据量变大更难以保持，LSM-Tree 则比较容易（非原地归并）</li><li>考虑到范围查询，可以增加兄弟节点指针</li><li>一些变体，如分形树，借鉴了日志结构的思路来减少寻道</li></ol><h3 id=b-树和-lsm-树对比>B 树和 LSM 树对比
<a class=anchor href=#b-%e6%a0%91%e5%92%8c-lsm-%e6%a0%91%e5%af%b9%e6%af%94>#</a></h3><p>整体来看，LSM 树写入更快，B 树读取更快。</p><ul><li>B 树的每一次写都需要至少修改 WAL 和整个页，写放大一般比 LSM 大，且随机读写较多。</li><li>LSM 树的数据结构更紧凑、压缩率更高，且碎片空间较少。B 树可能有很多页只存储了少量数据，造成浪费。</li><li>现代 SSD 可能将随机读写在内部转化为顺序读写，但写放大和碎片的问题不能被完全抹除。</li><li>LSM 树的后台压缩合并过程可能占用磁盘带宽，从而影响同时进行的读写操作，造成 LSM 树的高分位数读写延迟较高，而 B 树的性能比较稳定</li><li>LSM 树存储的数据量越大，压缩合并的成本就越高，用于实时读写的磁盘带宽就越少。</li><li>如果写入速度超过了压缩的速度，LSM 树的段文件就会越来越多。一般 LSM 树的数据库并不限制写入速度，因此需要额外监控。</li><li>B 树比较容易加锁，事务隔离可以直接实现到 B 树上。LSM 的写入有多副本，不容易隔离。</li></ul><h3 id=其他索引>其他索引
<a class=anchor href=#%e5%85%b6%e4%bb%96%e7%b4%a2%e5%bc%95>#</a></h3><p>上述只考虑了主键索引。除此之外，两种索引都可以用来实现二级索引。和主键索引不同，二级索引的 key 经常重复，这时可以用拉链法或在 key 上加入其他标记，然后用范围查询来实现。</p><h4 id=聚集索引>聚集索引
<a class=anchor href=#%e8%81%9a%e9%9b%86%e7%b4%a2%e5%bc%95>#</a></h4><p>无论主键还是二级索引，索引的 key 是要查找的值，value 可以是行本身，或者指向实际行的指针，实际行位于堆文件中。堆文件可以是追加的，也可以是替换的（记录下被删除的位置，下次再填入）。这样，当存在二级索引时，就不需要复制数据。在 update 数据时，如果新值的大小不大于旧值，就可以原地替换，非常高效；如果大于旧值，就需要进行一系列移动并更新所有索引，或者直接在旧位置留下一个指向新位置的指针。</p><p>如果索引的 value 是行本身而不是指向堆文件的指针，就是聚集索引。在 InnoDB 中，主键永远是聚集索引，二级索引引用的是主键，而非直接指向堆文件。在另一些实现中，可能主键和二级索引都不是聚集的，而是把数据存在散乱的堆文件中。</p><p>也可以只在索引中保存部分列，称为覆盖索引，介于聚集索引和非聚集索引之间。如果查询的列是这些列的子集，就可以只利用索引返回结果，称索引覆盖了这个查询。例如，对于多个字段的索引，将前面的字段放在索引内，后面的字段只保存指针。</p><p>当然，聚集和覆盖索引加快了查询速度，提高了数据冗余，占用更多空间，且提高了事务的复杂性。</p><h4 id=多列索引>多列索引
<a class=anchor href=#%e5%a4%9a%e5%88%97%e7%b4%a2%e5%bc%95>#</a></h4><p>上面的索引都只有一个 key 对应一个 value。但如果查询包括了多个列的范围查询，就不能满足，常见的是地理数据中需要同时过滤经度和纬度。一种选择是使用空间填充曲线（Space-filling curve）将两个列转化为单个列，或者使用专门适用于空间的索引结构，如 R 树。</p><h4 id=全文搜索和模糊索引>全文搜索和模糊索引
<a class=anchor href=#%e5%85%a8%e6%96%87%e6%90%9c%e7%b4%a2%e5%92%8c%e6%a8%a1%e7%b3%8a%e7%b4%a2%e5%bc%95>#</a></h4><p>Lucene 的做法是搜索在某个编辑距离内的文本，使用类似 SSTable 的方法，内存中的索引不再是稀疏的 key，而是一系列 DFA，类似字典树。这个自动机可以转化为 Levenshtein 自动机。</p><h4 id=在内存中保存所有内容>在内存中保存所有内容
<a class=anchor href=#%e5%9c%a8%e5%86%85%e5%ad%98%e4%b8%ad%e4%bf%9d%e5%ad%98%e6%89%80%e6%9c%89%e5%86%85%e5%ae%b9>#</a></h4><p>典型例子是 Memcached。也有在内存中实现的关系数据库。重启后也可以从磁盘中恢复状态，但运行时读取完全靠内存服务。写入磁盘一般是追加日志，除了持久化以外还方便备份、分析等。</p><p>需要注意的是，内存数据库的性能优势并不来自内存读写，因为当数据较小时，磁盘数据库也可以几乎不访问磁盘。其优势主要来自序列化的开销。</p><p>此外，内存数据库可以提供一些磁盘难以实现的功能，如 Redis 的优先队列和 Set。</p><p>内存数据库也可以反缓存到磁盘，和磁盘数据库的区别是，被保存到磁盘的单位可以是行，而非页，因此也可能有一定性能优势。</p><p>Optane 等非易失性存储（Non-volatile Memory）为内存数据库带来更多的想象空间。</p><h2 id=事务处理与分析处理>事务处理与分析处理
<a class=anchor href=#%e4%ba%8b%e5%8a%a1%e5%a4%84%e7%90%86%e4%b8%8e%e5%88%86%e6%9e%90%e5%a4%84%e7%90%86>#</a></h2><p>事务这个名词并不等同于 ACID，它实际上指的是 OLTP 的典型行为，即少量数据的低延迟读取和写入。与之对应的是分析处理，即 OLAP。</p><p>OLAP 数据一般都是关系模型，因为 SQL 是分析的强力工具。</p><h3 id=星型模式--维度建模--雪花模式>星型模式 / 维度建模 / 雪花模式
<a class=anchor href=#%e6%98%9f%e5%9e%8b%e6%a8%a1%e5%bc%8f--%e7%bb%b4%e5%ba%a6%e5%bb%ba%e6%a8%a1--%e9%9b%aa%e8%8a%b1%e6%a8%a1%e5%bc%8f>#</a></h3><p>在维度建模中，通常有一个事实表加上多个维度表，每个维度表达了 5W1H 信息。日期和时间也被建立维度表，从而进行日期维度的分析，如区分假期和平日的区别。</p><p>在星型模式的每个维度表基础上再增加维度表就是雪花模式，例如产品表可以外键到另一个品牌维度表等。</p><h2 id=列存>列存
<a class=anchor href=#%e5%88%97%e5%ad%98>#</a></h2><p>OLTP 和文档数据库中，每一行通常被相邻存放。在 OLAP 维度建模的场景下，每一个表通常非常宽，但每次只访问其中的几个列。这个模型和关系数据库相匹配，但非关系数据也可以使用，例如 Parquet 也支持文档数据存储结构。</p><p>因为相同的列被放在一起，它们的数据相似性也变高，所以压缩率也大于行存。</p><h3 id=列压缩>列压缩
<a class=anchor href=#%e5%88%97%e5%8e%8b%e7%bc%a9>#</a></h3><p>列压缩的一个办法是，把枚举值变成 bitmap，那么当计算 <code>IN (a, b, c)</code> 的查询时，只需要按位与再和 0 比较即可。</p><p>对于有 n 个枚举值的数据，每一个单元格的数据大小就是 n 个 bit。显然，仅仅这样存储的数据中会有很多 0。此时对于每个枚举值，再使用 run-length code 压缩，从而获得很高的压缩率和查询性能。</p><table><thead><tr><th></th><th>A</th><th>B</th><th>C</th><th>D</th></tr></thead><tbody><tr><td>0</td><td>1</td><td></td><td></td><td></td></tr><tr><td>1</td><td></td><td></td><td>1</td><td></td></tr><tr><td>2</td><td></td><td></td><td>1</td><td></td></tr><tr><td>3</td><td></td><td></td><td>1</td><td></td></tr><tr><td>4</td><td></td><td>1</td><td></td><td></td></tr><tr><td>5</td><td></td><td></td><td></td><td>1</td></tr></tbody></table><p>上述数据，按照对每个枚举值从上到下 run-length code 的方式编码。因为对每个枚举值，取值只有 0 和 1，所以可以省略，只记录每一段的长度：</p><blockquote><p>A, 0, 1, 5; B, 4, 1, 1; C, 1 3 2; D, 5 1</p></blockquote><h3 id=内存带宽和矢量化>内存带宽和矢量化
<a class=anchor href=#%e5%86%85%e5%ad%98%e5%b8%a6%e5%ae%bd%e5%92%8c%e7%9f%a2%e9%87%8f%e5%8c%96>#</a></h3><p>对大数据量的高速处理，需要考虑内存带宽、缓存命中率和 SIMD 指令的利用率。</p><p>列压缩使得数据可以被放在 L1 缓存中用循环来处理，而避免了条件跳转和函数调用；使用按位操作运算符，使得 SIMD 可以比较容易使用。</p><h3 id=列存与排序>列存与排序
<a class=anchor href=#%e5%88%97%e5%ad%98%e4%b8%8e%e6%8e%92%e5%ba%8f>#</a></h3><p>虽然数据是按列存储的，仍然需要按行排序，否则无法和主键相关联。排序的依据可以是多个列，例如把日期作为第一排序，对日期相同的可以用其他列来排序。当然，过多排序列将失去排序的作用。</p><p>排序也使得 run-length code 的压缩率更高。</p><p>另一种思路是，既然分布式数据库需要将数据备份存储，就可以在不同的副本中使用不同的排序列。当数据没有丢失时，就可以在不同的列上得到性能优势。</p><h3 id=列存的写操作>列存的写操作
<a class=anchor href=#%e5%88%97%e5%ad%98%e7%9a%84%e5%86%99%e6%93%8d%e4%bd%9c>#</a></h3><p>OLAP 常见的是只读操作，但上面的优化都会使得写操作更加复杂。一个简单的改进办法是 LSM-Tree。</p><h3 id=聚合数据-cube-与物化视图>聚合：数据 CUBE 与物化视图
<a class=anchor href=#%e8%81%9a%e5%90%88%e6%95%b0%e6%8d%ae-cube-%e4%b8%8e%e7%89%a9%e5%8c%96%e8%a7%86%e5%9b%be>#</a></h3><p>将常见的聚合操作预先计算缓存起来，即物化视图。视图是指将计算逻辑固化，物化是指其将数据缓存了起来，而不仅仅保存了逻辑。</p><p>当数据发生变化时，物化视图也需要随之更新，降低写入性能。所以总的来说是否提升性能需要考虑到实际的查询情况。</p><p>数据 CUBE 是不同维度聚合的物化视图的集合。一个简单的二维数据 CUBE 就是数据透视表。事实表一般有不止两个维度，因此数据是一个高维超立方体。</p><h1 id=数据编码与演化>数据编码与演化
<a class=anchor href=#%e6%95%b0%e6%8d%ae%e7%bc%96%e7%a0%81%e4%b8%8e%e6%bc%94%e5%8c%96>#</a></h1><h2 id=数据编码格式>数据编码格式
<a class=anchor href=#%e6%95%b0%e6%8d%ae%e7%bc%96%e7%a0%81%e6%a0%bc%e5%bc%8f>#</a></h2><p>通常数据同时存在于内存中和文件/网络中，需要在这两种形式间互相转化，即编解码。</p><h3 id=language-specific-formats>Language-Specific formats
<a class=anchor href=#language-specific-formats>#</a></h3><p>Java 有 Serializable，Ruby 有 Marshal，Python 有 Pickle，此外还有第三方的 Kryo 等。但它们的问题是：</p><ul><li>仅适用于一个语言</li><li>经常包含能够生成一个类的实例的功能，可能带来安全问题</li><li>前后兼容能力一般不好</li><li>性能效率通常不好</li></ul><h3 id=jsonxmlcsv-与其二进制变体>JSON、XML、CSV 与其二进制变体
<a class=anchor href=#jsonxmlcsv-%e4%b8%8e%e5%85%b6%e4%ba%8c%e8%bf%9b%e5%88%b6%e5%8f%98%e4%bd%93>#</a></h3><ul><li>XML 和 CSV 无法区分数字和数字字符串，遇到浮点数边界时问题尤其明显</li><li>不支持二进制</li><li>XML 有一些 Schema 规范，但都很复杂，正确实现其解码比较困难</li><li>CSV 没有模式，在格式变化时的前后兼容很难实现，很多实现也没有很好处理转义</li></ul><p>XML 和 JSON 都有一些二进制变体，如 BSON，MessagePack，其中一些扩展了其数字和二进制的能力，但都没有规定模式，因此字段名仍然需要保存在编码后的每一条数据中。</p><h3 id=thrift-与-protobuf>Thrift 与 ProtoBuf
<a class=anchor href=#thrift-%e4%b8%8e-protobuf>#</a></h3><p>Thrift 和 ProtoBuf 的 IDL 和二进制都比较相似。共同特点是二进制数据中有字段类型、字段编号和字段长度，但没有字段名，字段名由 IDL 和基于 IDL 生成的各种语言的编解码代码确定。字段都区分 Optional 和 Required，通过字段编号来支持前后兼容和 Schema 变化。</p><p>当旧代码读取新数据时，会直接忽略新的字段。当新代码读取旧数据时，不能缺少 required 字段，但可以缺少 optional 字段。</p><p>当数据类型变化时，可能造成精度损失。</p><p>Thrift 支持列表和列表嵌套。</p><p>Protobuf 不支持列表，只能将字段标为 Repeated。如果一个字段从非 Repeated 变成了 Repeated，那么读取旧数据的新代码只能看到一个数据，读取新数据的旧代码只能看到最后一个数据。</p><h3 id=avro>Avro
<a class=anchor href=#avro>#</a></h3><p>Avro 解决的是 Thrift 和 Protobuf 不适合 Hadoop 使用的问题，IDL 可以用 JSON 表示以方便机器读取。Avro 没有字段类型和编号的标记，完全由读写模式确定。读写模式不必完全一样，只需要互相兼容。读取数据时，同时提供读模式和写模式，用写模式将数据取出，再转换为读模式，二者之间用字段名关联，从而允许字段位置变化或增减字段。</p><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;type&#34;</span> : <span style=color:#ba2121>&#34;record&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;name&#34;</span> : <span style=color:#ba2121>&#34;userInfo&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;namespace&#34;</span> : <span style=color:#ba2121>&#34;my.example&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>&#34;fields&#34;</span> : [{<span style=color:green;font-weight:700>&#34;name&#34;</span> : <span style=color:#ba2121>&#34;username&#34;</span>, 
</span></span><span style=display:flex><span>                <span style=color:green;font-weight:700>&#34;type&#34;</span> : <span style=color:#ba2121>&#34;string&#34;</span>, 
</span></span><span style=display:flex><span>                <span style=color:green;font-weight:700>&#34;default&#34;</span> : <span style=color:#ba2121>&#34;NONE&#34;</span>},
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>                {<span style=color:green;font-weight:700>&#34;name&#34;</span> : <span style=color:#ba2121>&#34;age&#34;</span>, 
</span></span><span style=display:flex><span>                <span style=color:green;font-weight:700>&#34;type&#34;</span> : <span style=color:#ba2121>&#34;int&#34;</span>, 
</span></span><span style=display:flex><span>                <span style=color:green;font-weight:700>&#34;default&#34;</span> : <span style=color:#666>-1</span>},
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>                {<span style=color:green;font-weight:700>&#34;name&#34;</span> : <span style=color:#ba2121>&#34;state_province&#34;</span>, 
</span></span><span style=display:flex><span>                <span style=color:green;font-weight:700>&#34;type&#34;</span> : <span style=color:#ba2121>&#34;string&#34;</span>, 
</span></span><span style=display:flex><span>                <span style=color:green;font-weight:700>&#34;default&#34;</span> : <span style=color:#ba2121>&#34;NONE&#34;</span>},
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>                {<span style=color:green;font-weight:700>&#34;name&#34;</span> : <span style=color:#ba2121>&#34;country&#34;</span>, 
</span></span><span style=display:flex><span>                <span style=color:green;font-weight:700>&#34;type&#34;</span> : <span style=color:#ba2121>&#34;string&#34;</span>, 
</span></span><span style=display:flex><span>                <span style=color:green;font-weight:700>&#34;default&#34;</span> : <span style=color:#ba2121>&#34;NONE&#34;</span>},
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>                {<span style=color:green;font-weight:700>&#34;name&#34;</span> : <span style=color:#ba2121>&#34;zip&#34;</span>, 
</span></span><span style=display:flex><span>                <span style=color:green;font-weight:700>&#34;type&#34;</span> : <span style=color:#ba2121>&#34;string&#34;</span>, 
</span></span><span style=display:flex><span>                <span style=color:green;font-weight:700>&#34;default&#34;</span> : <span style=color:#ba2121>&#34;NONE&#34;</span>}]
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>如果读模式里有某个字段，写模式中没有（即要读取的数据中没有），则要求读模式中的这个字段有默认值。可以在 schema 中指定，也可以把字段定义为 <code>union{null, long}</code> 从而用 NULL 当默认值。因此 Avro 的字段无需区分 Required 和 Optional。</p><p>总的来看：</p><ul><li>如果新的 reader 增加了一个没有默认值的字段，就无法读取旧 writer 写的数据</li><li>如果新的 writer 删除了一个没有默认值的字段，就无用旧 reader 读这个数据</li><li>如果新的 writer 给 union 类型增加了分枝，就无法用旧 reader 读</li><li>如果新 reader 更改了字段名，可以通过 alias 解决；但如果新 writer 更改了字段名，旧 reader 并不知道新的字段名是什么，所以无法读取</li></ul><p>可以看到，Avro 在读取数据的时候，需要额外知道 writer 使用的 schema 是什么。注意到，很多时候 schema 定义可能比一行数据本身还要大。因此，Avro 适用于：</p><ol><li>Hadoop 等场景，有数百万行 schema 相同的数据，schema 本身的大小变得不值一提，可以放在数据头部</li><li>在每一行数据开头带上 writer 的版本号，reader 侧另外记录每个版本号对应的 schema。</li><li>建立连接时先确定 schema，之后都用这个 schema 来传输大量文件。</li></ol><p>Avro 同时支持代码生成和动态解析两种方式。</p><h3 id=动态模式--模式的优点>动态模式 / 模式的优点
<a class=anchor href=#%e5%8a%a8%e6%80%81%e6%a8%a1%e5%bc%8f--%e6%a8%a1%e5%bc%8f%e7%9a%84%e4%bc%98%e7%82%b9>#</a></h3><p>Avro 不通过字段的编号来确定字段，而是把 schema 直接带上。这样的好处是，当数据的结构发生变化时，使用 Thrift 或 ProtoBuf 需要手动根据编号来改动 schema、再生成编解码代码、再编译，而 Avro 直接生成一个新的 schema（JSON 格式，可以比较方便地用机器生成）。并且，只要不改变字段名，就可以比较好地前后兼容。</p><p>相应地，使用代码生成再编译的方式，产生的编解码代码通常性能更好，而且可以在编译期进行检查，确保某个数据只要能够被解码，就可以正确地操作。</p><p>XML 和 JSON 有一些 schema 实现，但通常都更加复杂。例如，其中经常包括要求某个字符串字段符合某个正则表达式、要求某个整数字段在某个范围内的限制。相比之下，Thrift 这类二进制编码在这方面要简单得多。另外，数据库的 ODBC 或 JDBC Driver 经常使用自己的数据编解码格式。二进制编码的优势：</p><ul><li>通常比二进制变体的 JSON 更紧凑</li><li>Schema 本身是有价值的文档</li><li>可以在部署之前检查兼容性</li><li>对静态类型语言+代码生成的情况，可以进行类型检查。</li></ul><h2 id=数据流格式>数据流格式
<a class=anchor href=#%e6%95%b0%e6%8d%ae%e6%b5%81%e6%a0%bc%e5%bc%8f>#</a></h2><h3 id=通过数据库>通过数据库
<a class=anchor href=#%e9%80%9a%e8%bf%87%e6%95%b0%e6%8d%ae%e5%ba%93>#</a></h3><p>访问同一个数据库的不同进程可能正在运行不同版本 schema 的代码，如果已经用新 schema 写入过，旧代码再写入同一行数据，对于旧代码中不存在的字段，理想的行为是保持不变。在使用 ORM 的时候需要注意这一点。</p><p>在数据库中，数据比代码更加长久，经常可能存在数年前的数据。大部分关系数据库支持以常数代价增加一个全为空的新列，Linkedin 的文档数据库 Espresso 使用 Avro 存储并支持其演化规则。因此，虽然数据库底层可能存在各个版本的数据（例如，数年前的数据可能比现在的数据少很多个列），但从用户视角它们的模型是一样的。</p><p>归档存储时，无论数据编码是何时的形式，在归档中通常都用最新的编码。</p><h3 id=通过-rest--rpc>通过 REST / RPC
<a class=anchor href=#%e9%80%9a%e8%bf%87-rest--rpc>#</a></h3><p>在 SOA（Service-Oriented Architecture）或称微服务的架构下，预期每个服务可以由单独的团队维护，因此新旧版本的代码经常需要一起运行。</p><p>Web 服务不仅用于 Web：</p><ul><li>客户端，浏览器，JS Web 应用程序</li><li>同一组织的内部调用（中间件）</li><li>不同组织互相调用（如支付）</li></ul><p>REST 的基本思路是，使用 URL 来标识资源，用 HTTP 的身份认证、缓存控制、内容协商等功能，通常基于 JSON。</p><p>SOAP 是基于 XML 的协议，避免使用 HTTP 功能，而是使用 <code>ws-</code> 系列功能。因为使用 XML，所以严重依赖代码生成、IDE 等，且不同厂商的实现之间兼容性不一致。</p><p>RPC 曾有多种历史实现：Enterprise JavaBeans 和 RMI 仅限于 Java，DCOM 仅限于微软平台，CORBA 过于复杂且没有前后兼容能力。本质上，网络调用和本地调用本就存在一定的差异：</p><ol><li>本地函数是可预测的，而远程调用可能由于网络故障、远端运算速度都受影响，需要有重试、超时等机制</li><li>本地函数要么返回结果、要么抛异常、要么陷入阻塞；而远程调用超时，我们无法确定远端是否收到并处理了请求，只是回复没有收到。再考虑到重试，需要提供幂等性。</li><li>每次调用本地函数的时间比较稳定，远程调用则波动很大</li><li>对于大对象，本地调用可以传递指针共用内存，远程调用需要编解码</li><li>RPC 可以用不同语言来实现，可能带来复杂的实现，例如不同语言对大整数的处理不尽相同。</li></ol><p>REST 其中一个吸引人之处在于，它并不试图隐藏自己是网络调用的事实。尽管如此，很多 RPC 框架仍然尝试在 REST 之上实现。</p><p>上面的例子中，Thrift 和 Avro 有 RPC 实现，ProtoBuf 有 gRPC 等。新一代的 RPC 框架一般不再试图和本地函数调用混淆，例如使用 Futures 来包装返回结果。gRPC 还支持流，一些框架还提供了服务发现。</p><p>尽管如此，因为 REST 更方便调试，常见的方式是在组织内部使用 RPC，对外 API 使用 REST。</p><p>在 RPC 的数据编码演化中，一个简化的假设是所有服务端先更新，客户端后更新。于是，请求需要向后兼容，相应需要向前兼容。对提供给外部的 API，很难强迫调用方升级，经常直接维护多个版本。标记版本可以基于 API Token+管理平台，或者在 URL 和 header 里说明。</p><h3 id=通过消息队列>通过消息队列
<a class=anchor href=#%e9%80%9a%e8%bf%87%e6%b6%88%e6%81%af%e9%98%9f%e5%88%97>#</a></h3><p>和直接 RPC 相比，消息队列的优势：</p><ol><li>当接收方不可用或过载，可以缓冲请求</li><li>可以自动重试，避免请求丢失</li><li>避免依赖固定 IP</li><li>可以将一条消息发给多个接收方</li><li>在逻辑上将发送方和接收方分离</li></ol><p>相应地，消息队列一般是单向的。消费者可以把数据发送到其他队列或回复队列。消息队列本身对数据 schema 一般不会强制，可以使用任意的编解码方式。</p><p>Actor 模型原本是用于单个进程并发的模型，通过封装 Actor 和消息传递避免竞争条件、锁和死锁等问题。在分布式 Actor 中，不同的 Actor 部署在不同的节点上。无论两个 Actor 是否在同一个节点上，都采用相同的编解码方式来传递消息，模型已经假定了消息丢失的情况，无需额外考虑。不过，对 Actor 的滚动升级仍然需要考虑前后兼容性。</p><ul><li>Akka 使用 Java 的内置序列化，不提供前后兼容性，但可以用 ProtoBuf 等来替代从而获得兼容</li><li>Orleans 同理，除了使用其他的序列化方式之外，也可以新建一个集群，将流量逐渐切换。</li><li>Erlang OTP 中，滚动升级很难实现。</li></ul></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#数据存储与检索>数据存储与检索</a><ul><li><a href=#数据结构>数据结构</a><ul><li><a href=#哈希索引>哈希索引</a></li><li><a href=#sstable-和-lsm-tree>SSTable 和 LSM-Tree</a></li><li><a href=#b-树>B 树</a></li><li><a href=#b-树和-lsm-树对比>B 树和 LSM 树对比</a></li><li><a href=#其他索引>其他索引</a><ul><li><a href=#聚集索引>聚集索引</a></li><li><a href=#多列索引>多列索引</a></li><li><a href=#全文搜索和模糊索引>全文搜索和模糊索引</a></li><li><a href=#在内存中保存所有内容>在内存中保存所有内容</a></li></ul></li></ul></li><li><a href=#事务处理与分析处理>事务处理与分析处理</a><ul><li><a href=#星型模式--维度建模--雪花模式>星型模式 / 维度建模 / 雪花模式</a></li></ul></li><li><a href=#列存>列存</a><ul><li><a href=#列压缩>列压缩</a></li><li><a href=#内存带宽和矢量化>内存带宽和矢量化</a></li><li><a href=#列存与排序>列存与排序</a></li><li><a href=#列存的写操作>列存的写操作</a></li><li><a href=#聚合数据-cube-与物化视图>聚合：数据 CUBE 与物化视图</a></li></ul></li></ul></li><li><a href=#数据编码与演化>数据编码与演化</a><ul><li><a href=#数据编码格式>数据编码格式</a><ul><li><a href=#language-specific-formats>Language-Specific formats</a></li><li><a href=#jsonxmlcsv-与其二进制变体>JSON、XML、CSV 与其二进制变体</a></li><li><a href=#thrift-与-protobuf>Thrift 与 ProtoBuf</a></li><li><a href=#avro>Avro</a></li><li><a href=#动态模式--模式的优点>动态模式 / 模式的优点</a></li></ul></li><li><a href=#数据流格式>数据流格式</a><ul><li><a href=#通过数据库>通过数据库</a></li><li><a href=#通过-rest--rpc>通过 REST / RPC</a></li><li><a href=#通过消息队列>通过消息队列</a></li></ul></li></ul></li></ul></nav></div></aside></main></body></html>