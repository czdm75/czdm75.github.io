<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Spark SQL Programming #  Basic #  DataFrame #  # standalone from pyspark.sql import SparkSession spark = SparkSession \  .builder \  .appName(&#34;Python Spark SQL basic example&#34;) \  .config(&#34;spark.some.config.option&#34;, &#34;some-value&#34;) \  .getOrCreate()  # in pyspark repl spark = SQLContext(sc)  # json file content: # {&#34;name&#34;:&#34;Michael&#34;} # {&#34;name&#34;:&#34;Andy&#34;, &#34;age&#34;:30} # {&#34;name&#34;:&#34;Justin&#34;, &#34;age&#34;:19} df = spark.read.json(&#34;examples/src/main/resources/people.json&#34;) # missing value is null df.show() df.printSchema()  df.select(&#34;name&#34;).show() # prints a column of data df."><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content="Spark SQL Programming"><meta property="og:description" content="Spark SQL Programming #  Basic #  DataFrame #  # standalone from pyspark.sql import SparkSession spark = SparkSession \  .builder \  .appName(&#34;Python Spark SQL basic example&#34;) \  .config(&#34;spark.some.config.option&#34;, &#34;some-value&#34;) \  .getOrCreate()  # in pyspark repl spark = SQLContext(sc)  # json file content: # {&#34;name&#34;:&#34;Michael&#34;} # {&#34;name&#34;:&#34;Andy&#34;, &#34;age&#34;:30} # {&#34;name&#34;:&#34;Justin&#34;, &#34;age&#34;:19} df = spark.read.json(&#34;examples/src/main/resources/people.json&#34;) # missing value is null df.show() df.printSchema()  df.select(&#34;name&#34;).show() # prints a column of data df."><meta property="og:type" content="article"><meta property="og:url" content="/distributed/spark-sql/"><meta property="article:section" content="distributed"><title>Spark SQL Programming | czdm75 Blog</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.97cfda4f5e3c9fa49a2bf8d401f4ddc0eec576c99cdcf6afbec19173200c37db.css><script defer src=/flexsearch.min.js></script>
<script defer src=/en.search.min.60f5c0362a1b15384bf6fbb748ad6fb49d79819ad4313fc4618ffb6d1f645f15.js></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>czdm75 Blog</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><input type=checkbox id=section-25b8c894ab868b34ecd6cce0ce4c79c7 class=toggle>
<label for=section-25b8c894ab868b34ecd6cce0ce4c79c7 class="flex justify-between"><a href=/cs/>Computer Science</a></label><ul><li><a href=/cs/linux-io-multiplex/>Linux IO Multiplexing</a></li></ul></li><li><input type=checkbox id=section-d5643d9c227c9fc0bfaa81dc6e0249af class=toggle checked>
<label for=section-d5643d9c227c9fc0bfaa81dc6e0249af class="flex justify-between"><a href=/distributed/>Distributed Systems</a></label><ul><li><a href=/distributed/hadoop-basic/>Hadoop Basic Concepts</a></li><li><a href=/distributed/spark-rdd/>Spark RDD Programming</a></li><li><a href=/distributed/spark-sql/ class=active>Spark SQL Programming</a></li></ul></li><li><a href=/notes/>Notes on Books</a><ul><li><input type=checkbox id=section-f9c54ee28ad742882651b9afb106f923 class=toggle>
<label for=section-f9c54ee28ad742882651b9afb106f923 class="flex justify-between"><a href=/notes/core-java-impatient/>Core Java for Impatients</a></label><ul><li><a href=/notes/core-java-impatient/1/>1. Basic OOP</a></li><li><a href=/notes/core-java-impatient/2/>2. Interface, Lambda</a></li><li><a href=/notes/core-java-impatient/3/>3. Inheritance, Reflection</a></li><li><a href=/notes/core-java-impatient/4/>4. Exception, Logging</a></li><li><a href=/notes/core-java-impatient/5/>5. Generics</a></li><li><a href=/notes/core-java-impatient/6/>6. Collections, Streams</a></li><li><a href=/notes/core-java-impatient/7/>7. IO, Regexp, Serialization</a></li><li><a href=/notes/core-java-impatient/8/>8. Threading</a></li><li><a href=/notes/core-java-impatient/9/>9. Notations</a></li></ul></li><li><input type=checkbox id=section-9d0fb26a4934bb77406a56b94138590b class=toggle>
<label for=section-9d0fb26a4934bb77406a56b94138590b class="flex justify-between"><a href=/notes/in-depth-jvm/>In-depth Understanding JVM</a></label><ul><li><a href=/notes/in-depth-jvm/gc/>Garbage Collection</a></li><li><a href=/notes/in-depth-jvm/synchronization/>Java Synchronization</a></li><li><a href=/notes/in-depth-jvm/memory-model/>JVM Memory Model</a></li><li><a href=/notes/in-depth-jvm/memory-region/>JVM Memory Regions</a></li><li><a href=/notes/in-depth-jvm/threadlocal-reference/>ThreadLocal and Reference</a></li></ul></li><li><input type=checkbox id=section-4d028229be962782539eef651433109e class=toggle>
<label for=section-4d028229be962782539eef651433109e class="flex justify-between"><a href=/notes/intro-algo/>Introduction to Algorithms</a></label><ul><li><a href=/notes/intro-algo/1/>1. Compexity, Divide</a></li><li><a href=/notes/intro-algo/2/>2. Sorting, Order Statistic</a></li><li><a href=/notes/intro-algo/3/>3. LinkedList, HashTable</a></li><li><a href=/notes/intro-algo/4/>4. BST, Balanced BSTs</a></li><li><a href=/notes/intro-algo/5/>5. Trie-Tree, Extending Data Structures</a></li><li><a href=/notes/intro-algo/6/>6. Dynamic Programming, Greedy, Amortize</a></li><li><a href=/notes/intro-algo/7/>7. B-Tree, Fibonacci Heap, vEB Tree</a></li><li><a href=/notes/intro-algo/8/>8. Graphs</a></li></ul></li><li><input type=checkbox id=section-76be9453a58f37863458b83352d3ff3c class=toggle>
<label for=section-76be9453a58f37863458b83352d3ff3c class="flex justify-between"><a href=/notes/programming-scala/>Programming in Scala</a></label><ul><li><a href=/notes/programming-scala/1/>1. Basics</a></li><li><a href=/notes/programming-scala/2/>2. Functions</a></li><li><a href=/notes/programming-scala/3/>3 .Inheritance, Package, Assertion</a></li><li><a href=/notes/programming-scala/4/>4. Pattern Matching, Collections</a></li><li><a href=/notes/programming-scala/5/>5. Generics, Abstract, Implicits</a></li><li><a href=/notes/programming-scala/6/>6. Collections, Extractor, etc</a></li></ul></li></ul></li><li><input type=checkbox id=section-9784d97422a8bbe41d06f74a08150515 class=toggle>
<label for=section-9784d97422a8bbe41d06f74a08150515 class="flex justify-between"><a href=/pl/>Programming Languages</a></label><ul><li><a href=/pl/java-nio-2/>Java NIO Internal</a></li><li><a href=/pl/java-nio-1/>Java NIO Usage</a></li><li><a href=/pl/lambda/>Lambda Calculus and Y Combinator</a></li><li><a href=/pl/curry/>Scala: Currying, Partially Applied, Partial</a></li><li><a href=/pl/monad/>Scala: Monad, from Scala Perspective</a></li></ul></li></ul><ul><li><a href=https://github.com/czdm75 target=_blank rel=noopener>GitHub</a></li><li><a href=https://themes.gohugo.io/hugo-book/ target=_blank rel=noopener>Theme</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Spark SQL Programming</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#spark-sql-programming>Spark SQL Programming</a><ul><li><a href=#basic>Basic</a><ul><li><a href=#dataframe>DataFrame</a></li><li><a href=#sql-queries>SQL Queries</a></li></ul></li><li><a href=#schema>Schema</a><ul><li><a href=#infering-schema>Infering Schema</a></li><li><a href=#programatically-specifying-the-schema>Programatically Specifying the Schema</a></li><li><a href=#user-defined-functions-udfs>User-defined Functions (UDFs)</a></li><li><a href=#user-defined-aggregate-functions>User-defined Aggregate Functions</a></li></ul></li><li><a href=#data-sources>Data Sources</a><ul><li><a href=#savemode>SaveMode</a></li><li><a href=#save-to-persistent-table>Save to Persistent Table</a></li><li><a href=#hive>Hive</a></li><li><a href=#hive-settings>Hive Settings</a></li></ul></li><li><a href=#pandas>Pandas</a><ul><li><a href=#transforming>Transforming</a></li><li><a href=#pandas-scalar-纯量-udfs>Pandas Scalar (纯量) UDFs</a></li><li><a href=#pandas-grouped-map-udfs>Pandas Grouped Map UDFs</a></li></ul></li><li><a href=#shuffle-hash-join--broadcast-hash-join--sort-merge-join>Shuffle Hash Join / Broadcast Hash Join / Sort Merge Join</a></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=spark-sql-programming>Spark SQL Programming
<a class=anchor href=#spark-sql-programming>#</a></h1><h2 id=basic>Basic
<a class=anchor href=#basic>#</a></h2><h3 id=dataframe>DataFrame
<a class=anchor href=#dataframe>#</a></h3><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#408080;font-style:italic># standalone</span>
</span></span><span style=display:flex><span><span style=color:green;font-weight:700>from</span> <span style=color:#00f;font-weight:700>pyspark.sql</span> <span style=color:green;font-weight:700>import</span> SparkSession
</span></span><span style=display:flex><span>spark <span style=color:#666>=</span> SparkSession \
</span></span><span style=display:flex><span>    <span style=color:#666>.</span>builder \
</span></span><span style=display:flex><span>    <span style=color:#666>.</span>appName(<span style=color:#ba2121>&#34;Python Spark SQL basic example&#34;</span>) \
</span></span><span style=display:flex><span>    <span style=color:#666>.</span>config(<span style=color:#ba2121>&#34;spark.some.config.option&#34;</span>, <span style=color:#ba2121>&#34;some-value&#34;</span>) \
</span></span><span style=display:flex><span>    <span style=color:#666>.</span>getOrCreate()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># in pyspark repl</span>
</span></span><span style=display:flex><span>spark <span style=color:#666>=</span> SQLContext(sc)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># json file content:</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># {&#34;name&#34;:&#34;Michael&#34;}</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># {&#34;name&#34;:&#34;Andy&#34;, &#34;age&#34;:30}</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># {&#34;name&#34;:&#34;Justin&#34;, &#34;age&#34;:19}</span>
</span></span><span style=display:flex><span>df <span style=color:#666>=</span> spark<span style=color:#666>.</span>read<span style=color:#666>.</span>json(<span style=color:#ba2121>&#34;examples/src/main/resources/people.json&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># missing value is null</span>
</span></span><span style=display:flex><span>df<span style=color:#666>.</span>show()
</span></span><span style=display:flex><span>df<span style=color:#666>.</span>printSchema()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df<span style=color:#666>.</span>select(<span style=color:#ba2121>&#34;name&#34;</span>)<span style=color:#666>.</span>show() <span style=color:#408080;font-style:italic># prints a column of data</span>
</span></span><span style=display:flex><span>df<span style=color:#666>.</span>select(df[<span style=color:#ba2121>&#39;name&#39;</span>], df[<span style=color:#ba2121>&#39;age&#39;</span>] <span style=color:#666>+</span> <span style=color:#666>1</span>)<span style=color:#666>.</span>show() <span style=color:#408080;font-style:italic># prints two columns, one of&#39;em is operated</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df<span style=color:#666>.</span>filter(df[<span style=color:#ba2121>&#39;age&#39;</span>] <span style=color:#666>&gt;</span> <span style=color:#666>21</span>)<span style=color:#666>.</span>show
</span></span><span style=display:flex><span>df<span style=color:#666>.</span>groupBy(<span style=color:#ba2121>&#34;age&#34;</span>)<span style=color:#666>.</span>count()<span style=color:#666>.</span>show()
</span></span></code></pre></div><h3 id=sql-queries>SQL Queries
<a class=anchor href=#sql-queries>#</a></h3><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#408080;font-style:italic># temp view</span>
</span></span><span style=display:flex><span>df<span style=color:#666>.</span>createOrReplaceTempView(<span style=color:#ba2121>&#34;people&#34;</span>)
</span></span><span style=display:flex><span>spark<span style=color:#666>.</span>sql(<span style=color:#ba2121>&#34;SELCT * FROM people&#34;</span>)<span style=color:#666>.</span>show()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># global temp view</span>
</span></span><span style=display:flex><span>df<span style=color:#666>.</span>createGlobalTempView(<span style=color:#ba2121>&#34;people&#34;</span>)
</span></span><span style=display:flex><span>spark<span style=color:#666>.</span>newSession()<span style=color:#666>.</span>sql(<span style=color:#ba2121>&#34;SELECT * FROM global_temp.people&#34;</span>)<span style=color:#666>.</span>show()
</span></span></code></pre></div><h2 id=schema>Schema
<a class=anchor href=#schema>#</a></h2><h3 id=infering-schema>Infering Schema
<a class=anchor href=#infering-schema>#</a></h3><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:green;font-weight:700>from</span> <span style=color:#00f;font-weight:700>pyspark.sql</span> <span style=color:green;font-weight:700>import</span> Row
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># reading text file as RDD</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># text file content:</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># Michael, 29</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># Andy, 30</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># Justin, 19</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>lines <span style=color:#666>=</span> sc<span style=color:#666>.</span>textFile(<span style=color:#ba2121>&#34;examples/src/main/resources/people.txt&#34;</span>)
</span></span><span style=display:flex><span>parts <span style=color:#666>=</span> lines<span style=color:#666>.</span>map(<span style=color:green;font-weight:700>lambda</span> l: l<span style=color:#666>.</span>split(<span style=color:#ba2121>&#34;,&#34;</span>))
</span></span><span style=display:flex><span>people <span style=color:#666>=</span> parts<span style=color:#666>.</span>map(<span style=color:green;font-weight:700>lambda</span> p: Row(name<span style=color:#666>=</span>p[<span style=color:#666>0</span>], age<span style=color:#666>=</span><span style=color:green>int</span>([[<span style=color:#666>1</span>]])))  <span style=color:#408080;font-style:italic># RDD[Row]</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>schemaPeople <span style=color:#666>=</span> sql<span style=color:#666>.</span>createDataFrame(people) <span style=color:#408080;font-style:italic># transform into sql dataframe</span>
</span></span><span style=display:flex><span>schemaPeople<span style=color:#666>.</span>createOrReplaceTempView(<span style=color:#ba2121>&#34;people&#34;</span>)
</span></span><span style=display:flex><span>teenNames <span style=color:#666>=</span> spark<span style=color:#666>.</span>sql(<span style=color:#ba2121>&#34;SELECT name FROM people WHERE age &gt;= 13 AND age &lt;= 19&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>teenNames<span style=color:#666>.</span>rdd<span style=color:#666>.</span>map(<span style=color:green;font-weight:700>lambda</span> p: <span style=color:#ba2121>&#34;name: &#34;</span> <span style=color:#666>+</span> p<span style=color:#666>.</span>name)<span style=color:#666>.</span>collect()  <span style=color:#408080;font-style:italic># RDD[String]</span>
</span></span></code></pre></div><h3 id=programatically-specifying-the-schema>Programatically Specifying the Schema
<a class=anchor href=#programatically-specifying-the-schema>#</a></h3><ol><li>Create an RDD of tuple or lists. (like <code>RDD[Tuple2]</code>)</li><li>Create the schema as a <code>StructType</code> matching these tuples</li><li>Apply the schema via <code>createDataFrame</code></li></ol><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:green;font-weight:700>from</span> <span style=color:#00f;font-weight:700>pyspark.sql.types</span> <span style=color:green;font-weight:700>import</span> <span style=color:#666>*</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>people <span style=color:#666>=</span> sc<span style=color:#666>.</span>textFile(<span style=color:#ba2121>&#34;examples/src/main/resources/people.txt&#34;</span>) \
</span></span><span style=display:flex><span>    <span style=color:#666>.</span>map(<span style=color:green;font-weight:700>lambda</span> l: l<span style=color:#666>.</span>split(<span style=color:#ba2121>&#34;,&#34;</span>)) \
</span></span><span style=display:flex><span>    <span style=color:#666>.</span>map(<span style=color:green;font-weight:700>lambda</span> p: (p[<span style=color:#666>0</span>], p[<span style=color:#666>1</span>]<span style=color:#666>.</span>strip()))  <span style=color:#408080;font-style:italic># RDD[(String, String)]</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>schemaString <span style=color:#666>=</span> <span style=color:#ba2121>&#34;name age&#34;</span>  <span style=color:#408080;font-style:italic># cloumn names string</span>
</span></span><span style=display:flex><span>fields <span style=color:#666>=</span> [
</span></span><span style=display:flex><span>    StructField(field_name, StringType(), <span style=color:green;font-weight:700>True</span>)
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>for</span> field_name <span style=color:#a2f;font-weight:700>in</span> schemaString<span style=color:#666>.</span>split()
</span></span><span style=display:flex><span>]  <span style=color:#408080;font-style:italic># One StructField is One field in structType</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># class StructField(name, dataType, nullable=True, metadata=None)</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># DataType is base class of datatypes, e.g. StringType, BinaryType, etc.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>schema <span style=color:#666>=</span> StructType(fields)
</span></span><span style=display:flex><span>schemaPeople <span style=color:#666>=</span> sql<span style=color:#666>.</span>createDataFrame(people, schema)
</span></span></code></pre></div><h3 id=user-defined-functions-udfs>User-defined Functions (UDFs)
<a class=anchor href=#user-defined-functions-udfs>#</a></h3><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>spark<span style=color:#666>.</span>registerFunction(
</span></span><span style=display:flex><span>    <span style=color:#ba2121>&#34;CTOF&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>lambda</span> degreesCelsius: ((degreesCelsius <span style=color:#666>*</span> <span style=color:#666>9.0</span> <span style=color:#666>/</span> <span style=color:#666>5.0</span>) <span style=color:#666>+</span> <span style=color:#666>32.0</span>)
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>spark<span style=color:#666>.</span>sql(
</span></span><span style=display:flex><span>    <span style=color:#ba2121>&#34;SELECT city, CTOF(avgLow) AS avgLowF, CTOF(avgHigh) AS avgHighF FROM citytemps&#34;</span>
</span></span><span style=display:flex><span>)<span style=color:#666>.</span>show()
</span></span></code></pre></div><h3 id=user-defined-aggregate-functions>User-defined Aggregate Functions
<a class=anchor href=#user-defined-aggregate-functions>#</a></h3><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span><span style=color:green;font-weight:700>import</span> <span style=color:#00f;font-weight:700>org.apache.spark.sql.</span><span style=color:#666>{</span><span style=color:#00f;font-weight:700>Row</span><span style=color:#666>,</span> <span style=color:#00f;font-weight:700>SparkSession</span><span style=color:#666>}</span>
</span></span><span style=display:flex><span><span style=color:green;font-weight:700>import</span> <span style=color:#00f;font-weight:700>org.apache.spark.sql.expressions.MutableAggregationBuffer</span>
</span></span><span style=display:flex><span><span style=color:green;font-weight:700>import</span> <span style=color:#00f;font-weight:700>org.apache.spark.sql.expressions.UserDefinedAggregateFunction</span>
</span></span><span style=display:flex><span><span style=color:green;font-weight:700>import</span> <span style=color:#00f;font-weight:700>org.apache.spark.sql.types._</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:green;font-weight:700>object</span> <span style=color:#00f;font-weight:700>MyAverage</span> <span style=color:green;font-weight:700>extends</span> <span style=color:#00f;font-weight:700>UserDefinedAggregateFunction</span> <span style=color:#666>{</span>
</span></span><span style=display:flex><span>  <span style=color:#408080;font-style:italic>// The data type of the input value
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>  <span style=color:green;font-weight:700>def</span> inputSchema<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>StructType</span> <span style=color:#666>=</span> <span style=color:#00f;font-weight:700>StructType</span><span style=color:#666>(</span>
</span></span><span style=display:flex><span>      <span style=color:#00f;font-weight:700>StructField</span><span style=color:#666>(</span><span style=color:#ba2121>&#34;inputColumn&#34;</span><span style=color:#666>,</span> <span style=color:#00f;font-weight:700>LongType</span><span style=color:#666>)</span> <span style=color:green;font-weight:700>:</span><span style=color:#b00040>:</span> <span style=color:#b00040>Nil</span><span style=color:#666>)</span>
</span></span><span style=display:flex><span>  <span style=color:#408080;font-style:italic>// The data type of the aggregation buffer
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>  <span style=color:green;font-weight:700>def</span> bufferSchema<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>StructType</span> <span style=color:#666>=</span> <span style=color:#00f;font-weight:700>StructType</span><span style=color:#666>(</span>
</span></span><span style=display:flex><span>      <span style=color:#00f;font-weight:700>StructField</span><span style=color:#666>(</span><span style=color:#ba2121>&#34;sum&#34;</span><span style=color:#666>,</span> <span style=color:#00f;font-weight:700>LongType</span><span style=color:#666>)</span> <span style=color:green;font-weight:700>:</span><span style=color:#b00040>:</span> <span style=color:#b00040>StructField</span><span style=color:#666>(</span><span>&#34;</span><span style=color:#b00040>count</span><span>&#34;</span><span style=color:#666>,</span> <span style=color:#b00040>LongType</span><span style=color:#666>)</span> <span style=color:green;font-weight:700>:</span><span style=color:#b00040>:</span> <span style=color:#b00040>Nil</span><span style=color:#666>)</span>
</span></span><span style=display:flex><span>  <span style=color:#408080;font-style:italic>// The data type of the returned value
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>  <span style=color:green;font-weight:700>def</span> dataType<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>DataType</span> <span style=color:#666>=</span> <span style=color:#00f;font-weight:700>DoubleType</span>
</span></span><span style=display:flex><span>  <span style=color:#408080;font-style:italic>// Whether this function always returns the same output on the identical input
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>  <span style=color:green;font-weight:700>def</span> deterministic<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Boolean</span> <span style=color:#666>=</span> <span style=color:green;font-weight:700>true</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#408080;font-style:italic>// Initializes the given aggregation buffer. The buffer itself is a `Row` that
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>  <span style=color:#408080;font-style:italic>// in addition to standard methods like retrieving a value at an index
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>  <span style=color:#408080;font-style:italic>// (e.g., get(), getBoolean()), provides the opportunity to update its values.
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>  <span style=color:#408080;font-style:italic>// Note that arrays and maps inside the buffer are still immutable.
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>  <span style=color:green;font-weight:700>def</span> initialize<span style=color:#666>(</span>buffer<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>MutableAggregationBuffer</span><span style=color:#666>)</span><span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Unit</span> <span style=color:#666>=</span> <span style=color:#666>{</span>
</span></span><span style=display:flex><span>    buffer<span style=color:#666>(</span><span style=color:#666>0</span><span style=color:#666>)</span> <span style=color:green;font-weight:700>=</span> <span style=color:#666>0L</span>  <span style=color:#408080;font-style:italic>// sum
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>    buffer<span style=color:#666>(</span><span style=color:#666>1</span><span style=color:#666>)</span> <span style=color:green;font-weight:700>=</span> <span style=color:#666>0L</span>  <span style=color:#408080;font-style:italic>// count
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>  <span style=color:#666>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#408080;font-style:italic>// Updates the given aggregation buffer `buffer` with new input data from `input`
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>  <span style=color:green;font-weight:700>def</span> update<span style=color:#666>(</span>buffer<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>MutableAggregationBuffer</span><span style=color:#666>,</span> input<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Row</span><span style=color:#666>)</span><span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Unit</span> <span style=color:#666>=</span> <span style=color:#666>{</span>
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>if</span> <span style=color:#666>(!</span>input<span style=color:#666>.</span>isNullAt<span style=color:#666>(</span><span style=color:#666>0</span><span style=color:#666>))</span> <span style=color:#666>{</span>
</span></span><span style=display:flex><span>      buffer<span style=color:#666>(</span><span style=color:#666>0</span><span style=color:#666>)</span> <span style=color:green;font-weight:700>=</span> buffer<span style=color:#666>.</span>getLong<span style=color:#666>(</span><span style=color:#666>0</span><span style=color:#666>)</span> <span style=color:#666>+</span> input<span style=color:#666>.</span>getLong<span style=color:#666>(</span><span style=color:#666>0</span><span style=color:#666>)</span>
</span></span><span style=display:flex><span>      buffer<span style=color:#666>(</span><span style=color:#666>1</span><span style=color:#666>)</span> <span style=color:green;font-weight:700>=</span> buffer<span style=color:#666>.</span>getLong<span style=color:#666>(</span><span style=color:#666>1</span><span style=color:#666>)</span> <span style=color:#666>+</span> <span style=color:#666>1</span>
</span></span><span style=display:flex><span>    <span style=color:#666>}</span>
</span></span><span style=display:flex><span>  <span style=color:#666>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#408080;font-style:italic>// Merges two aggregation buffers and stores the updated buffer values back to `buffer1`
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>  <span style=color:green;font-weight:700>def</span> merge<span style=color:#666>(</span>buffer1<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>MutableAggregationBuffer</span><span style=color:#666>,</span> buffer2<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Row</span><span style=color:#666>)</span><span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Unit</span> <span style=color:#666>=</span> <span style=color:#666>{</span>
</span></span><span style=display:flex><span>    buffer1<span style=color:#666>(</span><span style=color:#666>0</span><span style=color:#666>)</span> <span style=color:green;font-weight:700>=</span> buffer1<span style=color:#666>.</span>getLong<span style=color:#666>(</span><span style=color:#666>0</span><span style=color:#666>)</span> <span style=color:#666>+</span> buffer2<span style=color:#666>.</span>getLong<span style=color:#666>(</span><span style=color:#666>0</span><span style=color:#666>)</span>
</span></span><span style=display:flex><span>    buffer1<span style=color:#666>(</span><span style=color:#666>1</span><span style=color:#666>)</span> <span style=color:green;font-weight:700>=</span> buffer1<span style=color:#666>.</span>getLong<span style=color:#666>(</span><span style=color:#666>1</span><span style=color:#666>)</span> <span style=color:#666>+</span> buffer2<span style=color:#666>.</span>getLong<span style=color:#666>(</span><span style=color:#666>1</span><span style=color:#666>)</span>
</span></span><span style=display:flex><span>  <span style=color:#666>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#408080;font-style:italic>// Calculates the final result
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>  <span style=color:green;font-weight:700>def</span> evaluate<span style=color:#666>(</span>buffer<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Row</span><span style=color:#666>)</span><span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Double</span> <span style=color:#666>=</span> buffer<span style=color:#666>.</span>getLong<span style=color:#666>(</span><span style=color:#666>0</span><span style=color:#666>).</span>toDouble <span style=color:#666>/</span> buffer<span style=color:#666>.</span>getLong<span style=color:#666>(</span><span style=color:#666>1</span><span style=color:#666>)</span>
</span></span><span style=display:flex><span><span style=color:#666>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:green;font-weight:700>val</span> df <span style=color:green;font-weight:700>=</span> spark<span style=color:#666>.</span>read<span style=color:#666>.</span>json<span style=color:#666>(</span><span style=color:#ba2121>&#34;examples/src/main/resources/employees.json&#34;</span><span style=color:#666>)</span>
</span></span><span style=display:flex><span>df<span style=color:#666>.</span>createOrReplaceTempView<span style=color:#666>(</span><span style=color:#ba2121>&#34;employees&#34;</span><span style=color:#666>)</span>
</span></span><span style=display:flex><span>spark<span style=color:#666>.</span>udf<span style=color:#666>.</span>register<span style=color:#666>(</span><span style=color:#ba2121>&#34;myAverage&#34;</span><span style=color:#666>,</span> <span style=color:#00f;font-weight:700>MyAverage</span><span style=color:#666>)</span>
</span></span><span style=display:flex><span>spark<span style=color:#666>.</span>sql<span style=color:#666>(</span><span style=color:#ba2121>&#34;SELECT myAverage(salary) as average_salary FROM employees&#34;</span><span style=color:#666>)</span>
</span></span></code></pre></div><p>Or, a type-safe version, using pre-defined case classes as schema:</p><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span><span style=color:green;font-weight:700>import</span> <span style=color:#00f;font-weight:700>org.apache.spark.sql.</span><span style=color:#666>{</span><span style=color:#00f;font-weight:700>Encoder</span><span style=color:#666>,</span> <span style=color:#00f;font-weight:700>Encoders</span><span style=color:#666>,</span> <span style=color:#00f;font-weight:700>SparkSession</span><span style=color:#666>}</span>
</span></span><span style=display:flex><span><span style=color:green;font-weight:700>import</span> <span style=color:#00f;font-weight:700>org.apache.spark.sql.expressions.Aggregator</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:green;font-weight:700>case</span> <span style=color:green;font-weight:700>class</span> <span style=color:#00f;font-weight:700>Employee</span><span style=color:#666>(</span>name<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>String</span><span style=color:#666>,</span> salary<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Long</span><span style=color:#666>)</span>
</span></span><span style=display:flex><span><span style=color:green;font-weight:700>case</span> <span style=color:green;font-weight:700>class</span> <span style=color:#00f;font-weight:700>Average</span><span style=color:#666>(</span><span style=color:green;font-weight:700>var</span> sum<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Long</span><span style=color:#666>,</span> <span style=color:green;font-weight:700>var</span> count<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Long</span><span style=color:#666>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:green;font-weight:700>object</span> <span style=color:#00f;font-weight:700>MyAverage</span> <span style=color:green;font-weight:700>extends</span> <span style=color:#00f;font-weight:700>Aggregator</span><span style=color:#666>[</span><span style=color:#b00040>Employee</span>, <span style=color:#b00040>Average</span>, <span style=color:#b00040>Double</span><span style=color:#666>]</span> <span style=color:#666>{</span>
</span></span><span style=display:flex><span>  <span style=color:#408080;font-style:italic>// Should satisfy the property that any b + zero = b
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>  <span style=color:green;font-weight:700>def</span> zero<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Average</span> <span style=color:#666>=</span> <span style=color:#00f;font-weight:700>Average</span><span style=color:#666>(</span><span style=color:#666>0L</span><span style=color:#666>,</span> <span style=color:#666>0L</span><span style=color:#666>)</span>
</span></span><span style=display:flex><span>  <span style=color:#408080;font-style:italic>// Combine two values to produce a new value. For performance, the function may
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>  <span style=color:#408080;font-style:italic>// modify `buffer` and return it instead of constructing a new object
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>  <span style=color:green;font-weight:700>def</span> reduce<span style=color:#666>(</span>buffer<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Average</span><span style=color:#666>,</span> employee<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Employee</span><span style=color:#666>)</span><span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Average</span> <span style=color:#666>=</span> <span style=color:#666>{</span>
</span></span><span style=display:flex><span>    buffer<span style=color:#666>.</span>sum <span style=color:#666>+=</span> employee<span style=color:#666>.</span>salary
</span></span><span style=display:flex><span>    buffer<span style=color:#666>.</span>count <span style=color:#666>+=</span> <span style=color:#666>1</span>
</span></span><span style=display:flex><span>    buffer
</span></span><span style=display:flex><span>  <span style=color:#666>}</span>
</span></span><span style=display:flex><span>  <span style=color:#408080;font-style:italic>// Merge two intermediate values
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>  <span style=color:green;font-weight:700>def</span> merge<span style=color:#666>(</span>b1<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Average</span><span style=color:#666>,</span> b2<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Average</span><span style=color:#666>)</span><span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Average</span> <span style=color:#666>=</span> <span style=color:#666>{</span>
</span></span><span style=display:flex><span>    b1<span style=color:#666>.</span>sum <span style=color:#666>+=</span> b2<span style=color:#666>.</span>sum
</span></span><span style=display:flex><span>    b1<span style=color:#666>.</span>count <span style=color:#666>+=</span> b2<span style=color:#666>.</span>count
</span></span><span style=display:flex><span>    b1
</span></span><span style=display:flex><span>  <span style=color:#666>}</span>
</span></span><span style=display:flex><span>  <span style=color:#408080;font-style:italic>// Transform the output of the reduction
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>  <span style=color:green;font-weight:700>def</span> finish<span style=color:#666>(</span>reduction<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Average</span><span style=color:#666>)</span><span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Double</span> <span style=color:#666>=</span> reduction<span style=color:#666>.</span>sum<span style=color:#666>.</span>toDouble <span style=color:#666>/</span> reduction<span style=color:#666>.</span>count
</span></span><span style=display:flex><span>  <span style=color:#408080;font-style:italic>// Specifies the Encoder for the intermediate value type
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>  <span style=color:green;font-weight:700>def</span> bufferEncoder<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Encoder</span><span style=color:#666>[</span><span style=color:#b00040>Average</span><span style=color:#666>]</span> <span style=color:green;font-weight:700>=</span> <span style=color:#00f;font-weight:700>Encoders</span><span style=color:#666>.</span>product
</span></span><span style=display:flex><span>  <span style=color:#408080;font-style:italic>// Specifies the Encoder for the final output value type
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span>  <span style=color:green;font-weight:700>def</span> outputEncoder<span style=color:green;font-weight:700>:</span> <span style=color:#b00040>Encoder</span><span style=color:#666>[</span><span style=color:#b00040>Double</span><span style=color:#666>]</span> <span style=color:green;font-weight:700>=</span> <span style=color:#00f;font-weight:700>Encoders</span><span style=color:#666>.</span>scalaDouble
</span></span><span style=display:flex><span><span style=color:#666>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic>// a DataSet[Employee]
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span><span style=color:green;font-weight:700>val</span> ds <span style=color:green;font-weight:700>=</span> spark<span style=color:#666>.</span>read<span style=color:#666>.</span>json<span style=color:#666>(</span><span style=color:#ba2121>&#34;examples/src/main/resources/employees.json&#34;</span><span style=color:#666>).</span>as<span style=color:#666>[</span><span style=color:#b00040>Employee</span><span style=color:#666>]</span>
</span></span><span style=display:flex><span><span style=color:green;font-weight:700>val</span> averageSalary <span style=color:green;font-weight:700>=</span> <span style=color:#00f;font-weight:700>MyAverage</span><span style=color:#666>.</span>toColumn<span style=color:#666>.</span>name<span style=color:#666>(</span><span style=color:#ba2121>&#34;average_salary&#34;</span><span style=color:#666>)</span>
</span></span><span style=display:flex><span>ds<span style=color:#666>.</span>select<span style=color:#666>(</span>averageSalary<span style=color:#666>)</span>
</span></span></code></pre></div><h2 id=data-sources>Data Sources
<a class=anchor href=#data-sources>#</a></h2><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df <span style=color:#666>=</span> spark<span style=color:#666>.</span>read<span style=color:#666>.</span>load(<span style=color:#ba2121>&#34;examples/src/main/resources/users.parquet&#34;</span>)
</span></span><span style=display:flex><span>df<span style=color:#666>.</span>select(<span style=color:#ba2121>&#34;name&#34;</span>, <span style=color:#ba2121>&#34;favorite_color&#34;</span>)<span style=color:#666>.</span>write<span style=color:#666>.</span>save(<span style=color:#ba2121>&#34;namesAndFavColors.parquet&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df <span style=color:#666>=</span> spark<span style=color:#666>.</span>read<span style=color:#666>.</span>load(<span style=color:#ba2121>&#34;examples/src/main/resources/people.json&#34;</span>, <span style=color:green>format</span><span style=color:#666>=</span><span style=color:#ba2121>&#34;json&#34;</span>)
</span></span><span style=display:flex><span>df<span style=color:#666>.</span>select(<span style=color:#ba2121>&#34;name&#34;</span>, <span style=color:#ba2121>&#34;age&#34;</span>)<span style=color:#666>.</span>write<span style=color:#666>.</span>save(<span style=color:#ba2121>&#34;namesAndAges.parquet&#34;</span>, <span style=color:green>format</span><span style=color:#666>=</span><span style=color:#ba2121>&#34;parquet&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df <span style=color:#666>=</span> spark<span style=color:#666>.</span>read<span style=color:#666>.</span>load(
</span></span><span style=display:flex><span>    <span style=color:#ba2121>&#34;examples/src/main/resources/people.csv&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:green>format</span><span style=color:#666>=</span><span style=color:#ba2121>&#34;csv&#34;</span>,
</span></span><span style=display:flex><span>    sep<span style=color:#666>=</span><span style=color:#ba2121>&#34;:&#34;</span>,
</span></span><span style=display:flex><span>    inferSchema<span style=color:#666>=</span><span style=color:#ba2121>&#34;true&#34;</span>,
</span></span><span style=display:flex><span>    header<span style=color:#666>=</span><span style=color:#ba2121>&#34;true&#34;</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>df <span style=color:#666>=</span> spark<span style=color:#666>.</span>sql(<span style=color:#ba2121>&#34;SELECT * FROM parquet.`examples/src/main/resources/users.parquet`&#34;</span>)
</span></span></code></pre></div><h3 id=savemode>SaveMode
<a class=anchor href=#savemode>#</a></h3><ul><li><code>ErrorIfExists</code></li><li><code>Append</code></li><li><code>Overwrite</code></li><li><code>Ignore</code></li></ul><h3 id=save-to-persistent-table>Save to Persistent Table
<a class=anchor href=#save-to-persistent-table>#</a></h3><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df<span style=color:#666>.</span>write<span style=color:#666>.</span>option(<span style=color:#ba2121>&#34;path&#34;</span>, <span style=color:#ba2121>&#34;/some/path&#34;</span>)<span style=color:#666>.</span>saveAsTable(<span style=color:#ba2121>&#34;t&#34;</span>)
</span></span><span style=display:flex><span>df<span style=color:#666>.</span>write<span style=color:#666>.</span>bucketBy(<span style=color:#666>42</span>, <span style=color:#ba2121>&#34;name&#34;</span>)<span style=color:#666>.</span>sortBy(<span style=color:#ba2121>&#34;age&#34;</span>)<span style=color:#666>.</span>saveAsTable(<span style=color:#ba2121>&#34;people_bucketed&#34;</span>)
</span></span><span style=display:flex><span>df<span style=color:#666>.</span>write<span style=color:#666>.</span>partitionBy(<span style=color:#ba2121>&#34;favorite_color&#34;</span>)<span style=color:#666>.</span>format(<span style=color:#ba2121>&#34;parquet&#34;</span>)<span style=color:#666>.</span>save(<span style=color:#ba2121>&#34;namesPartByColor.parquet&#34;</span>)
</span></span></code></pre></div><h3 id=hive>Hive
<a class=anchor href=#hive>#</a></h3><p>For Spark SQL to operate Hive, you need hive jars in classpath of every node and <code>hive-site.xml</code> <code>core-site.xml</code> <code>hdfs-site.xml</code> file in <code>conf/</code> . When not configured by the <code>hive-site.xml</code>, the context automatically creates <code>metastore_db</code> in the current directory and creates a directory configured by <code>spark.sql.warehouse.dir</code>, which defaults to the directory <code>spark-warehouse</code> in the directory the Spark application starts.</p><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>warehouse_location <span style=color:#666>=</span> abspath(<span style=color:#ba2121>&#39;spark-warehouse&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># text file content:</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># 238val_238</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># 86val_86</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># 311val_311</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>spark<span style=color:#666>.</span>sql(<span style=color:#ba2121>&#34;CREATE TABLE IF NOT EXISTS src (key INT, value STRING) USING hive&#34;</span>)
</span></span><span style=display:flex><span>spark<span style=color:#666>.</span>sql(<span style=color:#ba2121>&#34;LOAD DATA LOCAL INPATH &#39;examples/src/main/resources/kv1.txt&#39; INTO TABLE src&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>spark<span style=color:#666>.</span>sql(<span style=color:#ba2121>&#34;SELECT * FROM src&#34;</span>)<span style=color:#666>.</span>show()
</span></span><span style=display:flex><span>spark<span style=color:#666>.</span>sql(<span style=color:#ba2121>&#34;SELECT COUNT(*) FROM src&#34;</span>)<span style=color:#666>.</span>show()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sqlDF <span style=color:#666>=</span> spark<span style=color:#666>.</span>sql(<span style=color:#ba2121>&#34;SELECT key, value FROM src WHERE key &lt; 10 ORDER BY key&#34;</span>)  <span style=color:#408080;font-style:italic># RDD[Row]</span>
</span></span><span style=display:flex><span>stringsDS <span style=color:#666>=</span> sqlDF<span style=color:#666>.</span>rdd<span style=color:#666>.</span>map(<span style=color:green;font-weight:700>lambda</span> row: <span style=color:#ba2121>&#34;Key: </span><span style=color:#b68;font-weight:700>%d</span><span style=color:#ba2121>, Value: </span><span style=color:#b68;font-weight:700>%s</span><span style=color:#ba2121>&#34;</span> <span style=color:#666>%</span> (row<span style=color:#666>.</span>key, row<span style=color:#666>.</span>value))<span style=color:#666>.</span>collect()  <span style=color:#408080;font-style:italic># RDD[String]</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># Create a Spark dataframe</span>
</span></span><span style=display:flex><span>Record <span style=color:#666>=</span> Row(<span style=color:#ba2121>&#34;key&#34;</span>, <span style=color:#ba2121>&#34;value&#34;</span>)
</span></span><span style=display:flex><span>recordsDF <span style=color:#666>=</span> spark<span style=color:#666>.</span>createDataFrame([Record(i, <span style=color:#ba2121>&#34;val_&#34;</span> <span style=color:#666>+</span> <span style=color:green>str</span>(i)) <span style=color:green;font-weight:700>for</span> i <span style=color:#a2f;font-weight:700>in</span> <span style=color:green>range</span>(<span style=color:#666>1</span>, <span style=color:#666>101</span>)])
</span></span><span style=display:flex><span>recordsDF<span style=color:#666>.</span>createOrReplaceTempView(<span style=color:#ba2121>&#34;records&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># Can also join DataFrame data with data stored in Hive.</span>
</span></span><span style=display:flex><span>spark<span style=color:#666>.</span>sql(<span style=color:#ba2121>&#34;SELECT * FROM records r JOIN src s ON r.key = s.key&#34;</span>)<span style=color:#666>.</span>show()
</span></span></code></pre></div><h3 id=hive-settings>Hive Settings
<a class=anchor href=#hive-settings>#</a></h3><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:green;font-weight:700>CREATE</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>TABLE</span><span style=color:#bbb> </span>src(id<span style=color:#bbb> </span><span style=color:green>int</span>)<span style=color:#bbb> </span><span style=color:green;font-weight:700>USING</span><span style=color:#bbb> </span>hive<span style=color:#bbb> </span><span style=color:green;font-weight:700>OPTIONS</span>(fileFormat<span style=color:#bbb> </span><span style=color:#ba2121>&#39;parquet&#39;</span>)<span style=color:#bbb>
</span></span></span></code></pre></div><ul><li><code>fileFormat</code>: A fileFormat is kind of a package of storage format specifications, including &ldquo;serde&rdquo;, &ldquo;input format&rdquo; and &ldquo;output format&rdquo;. Currently we support 6 fileFormats: &lsquo;sequencefile&rsquo;, &lsquo;rcfile&rsquo;, &lsquo;orc&rsquo;, &lsquo;parquet&rsquo;, &rsquo;textfile&rsquo; and &lsquo;avro&rsquo;.</li><li><code>inputFormat</code> <code>outputFormat</code>: These 2 options specify the name of a corresponding InputFormat and OutputFormat class as a string literal, e.g. org.apache.hadoop.hive.ql.io.orc.OrcInputFormat. These 2 options must be appeared in pair, and you can not specify them if you already specified the fileFormat option.</li><li><code>serde</code>: This option specifies the name of a serde class. When the fileFormat option is specified, do not specify this option if the given fileFormat already include the information of serde. Currently &ldquo;sequencefile&rdquo;, &ldquo;textfile&rdquo; and &ldquo;rcfile&rdquo; don&rsquo;t include the serde information and you can use this option with these 3 fileFormats.</li><li><code>fieldDelim</code> <code>escapeDelim</code> <code>collectionDelim</code> <code>mapkeyDelim</code> <code>lineDelim</code>: These options can only be used with &ldquo;textfile&rdquo; fileFormat. They define how to read delimited files into rows.</li></ul><p><code>broadcast</code> hints Spark to broadcast the table to the cluster when join with others. <strong>Broadcast Hash Join</strong> is preferred but not guaranteed. When both side is broadcasted, Spark chooses the one with lower statistics.</p><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:green;font-weight:700>from</span> <span style=color:#00f;font-weight:700>pyspark.sql.functions</span> <span style=color:green;font-weight:700>import</span> broadcast
</span></span><span style=display:flex><span>broadcast(spark<span style=color:#666>.</span>table(<span style=color:#ba2121>&#34;src&#34;</span>))<span style=color:#666>.</span>join(spark<span style=color:#666>.</span>table(<span style=color:#ba2121>&#34;records&#34;</span>), <span style=color:#ba2121>&#34;key&#34;</span>)<span style=color:#666>.</span>show()
</span></span></code></pre></div><h2 id=pandas>Pandas
<a class=anchor href=#pandas>#</a></h2><h3 id=transforming>Transforming
<a class=anchor href=#transforming>#</a></h3><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:green;font-weight:700>import</span> <span style=color:#00f;font-weight:700>numpy</span> <span style=color:green;font-weight:700>as</span> <span style=color:#00f;font-weight:700>np</span>
</span></span><span style=display:flex><span><span style=color:green;font-weight:700>import</span> <span style=color:#00f;font-weight:700>pandas</span> <span style=color:green;font-weight:700>as</span> <span style=color:#00f;font-weight:700>pd</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># Enable Arrow-based columnar data transfers</span>
</span></span><span style=display:flex><span>spark<span style=color:#666>.</span>conf<span style=color:#666>.</span>set(<span style=color:#ba2121>&#34;spark.sql.execution.arrow.enabled&#34;</span>, <span style=color:#ba2121>&#34;true&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># Create a Spark DataFrame from a Pandas DataFrame using Arrow</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>pdf <span style=color:#666>=</span> pd<span style=color:#666>.</span>DataFrame(np<span style=color:#666>.</span>random<span style=color:#666>.</span>rand(<span style=color:#666>100</span>, <span style=color:#666>3</span>))
</span></span><span style=display:flex><span>df <span style=color:#666>=</span> spark<span style=color:#666>.</span>createDataFrame(pdf)
</span></span><span style=display:flex><span>result_pdf <span style=color:#666>=</span> df<span style=color:#666>.</span>select(<span style=color:#ba2121>&#34;*&#34;</span>)<span style=color:#666>.</span>toPandas()
</span></span></code></pre></div><h3 id=pandas-scalar-纯量-udfs>Pandas Scalar (纯量) UDFs
<a class=anchor href=#pandas-scalar-%e7%ba%af%e9%87%8f-udfs>#</a></h3><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:green;font-weight:700>import</span> <span style=color:#00f;font-weight:700>pandas</span> <span style=color:green;font-weight:700>as</span> <span style=color:#00f;font-weight:700>pd</span>
</span></span><span style=display:flex><span><span style=color:green;font-weight:700>from</span> <span style=color:#00f;font-weight:700>pyspark.sql.functions</span> <span style=color:green;font-weight:700>import</span> col, pandas_udf
</span></span><span style=display:flex><span><span style=color:green;font-weight:700>from</span> <span style=color:#00f;font-weight:700>pyspark.sql.types</span> <span style=color:green;font-weight:700>import</span> LongType
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># Declare the function and create the UDF</span>
</span></span><span style=display:flex><span><span style=color:green;font-weight:700>def</span> <span style=color:#00f>multiply_func</span>(a, b):
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>return</span> a <span style=color:#666>*</span> b
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>multiply <span style=color:#666>=</span> pandas_udf(multiply_func, returnType<span style=color:#666>=</span>LongType())
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>x <span style=color:#666>=</span> pd<span style=color:#666>.</span>Series([<span style=color:#666>1</span>, <span style=color:#666>2</span>, <span style=color:#666>3</span>])
</span></span><span style=display:flex><span><span style=color:green>print</span>(multiply_func(x, x))
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># 0    1</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># 1    4</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># 2    9</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># dtype: int64</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># Execute function as a Spark vectorized UDF</span>
</span></span><span style=display:flex><span>df <span style=color:#666>=</span> spark<span style=color:#666>.</span>createDataFrame(pd<span style=color:#666>.</span>DataFrame(x, columns<span style=color:#666>=</span>[<span style=color:#ba2121>&#34;x&#34;</span>]))
</span></span><span style=display:flex><span>df<span style=color:#666>.</span>select(multiply(col(<span style=color:#ba2121>&#34;x&#34;</span>), col(<span style=color:#ba2121>&#34;x&#34;</span>)))<span style=color:#666>.</span>show()
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># +-------------------+</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># |multiply_func(x, x)|</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># +-------------------+</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># |                  1|</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># |                  4|</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># |                  9|</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># +-------------------+</span>
</span></span></code></pre></div><h3 id=pandas-grouped-map-udfs>Pandas Grouped Map UDFs
<a class=anchor href=#pandas-grouped-map-udfs>#</a></h3><p>Grouped Map UDFs are used along with <code>groupBy()</code></p><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:green;font-weight:700>from</span> <span style=color:#00f;font-weight:700>pyspark.sql.functions</span> <span style=color:green;font-weight:700>import</span> pandas_udf, PandasUDFType
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df <span style=color:#666>=</span> spark<span style=color:#666>.</span>createDataFrame(
</span></span><span style=display:flex><span>    [(<span style=color:#666>1</span>, <span style=color:#666>1.0</span>), (<span style=color:#666>1</span>, <span style=color:#666>2.0</span>), (<span style=color:#666>2</span>, <span style=color:#666>3.0</span>), (<span style=color:#666>2</span>, <span style=color:#666>5.0</span>), (<span style=color:#666>2</span>, <span style=color:#666>10.0</span>)],
</span></span><span style=display:flex><span>    (<span style=color:#ba2121>&#34;id&#34;</span>, <span style=color:#ba2121>&#34;v&#34;</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a2f>@pandas_udf</span>(<span style=color:#ba2121>&#34;id long, v double&#34;</span>, PandasUDFType<span style=color:#666>.</span>GROUPED_MAP)
</span></span><span style=display:flex><span><span style=color:green;font-weight:700>def</span> <span style=color:#00f>substract_mean</span>(pdf):
</span></span><span style=display:flex><span>    <span style=color:#408080;font-style:italic># pdf is a pandas.DataFrame</span>
</span></span><span style=display:flex><span>    v <span style=color:#666>=</span> pdf<span style=color:#666>.</span>v
</span></span><span style=display:flex><span>    <span style=color:green;font-weight:700>return</span> pdf<span style=color:#666>.</span>assign(v<span style=color:#666>=</span>v <span style=color:#666>-</span> v<span style=color:#666>.</span>mean())
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df<span style=color:#666>.</span>groupby(<span style=color:#ba2121>&#34;id&#34;</span>)<span style=color:#666>.</span>apply(substract_mean)<span style=color:#666>.</span>show()
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># +---+----+</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># | id|   v|</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># +---+----+</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># |  1|-0.5|</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># |  1| 0.5|</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># |  2|-3.0|</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># |  2|-1.0|</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># |  2| 4.0|</span>
</span></span><span style=display:flex><span><span style=color:#408080;font-style:italic># +---+----+</span>
</span></span></code></pre></div><h2 id=shuffle-hash-join--broadcast-hash-join--sort-merge-join>Shuffle Hash Join / Broadcast Hash Join / Sort Merge Join
<a class=anchor href=#shuffle-hash-join--broadcast-hash-join--sort-merge-join>#</a></h2><p>Hash Join 的思想是，首先将两个表分为小表 BuildTable 和大表 ProbeTable。将 BuildTable 以 Join Key 为 Key 构建为 HashMap，就可以将 ProbeTable 中的每条记录的 Key 在 HashMap 中进行 O(1) 的搜索，命中后再具体比较 Join Key 的实际值。整个算法的复杂度为 O(a+b)。</p><p>Broadcast Hash Join 非常好理解：对于大小表相 join 的情况，将小表的 HashMap 广播至所有 Executor，然后在所有的节点上执行 Hash Join。</p><p>当内存不足以存储小表时，使用 Shuffle Hash Join。通过 Spark 的 Shuffle 机制，将 Join Key 相同的数据发送到同一 Executor。</p><p>Sort Merge Join 目前用于两张大表互相 Join 的情况。先利用 Spark 的 Partition 将两张表重新分区，并在表内部进行排序。现在，每个节点上 A 表和 B 表数据的 Join Key 的范围相同，且都按照 Join Key 排序。然后，使用类似于归并排序的扫描方式来寻找相同的 Join Key。</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(n){const e=window.getSelection(),t=document.createRange();t.selectNodeContents(n),e.removeAllRanges(),e.addRange(t)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#spark-sql-programming>Spark SQL Programming</a><ul><li><a href=#basic>Basic</a><ul><li><a href=#dataframe>DataFrame</a></li><li><a href=#sql-queries>SQL Queries</a></li></ul></li><li><a href=#schema>Schema</a><ul><li><a href=#infering-schema>Infering Schema</a></li><li><a href=#programatically-specifying-the-schema>Programatically Specifying the Schema</a></li><li><a href=#user-defined-functions-udfs>User-defined Functions (UDFs)</a></li><li><a href=#user-defined-aggregate-functions>User-defined Aggregate Functions</a></li></ul></li><li><a href=#data-sources>Data Sources</a><ul><li><a href=#savemode>SaveMode</a></li><li><a href=#save-to-persistent-table>Save to Persistent Table</a></li><li><a href=#hive>Hive</a></li><li><a href=#hive-settings>Hive Settings</a></li></ul></li><li><a href=#pandas>Pandas</a><ul><li><a href=#transforming>Transforming</a></li><li><a href=#pandas-scalar-纯量-udfs>Pandas Scalar (纯量) UDFs</a></li><li><a href=#pandas-grouped-map-udfs>Pandas Grouped Map UDFs</a></li></ul></li><li><a href=#shuffle-hash-join--broadcast-hash-join--sort-merge-join>Shuffle Hash Join / Broadcast Hash Join / Sort Merge Join</a></li></ul></li></ul></nav></div></aside></main></body></html>