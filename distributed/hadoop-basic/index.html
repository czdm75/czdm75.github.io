<!doctype html><html lang=en dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Hadoop 基本概念 # HDFS # 功能特性 # 向各种计算框架开放文件读写端口，适合大文件、一次写入多次读取的存储。
仅支持单线程 append 写，不支持随机多线程访问。
结构 # HDFS Client # 与 NameNode 交互，获取文件 Block 所在结点等信息
切分文件为 Block
与 DataNode 交互，实际传输文件
其他管理 HDFS 的工作
NameNode # 作为集群的 Master，管理名称空间
管理 Block 的映射信息
配置副本策略
处理 Client 的读写请求
NameNode 是整个 HDFS 最重要的部分，在 Hadoop 2.0 之后和 YARN 一起引入了 HA 架构，使得 Hadoop 可以用于在线应用。
DataNode # 执行 NameNode 下达的操作
存储数据
执行读写
SecondaryNameNode # 定期将 edits 和 fsimage 合并
起到辅助恢复的作用，但并不是热备
SecondaryNameNode 的作用 # SecondaryNameNode 能够保存 HDFS 的变化信息，在集群故障时辅助进行恢复工作。同时，也为 NameNode 分担了一小部分工作。其工作流程是基于变化的："><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:url" content="/distributed/hadoop-basic/"><meta property="og:site_name" content="czdm75 Blog"><meta property="og:title" content="Hadoop Basic Concepts"><meta property="og:description" content="Hadoop 基本概念 # HDFS # 功能特性 # 向各种计算框架开放文件读写端口，适合大文件、一次写入多次读取的存储。
仅支持单线程 append 写，不支持随机多线程访问。
结构 # HDFS Client # 与 NameNode 交互，获取文件 Block 所在结点等信息
切分文件为 Block
与 DataNode 交互，实际传输文件
其他管理 HDFS 的工作
NameNode # 作为集群的 Master，管理名称空间
管理 Block 的映射信息
配置副本策略
处理 Client 的读写请求
NameNode 是整个 HDFS 最重要的部分，在 Hadoop 2.0 之后和 YARN 一起引入了 HA 架构，使得 Hadoop 可以用于在线应用。
DataNode # 执行 NameNode 下达的操作
存储数据
执行读写
SecondaryNameNode # 定期将 edits 和 fsimage 合并
起到辅助恢复的作用，但并不是热备
SecondaryNameNode 的作用 # SecondaryNameNode 能够保存 HDFS 的变化信息，在集群故障时辅助进行恢复工作。同时，也为 NameNode 分担了一小部分工作。其工作流程是基于变化的："><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="distributed"><title>Hadoop Basic Concepts | czdm75 Blog</title>
<link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.97cfda4f5e3c9fa49a2bf8d401f4ddc0eec576c99cdcf6afbec19173200c37db.css><script defer src=/flexsearch.min.js></script><script defer src=/en.search.min.f7e98004e6b8d1bafd93b9d4b053644c96b18c50c1205ec6db396c209e97a5a3.js></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>czdm75 Blog</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><input type=checkbox id=section-7258d8e1fea5a0c302a6de537a7b6f57 class=toggle>
<label for=section-7258d8e1fea5a0c302a6de537a7b6f57 class="flex justify-between"><a href=/cs/>Computer Science</a></label><ul><li><a href=/cs/linux-io-multiplex/>Linux IO Multiplexing</a></li></ul></li><li><input type=checkbox id=section-6c3d93bc59df31a703231f35ad75d678 class=toggle checked>
<label for=section-6c3d93bc59df31a703231f35ad75d678 class="flex justify-between"><a href=/distributed/>Distributed Systems</a></label><ul><li><a href=/distributed/hadoop-basic/ class=active>Hadoop Basic Concepts</a></li><li><a href=/distributed/spark-rdd/>Spark RDD Programming</a></li><li><a href=/distributed/spark-sql/>Spark SQL Programming</a></li></ul></li><li><a href=/notes/>Notes on Books</a><ul><li><input type=checkbox id=section-75aaf2c83c6ed8e1f079c5418c19dad4 class=toggle>
<label for=section-75aaf2c83c6ed8e1f079c5418c19dad4 class="flex justify-between"><a href=/notes/core-java-impatient/>Core Java for Impatients</a></label><ul><li><a href=/notes/core-java-impatient/1/>1. Basic OOP</a></li><li><a href=/notes/core-java-impatient/2/>2. Interface, Lambda</a></li><li><a href=/notes/core-java-impatient/3/>3. Inheritance, Reflection</a></li><li><a href=/notes/core-java-impatient/4/>4. Exception, Logging</a></li><li><a href=/notes/core-java-impatient/5/>5. Generics</a></li><li><a href=/notes/core-java-impatient/6/>6. Collections, Streams</a></li><li><a href=/notes/core-java-impatient/7/>7. IO, Regexp, Serialization</a></li><li><a href=/notes/core-java-impatient/8/>8. Threading</a></li><li><a href=/notes/core-java-impatient/9/>9. Notations</a></li></ul></li><li><input type=checkbox id=section-b2f01d2b22c35e214487b845322f7a58 class=toggle>
<label for=section-b2f01d2b22c35e214487b845322f7a58 class="flex justify-between"><a href=/notes/ddia/>Designing Data-Intensive Applications</a></label><ul><li><a href=/notes/ddia/1/>1. Data System and Data Model</a></li><li><a href=/notes/ddia/2/>2. Storage, Query, Encoding</a></li><li><a href=/notes/ddia/3/>3. Replication and Partition</a></li></ul></li><li><input type=checkbox id=section-8c64db930c5b756022bf5d3ba1af6015 class=toggle>
<label for=section-8c64db930c5b756022bf5d3ba1af6015 class="flex justify-between"><a href=/notes/in-depth-jvm/>In-depth Understanding JVM</a></label><ul><li><a href=/notes/in-depth-jvm/gc/>Garbage Collection</a></li><li><a href=/notes/in-depth-jvm/synchronization/>Java Synchronization</a></li><li><a href=/notes/in-depth-jvm/memory-model/>JVM Memory Model</a></li><li><a href=/notes/in-depth-jvm/memory-region/>JVM Memory Regions</a></li><li><a href=/notes/in-depth-jvm/threadlocal-reference/>ThreadLocal and Reference</a></li></ul></li><li><input type=checkbox id=section-15259ec15aa2cb7859c77500905f6b03 class=toggle>
<label for=section-15259ec15aa2cb7859c77500905f6b03 class="flex justify-between"><a href=/notes/intro-algo/>Introduction to Algorithms</a></label><ul><li><a href=/notes/intro-algo/1/>1. Compexity, Divide</a></li><li><a href=/notes/intro-algo/2/>2. Sorting, Order Statistic</a></li><li><a href=/notes/intro-algo/3/>3. LinkedList, HashTable</a></li><li><a href=/notes/intro-algo/4/>4. BST, Balanced BSTs</a></li><li><a href=/notes/intro-algo/5/>5. Trie-Tree, Extending Data Structures</a></li><li><a href=/notes/intro-algo/6/>6. Dynamic Programming, Greedy, Amortize</a></li><li><a href=/notes/intro-algo/7/>7. B-Tree, Fibonacci Heap, vEB Tree</a></li><li><a href=/notes/intro-algo/8/>8. Graphs</a></li></ul></li><li><input type=checkbox id=section-3efdc8e38ef7f47959bf45f30a9dec98 class=toggle>
<label for=section-3efdc8e38ef7f47959bf45f30a9dec98 class="flex justify-between"><a href=/notes/programming-scala/>Programming in Scala</a></label><ul><li><a href=/notes/programming-scala/1/>1. Basics</a></li><li><a href=/notes/programming-scala/2/>2. Functions</a></li><li><a href=/notes/programming-scala/3/>3 .Inheritance, Package, Assertion</a></li><li><a href=/notes/programming-scala/4/>4. Pattern Matching, Collections</a></li><li><a href=/notes/programming-scala/5/>5. Generics, Abstract, Implicits</a></li><li><a href=/notes/programming-scala/6/>6. Collections, Extractor, etc</a></li></ul></li></ul></li><li><input type=checkbox id=section-ebdb83a62411872593631ee1e4ab41d9 class=toggle>
<label for=section-ebdb83a62411872593631ee1e4ab41d9 class="flex justify-between"><a href=/pl/>Programming Languages</a></label><ul><li><a href=/pl/java-nio-2/>Java NIO Internal</a></li><li><a href=/pl/java-nio-1/>Java NIO Usage</a></li><li><a href=/pl/lambda/>Lambda Calculus and Y Combinator</a></li><li><a href=/pl/curry/>Scala: Currying, Partially Applied, Partial</a></li><li><a href=/pl/monad/>Scala: Monad, from Scala Perspective</a></li></ul></li></ul><ul><li><a href=https://github.com/czdm75 target=_blank rel=noopener>GitHub</a></li><li><a href=https://themes.gohugo.io/hugo-book/ target=_blank rel=noopener>Theme</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu>
</label><strong>Hadoop Basic Concepts</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#hadoop-基本概念>Hadoop 基本概念</a><ul><li><a href=#hdfs>HDFS</a><ul><li><a href=#功能特性>功能特性</a></li><li><a href=#结构>结构</a><ul><li><a href=#hdfs-client>HDFS Client</a></li><li><a href=#namenode>NameNode</a></li><li><a href=#datanode>DataNode</a></li><li><a href=#secondarynamenode>SecondaryNameNode</a></li></ul></li><li><a href=#secondarynamenode-的作用>SecondaryNameNode 的作用</a></li><li><a href=#hdfs-的读写流程>HDFS 的读写流程</a></li><li><a href=#hdfs-的副本策略>HDFS 的副本策略</a></li></ul></li><li><a href=#mapreduce>MapReduce</a><ul><li><a href=#代码示例>代码示例</a></li><li><a href=#mr-内部逻辑>MR 内部逻辑</a><ul><li><a href=#map-阶段>Map 阶段</a></li><li><a href=#reduce-阶段>Reduce 阶段</a></li><li><a href=#shuffle-阶段的具体细节>Shuffle 阶段的具体细节</a></li></ul></li><li><a href=#hadoop-序列化>Hadoop 序列化</a></li></ul></li><li><a href=#mr-的可插拔pluggable组件>MR 的可插拔（pluggable）组件</a><ul><li><a href=#io-format>IO Format</a></li><li><a href=#多输入--输出>多输入 / 输出</a></li><li><a href=#combiner>Combiner</a></li><li><a href=#partitioner>Partitioner</a></li></ul></li><li><a href=#yarn>YARN</a><ul><li><a href=#yarn-的组成>YARN 的组成</a></li><li><a href=#yarn-的容错>YARN 的容错</a></li></ul></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=hadoop-基本概念>Hadoop 基本概念
<a class=anchor href=#hadoop-%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5>#</a></h1><h2 id=hdfs>HDFS
<a class=anchor href=#hdfs>#</a></h2><h3 id=功能特性>功能特性
<a class=anchor href=#%e5%8a%9f%e8%83%bd%e7%89%b9%e6%80%a7>#</a></h3><p>向各种计算框架开放文件读写端口，适合大文件、一次写入多次读取的存储。</p><p>仅支持单线程 append 写，不支持随机多线程访问。</p><h3 id=结构>结构
<a class=anchor href=#%e7%bb%93%e6%9e%84>#</a></h3><h4 id=hdfs-client>HDFS Client
<a class=anchor href=#hdfs-client>#</a></h4><ul><li><p>与 NameNode 交互，获取文件 Block 所在结点等信息</p></li><li><p>切分文件为 Block</p></li><li><p>与 DataNode 交互，实际传输文件</p></li><li><p>其他管理 HDFS 的工作</p></li></ul><h4 id=namenode>NameNode
<a class=anchor href=#namenode>#</a></h4><ul><li><p>作为集群的 Master，管理名称空间</p></li><li><p>管理 Block 的映射信息</p></li><li><p>配置副本策略</p></li><li><p>处理 Client 的读写请求</p></li></ul><p>NameNode 是整个 HDFS 最重要的部分，在 Hadoop 2.0 之后和 YARN 一起引入了 HA 架构，使得 Hadoop 可以用于在线应用。</p><h4 id=datanode>DataNode
<a class=anchor href=#datanode>#</a></h4><ul><li><p>执行 NameNode 下达的操作</p></li><li><p>存储数据</p></li><li><p>执行读写</p></li></ul><h4 id=secondarynamenode>SecondaryNameNode
<a class=anchor href=#secondarynamenode>#</a></h4><ul><li><p>定期将 <code>edits</code> 和 <code>fsimage</code> 合并</p></li><li><p>起到辅助恢复的作用，但并不是热备</p></li></ul><h3 id=secondarynamenode-的作用>SecondaryNameNode 的作用
<a class=anchor href=#secondarynamenode-%e7%9a%84%e4%bd%9c%e7%94%a8>#</a></h3><p>SecondaryNameNode 能够保存 HDFS 的变化信息，在集群故障时辅助进行恢复工作。同时，也为 NameNode 分担了一小部分工作。其工作流程是基于变化的：</p><ol><li><p>NameNode 维护两部分信息：<code>edits</code> 和 <code>fsimage</code>。一切新的修改都执行在 <code>edits</code> 上。因此，访问文件也是优先访问 <code>edits</code> 部分。</p></li><li><p>当到达一定时间或 <code>edits</code> 达到一定大小（默认为 3600s 和 64MB）时，将二者共同传送给 SecondaryNameNode。然后，建立一个新的 <code>edits.new</code>，存储接下来文件系统的变化。</p></li><li><p>SecondaryNameNode 接收到 <code>edits</code> 和 <code>fsimage</code> 后，将二者合并，成为一个新的文件系统快照。这个快照在集群故障时就可作为恢复依据。将合并后的新的文件快照 <code>fsimage.ckpt</code> 发回给 NameNode。</p></li><li><p>NameNode 收到合并后的 <code>fsimage.ckpt</code> 后，将其作为新的 <code>fsimage</code> 使用，而在这段时间内存储文件系统变化的 <code>edits.new</code> 既可作为新的 <code>edits</code> 使用。</p></li></ol><p>通过这样的流程，SecondaryNameNode 将合并文件系统变化的工作接了过来，NameNode 只需要负责及时响应客户端的变化即可。</p><h3 id=hdfs-的读写流程>HDFS 的读写流程
<a class=anchor href=#hdfs-%e7%9a%84%e8%af%bb%e5%86%99%e6%b5%81%e7%a8%8b>#</a></h3><p>在读取文件时，客户端获取到 DFS 实例后，DFS 实例从 NameNode 通过 RPC 获取到一批 block 的位置，但并不一定是全部 block。这些 block 按照其所在的 DataNode 距离客户端从近到远的顺序排序。Client 依次串行地读取每一个 block，直到全部读完，再从 NameNode 获取下一批 block 的位置。这样，避免了文件较大时读取队列过长的情况。</p><p>在写入文件时，调用 DFS 实例的 <code>create</code> 方法，要求 NameNode 创建一个大小为 0 的文件。也就是说，HDFS 写入新文件的方式是先 touch 再 append。在创建时，NameNode 会检查是否有同名文件、目录权限等问题。</p><p>随后，Client 的 <code>DFSOutputStream</code> 将数据切分成 block 进入 <code>data queue</code> 队列，并向 NameNode 请求 3 个最合适的 DataNode（取决于副本策略）。此外，<code>DFSOutputStream</code> 还包含一个 <code>ack queue</code> 队列，用于等待 DataNode 的写入完成回复。只有在收到了来自 DataNode 的确认信息之后才会将 block 从 <code>data queue</code> 中移除。写入全部完成后，关闭流，通知元数据节点。</p><h3 id=hdfs-的副本策略>HDFS 的副本策略
<a class=anchor href=#hdfs-%e7%9a%84%e5%89%af%e6%9c%ac%e7%ad%96%e7%95%a5>#</a></h3><p>决定副本策略的权衡因素包括集群的可靠性以及读写带宽。默认副本因子为 3，要求同机架（rack）两份，其他机架一份。在 Client 需要读取文件时，选择距离最近的结点进行读取。</p><p>在 Hadoop 的安全模式下，会对所有的文件检查副本数量。</p><h2 id=mapreduce>MapReduce
<a class=anchor href=#mapreduce>#</a></h2><p>适用于离线处理的，高容错（在一个节点上失败将会移到其他节点）的分布式计算框架</p><h3 id=代码示例>代码示例
<a class=anchor href=#%e4%bb%a3%e7%a0%81%e7%a4%ba%e4%be%8b>#</a></h3><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span><span style=color:green;font-weight:700>public</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>class</span> <span style=color:#00f;font-weight:700>WordCount</span><span style=color:#bbb> </span>{<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>public</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>static</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>class</span> <span style=color:#00f;font-weight:700>TokenizerMapper</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>extends</span><span style=color:#bbb> </span>Mapper<span style=color:#666>&lt;</span>Object,<span style=color:#bbb> </span>Text,<span style=color:#bbb> </span>Text,<span style=color:#bbb> </span>IntWritable<span style=color:#666>&gt;</span><span style=color:#bbb> </span>{<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>private</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>final</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>static</span><span style=color:#bbb> </span>IntWritable<span style=color:#bbb> </span>one<span style=color:#bbb> </span><span style=color:#666>=</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>new</span><span style=color:#bbb> </span>IntWritable(1);<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>private</span><span style=color:#bbb> </span>Text<span style=color:#bbb> </span>word<span style=color:#bbb> </span><span style=color:#666>=</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>new</span><span style=color:#bbb> </span>Text();<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>public</span><span style=color:#bbb> </span><span style=color:#b00040>void</span><span style=color:#bbb> </span><span style=color:#00f>map</span>(Object<span style=color:#bbb> </span>key,<span style=color:#bbb> </span>Text<span style=color:#bbb> </span>value,<span style=color:#bbb> </span>Context<span style=color:#bbb> </span>context<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                    </span>)<span style=color:#bbb> </span><span style=color:green;font-weight:700>throws</span><span style=color:#bbb> </span>IOException,<span style=color:#bbb> </span>InterruptedException<span style=color:#bbb> </span>{<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>StringTokenizer<span style=color:#bbb> </span>itr<span style=color:#bbb> </span><span style=color:#666>=</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>new</span><span style=color:#bbb> </span>StringTokenizer(value.<span style=color:#7d9029>toString</span>());<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>while</span><span style=color:#bbb> </span>(itr.<span style=color:#7d9029>hasMoreTokens</span>())<span style=color:#bbb> </span>{<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>word.<span style=color:#7d9029>set</span>(itr.<span style=color:#7d9029>nextToken</span>());<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>context.<span style=color:#7d9029>write</span>(word,<span style=color:#bbb> </span>one);<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>public</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>static</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>class</span> <span style=color:#00f;font-weight:700>IntSumReducer</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>extends</span><span style=color:#bbb> </span>Reducer<span style=color:#666>&lt;</span>Text,IntWritable,Text,IntWritable<span style=color:#666>&gt;</span><span style=color:#bbb> </span>{<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>private</span><span style=color:#bbb> </span>IntWritable<span style=color:#bbb> </span>result<span style=color:#bbb> </span><span style=color:#666>=</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>new</span><span style=color:#bbb> </span>IntWritable();<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>public</span><span style=color:#bbb> </span><span style=color:#b00040>void</span><span style=color:#bbb> </span><span style=color:#00f>reduce</span>(Text<span style=color:#bbb> </span>key,<span style=color:#bbb> </span>Iterable<span style=color:#666>&lt;</span>IntWritable<span style=color:#666>&gt;</span><span style=color:#bbb> </span>values,<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                       </span>Context<span style=color:#bbb> </span>context<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>                       </span>)<span style=color:#bbb> </span><span style=color:green;font-weight:700>throws</span><span style=color:#bbb> </span>IOException,<span style=color:#bbb> </span>InterruptedException<span style=color:#bbb> </span>{<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:#b00040>int</span><span style=color:#bbb> </span>sum<span style=color:#bbb> </span><span style=color:#666>=</span><span style=color:#bbb> </span>0;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>for</span><span style=color:#bbb> </span>(IntWritable<span style=color:#bbb> </span>val<span style=color:#bbb> </span>:<span style=color:#bbb> </span>values)<span style=color:#bbb> </span>{<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span>sum<span style=color:#bbb> </span><span style=color:#666>+=</span><span style=color:#bbb> </span>val.<span style=color:#7d9029>get</span>();<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>result.<span style=color:#7d9029>set</span>(sum);<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>      </span>context.<span style=color:#7d9029>write</span>(key,<span style=color:#bbb> </span>result);<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>public</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>static</span><span style=color:#bbb> </span><span style=color:#b00040>void</span><span style=color:#bbb> </span><span style=color:#00f>main</span>(String<span style=color:#666>[]</span><span style=color:#bbb> </span>args)<span style=color:#bbb> </span><span style=color:green;font-weight:700>throws</span><span style=color:#bbb> </span>Exception<span style=color:#bbb> </span>{<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>Configuration<span style=color:#bbb> </span>conf<span style=color:#bbb> </span><span style=color:#666>=</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>new</span><span style=color:#bbb> </span>Configuration();<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>Job<span style=color:#bbb> </span>job<span style=color:#bbb> </span><span style=color:#666>=</span><span style=color:#bbb> </span>Job.<span style=color:#7d9029>getInstance</span>(conf,<span style=color:#bbb> </span><span style=color:#ba2121>&#34;word count&#34;</span>);<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>job.<span style=color:#7d9029>setJarByClass</span>(WordCount.<span style=color:#7d9029>class</span>);<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>job.<span style=color:#7d9029>setMapperClass</span>(TokenizerMapper.<span style=color:#7d9029>class</span>);<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>job.<span style=color:#7d9029>setCombinerClass</span>(IntSumReducer.<span style=color:#7d9029>class</span>);<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>job.<span style=color:#7d9029>setReducerClass</span>(IntSumReducer.<span style=color:#7d9029>class</span>);<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>job.<span style=color:#7d9029>setOutputKeyClass</span>(Text.<span style=color:#7d9029>class</span>);<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>job.<span style=color:#7d9029>setOutputValueClass</span>(IntWritable.<span style=color:#7d9029>class</span>);<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>FileInputFormat.<span style=color:#7d9029>addInputPath</span>(job,<span style=color:#bbb> </span><span style=color:green;font-weight:700>new</span><span style=color:#bbb> </span>Path(args<span style=color:#666>[</span>0<span style=color:#666>]</span>));<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>FileOutputFormat.<span style=color:#7d9029>setOutputPath</span>(job,<span style=color:#bbb> </span><span style=color:green;font-weight:700>new</span><span style=color:#bbb> </span>Path(args<span style=color:#666>[</span>1<span style=color:#666>]</span>));<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>System.<span style=color:#7d9029>exit</span>(job.<span style=color:#7d9029>waitForCompletion</span>(<span style=color:green;font-weight:700>true</span>)<span style=color:#bbb> </span><span style=color:#666>?</span><span style=color:#bbb> </span>0<span style=color:#bbb> </span>:<span style=color:#bbb> </span>1);<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>}<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=mr-内部逻辑>MR 内部逻辑
<a class=anchor href=#mr-%e5%86%85%e9%83%a8%e9%80%bb%e8%be%91>#</a></h3><h4 id=map-阶段>Map 阶段
<a class=anchor href=#map-%e9%98%b6%e6%ae%b5>#</a></h4><p>Map 阶段由 InputFormat、Mapper 和 Partitioner 三部分构成。</p><p>输入的每个 Split 交给一个 Mapper 进行处理。Split 与 HDFS 中 Block 的对应关系取决于 InputFormat 和压缩格式，通常为一对一。默认使用的是 <code>TextInputFormat</code>，其传递给 Mapper 的格式中，Key 为行的偏移量，Value 为行内容。</p><p>经过用户编写的 Map 逻辑后，数据根据 Key 由 Partitioner 分组选择不同的 Reduce 节点。默认方法是进行 Hash 取模，模数即为 Reduce 节点的数量。因此，相同的 Key 将会被分配到同一个 Reduce 节点。</p><p>在 Partitioner 之前，可以使用 Combiner 将数据进行合并。例如，在 wordcount 程序中，可以先使用 Combiner 将相同 Key 的数据计算出来。那么，Partitioner 输出的数据就将不再形如 <code>&lt;k1,1> &lt;k1,1> &lt;k2,1></code>，而是经过 Combiner 计算变成 <code>&lt;k1,2> &lt;k2,1></code>。相当于进行了局部的 Reduce 操作。因此，这个参数在很多时候（比如上面的例子）可以直接使用 Reducer，即使不传入也不会对结果有影响。</p><h4 id=reduce-阶段>Reduce 阶段
<a class=anchor href=#reduce-%e9%98%b6%e6%ae%b5>#</a></h4><p>Reduce 阶段由 Shuffle、Sort、Reducer、OutputFormat 四个部分构成。</p><p>在 Shuffle 部分，数据从 Mapper 拷贝到 Reduce 节点，具体拷贝哪一个由前面的 Partitioner 决定。拷贝之后，在 Reduce 节点本地进行 Sort，将相同的 Key 排列到一起以供 Reduce 使用。</p><p>Reducer 将数据处理完成后，根据 OutputFormat 输出到磁盘。默认为 <code>TextOutputFormat</code>。</p><h4 id=shuffle-阶段的具体细节>Shuffle 阶段的具体细节
<a class=anchor href=#shuffle-%e9%98%b6%e6%ae%b5%e7%9a%84%e5%85%b7%e4%bd%93%e7%bb%86%e8%8a%82>#</a></h4><p>在 Mapper 处理完成后，数据并不是直接进入磁盘，而是先储存在内存中的 buffer 中。buffer 是一个环形缓冲区，其大小由 <code>io.sort.mb</code> 属性控制，阈值由 <code>io.sort.spill.percent</code> 控制，默认为 100M 和 80%。缓冲区达到阈值后，将缓冲区内的内容进行 Partition，合并写入磁盘。</p><p>这样，一次缓冲区满的 80 MB 数据将被按 key 排列写入，每一片最终进入一个 Reducer。</p><h3 id=hadoop-序列化>Hadoop 序列化
<a class=anchor href=#hadoop-%e5%ba%8f%e5%88%97%e5%8c%96>#</a></h3><p>Java 的序列化比较复杂，而我们在 Hadoop 中需要的序列化只要把必须的数据依次序列化即可，可以更加紧凑。在集群间进行通讯和 RPC 时，需要进行大量的序列化和反序列化操作。</p><p>Hadoop 为 Java 的八种基本类型准备了对应的 <code>Writable</code> 类。其中，Boolean 的实现使用了一个字节来存储。另一种常用的序列化类型是 <code>Text</code>。默认使用 UTF-8 编码。</p><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span>Text<span style=color:#bbb> </span>text<span style=color:#bbb> </span><span style=color:#666>=</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>new</span><span style=color:#bbb> </span>Text(<span style=color:#ba2121>&#34;xxx&#34;</span>);<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>text.<span style=color:#7d9029>set</span>(<span style=color:#ba2121>&#34;xxx&#34;</span>);<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>text.<span style=color:#7d9029>set</span>(<span style=color:#ba2121>&#34;&#34;</span>.<span style=color:#7d9029>toByteArray</span>());<span style=color:#bbb>
</span></span></span></code></pre></div><p>所有的序列化类型都要实现 <code>WritableComparable</code> 接口。</p><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span><span style=color:green;font-weight:700>public</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>interface</span> <span style=color:#00f;font-weight:700>Writable</span><span style=color:#bbb> </span>{<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#b00040>void</span><span style=color:#bbb> </span><span style=color:#00f>write</span>(DataOutput<span style=color:#bbb> </span>out)<span style=color:#bbb> </span><span style=color:green;font-weight:700>throws</span><span style=color:#bbb> </span>IOException;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#b00040>void</span><span style=color:#bbb> </span><span style=color:#00f>readFields</span>(DataInput<span style=color:#bbb> </span>in)<span style=color:#bbb> </span><span style=color:green;font-weight:700>throws</span><span style=color:#bbb> </span>IOException;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>public</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>class</span> <span style=color:#00f;font-weight:700>IntWritable</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>implements</span><span style=color:#bbb> </span>WritableComparable<span style=color:#666>&lt;</span>IntWritable<span style=color:#666>&gt;</span><span style=color:#bbb> </span>{<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>private</span><span style=color:#bbb> </span><span style=color:#b00040>int</span><span style=color:#bbb> </span>value;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#a2f>@Override</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>public</span><span style=color:#bbb> </span><span style=color:#b00040>void</span><span style=color:#bbb> </span><span style=color:#00f>readFields</span>(DataInput<span style=color:#bbb> </span>in)<span style=color:#bbb> </span><span style=color:green;font-weight:700>throws</span><span style=color:#bbb> </span>IOException<span style=color:#bbb> </span>{<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>value<span style=color:#bbb> </span><span style=color:#666>=</span><span style=color:#bbb> </span>in.<span style=color:#7d9029>readInt</span>();<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#a2f>@Override</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>public</span><span style=color:#bbb> </span><span style=color:#b00040>void</span><span style=color:#bbb> </span><span style=color:#00f>write</span>(DataOutput<span style=color:#bbb> </span>out)<span style=color:#bbb> </span><span style=color:green;font-weight:700>throws</span><span style=color:#bbb> </span>IOException<span style=color:#bbb> </span>{<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>out.<span style=color:#7d9029>writeInt</span>(value);<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:#a2f>@Override</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>public</span><span style=color:#bbb> </span><span style=color:#b00040>int</span><span style=color:#bbb> </span><span style=color:#00f>compareTo</span>(IntWritable<span style=color:#bbb> </span>o)<span style=color:#bbb> </span>{<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#b00040>int</span><span style=color:#bbb> </span>thisValue<span style=color:#bbb> </span><span style=color:#666>=</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>this</span>.<span style=color:#7d9029>value</span>;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#b00040>int</span><span style=color:#bbb> </span>thatValue<span style=color:#bbb> </span><span style=color:#666>=</span><span style=color:#bbb> </span>o.<span style=color:#7d9029>value</span>;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>return</span><span style=color:#bbb> </span>(thisValue<span style=color:#666>&lt;</span>thatValue<span style=color:#bbb> </span><span style=color:#666>?</span><span style=color:#bbb> </span><span style=color:#666>-</span>1<span style=color:#bbb> </span>:<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>            </span>(thisValue<span style=color:#666>==</span>thatValue<span style=color:#bbb> </span><span style=color:#666>?</span><span style=color:#bbb> </span>0<span style=color:#bbb> </span>:<span style=color:#bbb> </span>1));<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>  </span>}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>}<span style=color:#bbb>
</span></span></span></code></pre></div><h2 id=mr-的可插拔pluggable组件>MR 的可插拔（pluggable）组件
<a class=anchor href=#mr-%e7%9a%84%e5%8f%af%e6%8f%92%e6%8b%94pluggable%e7%bb%84%e4%bb%b6>#</a></h2><h3 id=io-format>IO Format
<a class=anchor href=#io-format>#</a></h3><table><thead><tr><th>IO Format</th><th>Key</th><th>Value</th><th>备注</th></tr></thead><tbody><tr><td><code>TextInputFormat</code></td><td>字节偏移量</td><td>行内容</td><td></td></tr><tr><td><code>KeyvalueInputFormat</code></td><td>行前半</td><td>行后半</td><td>默认以制表符分割，可自定义</td></tr><tr><td><code>NLineInputFormat</code></td><td>字节偏移量</td><td>行内容</td><td>每个Mapper 固定收到 N 行</td></tr><tr><td><code>SequenceInputFormat</code></td><td>自定义</td><td>自定义</td><td>读取 Hadoop Sequence 文件</td></tr><tr><td><code>TextOutputFormat</code></td><td>key</td><td>value</td><td>输出结果类似 <code>KeyValueInputFormat</code> 输入格式</td></tr><tr><td><code>SequenceFileOutputFormat</code></td><td></td><td></td><td></td></tr></tbody></table><h3 id=多输入--输出>多输入 / 输出
<a class=anchor href=#%e5%a4%9a%e8%be%93%e5%85%a5--%e8%be%93%e5%87%ba>#</a></h3><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span>MultipleInputs.<span style=color:#7d9029>addInputPath</span>(<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>job,<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>aInputPath,<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>TextInputFormat.<span style=color:#7d9029>class</span>,<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>ADataMapper.<span style=color:#7d9029>class</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>);<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>MultipleInputs.<span style=color:#7d9029>addInputPath</span>(<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>job,<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>bInputPath,<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>TextInputFormat.<span style=color:#7d9029>class</span>,<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>BDataMapper.<span style=color:#7d9029>class</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>);<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>MultipleOutputs.<span style=color:#7d9029>addNamedOutput</span>(<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>job,<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#ba2121>&#34;text&#34;</span>,<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>TextOutputFormat.<span style=color:#7d9029>class</span>,<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>LongWritable.<span style=color:#7d9029>class</span>,<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>Text.<span style=color:#7d9029>class</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>);<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=combiner>Combiner
<a class=anchor href=#combiner>#</a></h3><p>Combiner 可以减少 Map Task 的磁盘 IO 与 Shuffle 的网络 IO。通常可以和 Reducer 使用同一个类。</p><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span>job.<span style=color:#7d9029>setCombinerClass</span>(IntSumReducer.<span style=color:#7d9029>class</span>);<span style=color:#bbb>
</span></span></span></code></pre></div><h3 id=partitioner>Partitioner
<a class=anchor href=#partitioner>#</a></h3><p>Partitioner 的作用是为相同的 key 分配相同的 Reducer。默认的实现是 <code>hash(key) mod R</code>，R 为 Reducer 的数量。自定义 Partitioner，需要继承 Partitioner 类并重写 <code>getPartition</code> 方法：</p><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span><span style=color:green;font-weight:700>class</span> <span style=color:#00f;font-weight:700>MyPartitioner</span><span style=color:#666>&lt;</span>K,<span style=color:#bbb> </span>V<span style=color:#666>&gt;</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>extends</span><span style=color:#bbb> </span>Partitioner<span style=color:#666>&lt;</span>K,<span style=color:#bbb> </span>V<span style=color:#666>&gt;</span><span style=color:#bbb> </span>{<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:#a2f>@Override</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>public</span><span style=color:#bbb> </span><span style=color:#b00040>int</span><span style=color:#bbb> </span><span style=color:#00f>getPartition</span>(K<span style=color:#bbb> </span>key,<span style=color:#bbb> </span>V<span style=color:#bbb> </span>value,<span style=color:#bbb> </span><span style=color:#b00040>int</span><span style=color:#bbb> </span>numPartitions)<span style=color:#bbb> </span>{<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>return</span><span style=color:#bbb> </span>key.<span style=color:#7d9029>hashCode</span>()<span style=color:#bbb> </span><span style=color:#666>%</span><span style=color:#bbb> </span>numPartitions;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>}<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>}<span style=color:#bbb>
</span></span></span></code></pre></div><p>需要注意的是，如果只有一个 Reduce Task，MR 会直接进行分配，不会执行我们自定义的 Partitioner。可以使用 <code>job.setNumReduceTasks(number);</code> 设置。</p><p>考虑一个全局排序的场景。默认的 <code>HashPartitioner</code> 不能保证 Reducer 之间的有序性，因此我们需要自定义 Partitioner。Hadoop 库中的 <code>TotalOrderPartitioner</code> 使用了前缀树来处理这个问题。</p><h2 id=yarn>YARN
<a class=anchor href=#yarn>#</a></h2><p>YARN 将原本 JobTracker 的任务划分为 ResourceManager 和 ApplicationManager 两部分，再统一到 YARN 中，将资源分配和任务调配统一起来。MapReduce 任务将直接部署到 YARN 上，资源的表示方法也从 slot 变成了直接的 RAM 和 CPU。</p><h3 id=yarn-的组成>YARN 的组成
<a class=anchor href=#yarn-%e7%9a%84%e7%bb%84%e6%88%90>#</a></h3><ul><li><p>ResourceManager 处理请求，启动 AM，监控 NM 与 AM，进行资源调度。</p></li><li><p>NodeManager 管理单个结点的资源，处理 RM 和 AM 发来的命令。</p></li><li><p>ApplicationMaster 负责单个任务的监控、调度以及向 RM 申请资源。</p></li><li><p>Container 封装运算资源</p></li></ul><p>总的来看，用户将任务提交给 ResourceManager，RM 为每个具体的应用程序在某个结点上启动一个 ApplicationMaster。这时 RM 只分配了 AM 所需的资源。AM 启动后，再根据任务的情况向 RM 请求任务执行所需的资源，并与 NodeManager 通信进行计算。计算完成后，AM 向 RM 注销，表示完成任务。</p><p>Container 的作用出现在 AM 向 RM 需求分配资源时。AM 向 RM 发送的数据包括优先级、需要的 RAM、CPU 以及是否接受跨机架等信息。当然，YARN 默认会尽量在同一个机架上完成任务。然后，RM 向 AM 返回一个 Container指示了分配到的资源所在位置等信息。也就是说，一个 Container 封装了一个节点上一定量计算资源的信息。然后，AM 将计算任务与 Container 的信息一同发送给 NodeManager 进行计算。</p><h3 id=yarn-的容错>YARN 的容错
<a class=anchor href=#yarn-%e7%9a%84%e5%ae%b9%e9%94%99>#</a></h3><p>在整个任务过程中，AM 和 NM 都要不停地发送心跳信息。如果 AM 出现问题，RM 可以直接启动另一个 AM。如果 NM 出现问题或者任务失败频率较高，则AM 可以将任务转移到其他结点。</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#hadoop-基本概念>Hadoop 基本概念</a><ul><li><a href=#hdfs>HDFS</a><ul><li><a href=#功能特性>功能特性</a></li><li><a href=#结构>结构</a><ul><li><a href=#hdfs-client>HDFS Client</a></li><li><a href=#namenode>NameNode</a></li><li><a href=#datanode>DataNode</a></li><li><a href=#secondarynamenode>SecondaryNameNode</a></li></ul></li><li><a href=#secondarynamenode-的作用>SecondaryNameNode 的作用</a></li><li><a href=#hdfs-的读写流程>HDFS 的读写流程</a></li><li><a href=#hdfs-的副本策略>HDFS 的副本策略</a></li></ul></li><li><a href=#mapreduce>MapReduce</a><ul><li><a href=#代码示例>代码示例</a></li><li><a href=#mr-内部逻辑>MR 内部逻辑</a><ul><li><a href=#map-阶段>Map 阶段</a></li><li><a href=#reduce-阶段>Reduce 阶段</a></li><li><a href=#shuffle-阶段的具体细节>Shuffle 阶段的具体细节</a></li></ul></li><li><a href=#hadoop-序列化>Hadoop 序列化</a></li></ul></li><li><a href=#mr-的可插拔pluggable组件>MR 的可插拔（pluggable）组件</a><ul><li><a href=#io-format>IO Format</a></li><li><a href=#多输入--输出>多输入 / 输出</a></li><li><a href=#combiner>Combiner</a></li><li><a href=#partitioner>Partitioner</a></li></ul></li><li><a href=#yarn>YARN</a><ul><li><a href=#yarn-的组成>YARN 的组成</a></li><li><a href=#yarn-的容错>YARN 的容错</a></li></ul></li></ul></li></ul></nav></div></aside></main></body></html>