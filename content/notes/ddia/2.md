+++
title = '2. Storage, Query, Encoding'
+++

# 数据存储与检索

## 数据结构

最基本的数据结构：线性的 k-v 对，增加/更新时直接 append，查询时搜索整个日志找到最晚的。

### 哈希索引

在上面的日志基础上，增加一个 hashmap，记录每个 key 的最晚位置。插入更新仍然是线性的，查找的速度也接近线性。需要所有 key 能够放在内存中，适合所有 key 都经常更新的情况。

为避免用尽磁盘，将日志文件切分为段。对每个已经写完的文件段，可以进行压缩合并，即仅保留其中同一个 key 最晚的记录。这个过程可以异步，不影响正在进行的读写。注意，压缩后每个 key 的 offset 会变化，所以对每个压缩后的段需要保存新的 hashmap。读数据时，从新到旧依次查找每一个 hashmap。这是 Riak 中的 BitCask 的默认做法。

1.  文件存储：使用二进制格式
2.  删除记录：使用特殊的已删除标记代替 value，进行插入
3.  崩溃恢复：可以从文件中直接还原出 hashmap，可能较慢；也可以在磁盘上保留 hashmap 的快照，减少还原时间
4.  写入时崩溃：使用校验位，确保不会认可不完整的数据
5.  并发控制：单线程追加，多线程读
6.  优点：写入快，并发和崩溃恢复简单，并发能力强
7.  缺点：哈希表需要全部放在内存，区间查询效率差（WHERE BETWEEN）

### SSTable 和 LSM-Tree

在上述基础上，对于压缩合并后的段文件，对 key 进行排序；对正在写入的文件，使用平衡二叉树。LevelDB、RocksDB、HBase、Cassandra 都是基于 SSTable。SSTable术语来自 BigTable 论文。整个方法也称 LSM-Tree（Log-Structured Merge Tree)

1.  合并段变成归并，更加高效
2.  段文件的 hashmap 可以是稀疏的，因为可以通过排序来查找，稀疏程度参考文件块，文件块可以进行通用压缩（区分于上述的取最晚操作，而是 gzip 等通用压缩）
3.  平衡二叉树变成已排序段文件（SS-Table）的效率较高（中序遍历）
4.  为防止崩溃时正在写入的文件丢失，可以双写到二叉树和日志，日志用于恢复，二叉树用于查询。
5.  当 key 完全不存在时，需要访问所有的 hashmap，可能有多次磁盘 IO；为此使用 bloomfilter 做预过滤
6.  压缩合并的方式：LevelDB 和 RocksDB 使用分层压缩，旧数据采用更高的压缩等级；HBase 使用大小分级压缩，较新的段文件较小，被合并到较旧、较大的段文件去。Cassandra 两种都支持。TODO

### B 树

关系型数据库的标准实现，思路是 1. 每个节点是一个磁盘块 2. 让树尽量平衡且矮。

B 树的可靠性保证比较复杂，因为它是直接替换磁盘上的文件，而非简单的追加的。如果是在节点分裂的过程中发生崩溃就更加危险。一般采用 WAL（Write-Ahead Log）先记录每一次 B 树的修改，再进行真正的改动。崩溃后可以从 WAL 恢复 B 树的状态。

1.  有些引擎不使用 WAL，而是用 copy-on-write 的方式更新节点。这样的缺点是，除了节点本身之外还要更新一系列指针；优点是崩溃恢复更容易，且比较容易支持并发事务。
2.  对于比较高层的节点并不需要存储完整的 key，而是给出能够描述子节点范围的部分就可以，有利于提高分叉数
3.  考虑到范围查询的需要，很多引擎尽量把相邻的节点在磁盘上相邻存储。但这一点随着数据量变大更难以保持，LSM-Tree 则比较容易（非原地归并）
4.  考虑到范围查询，可以增加兄弟节点指针
5.  一些变体，如分形树，借鉴了日志结构的思路来减少寻道

### B 树和 LSM 树对比

整体来看，LSM 树写入更快，B 树读取更快。

-   B 树的每一次写都需要至少修改 WAL 和整个页，写放大一般比 LSM 大，且随机读写较多。
-   LSM 树的数据结构更紧凑、压缩率更高，且碎片空间较少。B 树可能有很多页只存储了少量数据，造成浪费。
-   现代 SSD 可能将随机读写在内部转化为顺序读写，但写放大和碎片的问题不能被完全抹除。
-   LSM 树的后台压缩合并过程可能占用磁盘带宽，从而影响同时进行的读写操作，造成 LSM 树的高分位数读写延迟较高，而 B 树的性能比较稳定
-   LSM 树存储的数据量越大，压缩合并的成本就越高，用于实时读写的磁盘带宽就越少。
-   如果写入速度超过了压缩的速度，LSM 树的段文件就会越来越多。一般 LSM 树的数据库并不限制写入速度，因此需要额外监控。
-   B 树比较容易加锁，事务隔离可以直接实现到 B 树上。LSM 的写入有多副本，不容易隔离。

### 其他索引

上述只考虑了主键索引。除此之外，两种索引都可以用来实现二级索引。和主键索引不同，二级索引的 key 经常重复，这时可以用拉链法或在 key 上加入其他标记，然后用范围查询来实现。

#### 聚集索引

无论主键还是二级索引，索引的 key 是要查找的值，value 可以是行本身，或者指向实际行的指针，实际行位于堆文件中。堆文件可以是追加的，也可以是替换的（记录下被删除的位置，下次再填入）。这样，当存在二级索引时，就不需要复制数据。在 update 数据时，如果新值的大小不大于旧值，就可以原地替换，非常高效；如果大于旧值，就需要进行一系列移动并更新所有索引，或者直接在旧位置留下一个指向新位置的指针。

如果索引的 value 是行本身而不是指向堆文件的指针，就是聚集索引。在 InnoDB 中，主键永远是聚集索引，二级索引引用的是主键，而非直接指向堆文件。在另一些实现中，可能主键和二级索引都不是聚集的，而是把数据存在散乱的堆文件中。

也可以只在索引中保存部分列，称为覆盖索引，介于聚集索引和非聚集索引之间。如果查询的列是这些列的子集，就可以只利用索引返回结果，称索引覆盖了这个查询。例如，对于多个字段的索引，将前面的字段放在索引内，后面的字段只保存指针。

当然，聚集和覆盖索引加快了查询速度，提高了数据冗余，占用更多空间，且提高了事务的复杂性。

#### 多列索引

上面的索引都只有一个 key 对应一个 value。但如果查询包括了多个列的范围查询，就不能满足，常见的是地理数据中需要同时过滤经度和纬度。一种选择是使用空间填充曲线（Space-filling curve）将两个列转化为单个列，或者使用专门适用于空间的索引结构，如 R 树。

#### 全文搜索和模糊索引

Lucene 的做法是搜索在某个编辑距离内的文本，使用类似 SSTable 的方法，内存中的索引不再是稀疏的 key，而是一系列 DFA，类似字典树。这个自动机可以转化为 Levenshtein 自动机。

#### 在内存中保存所有内容

典型例子是 Memcached。也有在内存中实现的关系数据库。重启后也可以从磁盘中恢复状态，但运行时读取完全靠内存服务。写入磁盘一般是追加日志，除了持久化以外还方便备份、分析等。

需要注意的是，内存数据库的性能优势并不来自内存读写，因为当数据较小时，磁盘数据库也可以几乎不访问磁盘。其优势主要来自序列化的开销。

此外，内存数据库可以提供一些磁盘难以实现的功能，如 Redis 的优先队列和 Set。

内存数据库也可以反缓存到磁盘，和磁盘数据库的区别是，被保存到磁盘的单位可以是行，而非页，因此也可能有一定性能优势。

Optane 等非易失性存储（Non-volatile Memory）为内存数据库带来更多的想象空间。

## 事务处理与分析处理

事务这个名词并不等同于 ACID，它实际上指的是 OLTP 的典型行为，即少量数据的低延迟读取和写入。与之对应的是分析处理，即 OLAP。

OLAP 数据一般都是关系模型，因为 SQL 是分析的强力工具。

### 星型模式 / 维度建模 / 雪花模式

在维度建模中，通常有一个事实表加上多个维度表，每个维度表达了 5W1H 信息。日期和时间也被建立维度表，从而进行日期维度的分析，如区分假期和平日的区别。

在星型模式的每个维度表基础上再增加维度表就是雪花模式，例如产品表可以外键到另一个品牌维度表等。

## 列存

OLTP 和文档数据库中，每一行通常被相邻存放。在 OLAP 维度建模的场景下，每一个表通常非常宽，但每次只访问其中的几个列。这个模型和关系数据库相匹配，但非关系数据也可以使用，例如 Parquet 也支持文档数据存储结构。

因为相同的列被放在一起，它们的数据相似性也变高，所以压缩率也大于行存。

### 列压缩

列压缩的一个办法是，把枚举值变成 bitmap，那么当计算 `IN (a, b, c)` 的查询时，只需要按位与再和 0 比较即可。

对于有 n 个枚举值的数据，每一个单元格的数据大小就是 n 个 bit。显然，仅仅这样存储的数据中会有很多 0。此时对于每个枚举值，再使用 run-length code 压缩，从而获得很高的压缩率和查询性能。

|   | A | B | C | D |
| - | - | - | - | - |
| 0 | 1 |   |   |   |
| 1 |   |   | 1 |   |
| 2 |   |   | 1 |   |
| 3 |   |   | 1 |   |
| 4 |   | 1 |   |   |
| 5 |   |   |   | 1 |

上述数据，按照对每个枚举值从上到下 run-length code 的方式编码。因为对每个枚举值，取值只有 0 和 1，所以可以省略，只记录每一段的长度：

> A, 0, 1, 5; B, 4, 1, 1; C, 1 3 2; D, 5 1

### 内存带宽和矢量化

对大数据量的高速处理，需要考虑内存带宽、缓存命中率和 SIMD 指令的利用率。

列压缩使得数据可以被放在 L1 缓存中用循环来处理，而避免了条件跳转和函数调用；使用按位操作运算符，使得 SIMD 可以比较容易使用。

### 列存与排序

虽然数据是按列存储的，仍然需要按行排序，否则无法和主键相关联。排序的依据可以是多个列，例如把日期作为第一排序，对日期相同的可以用其他列来排序。当然，过多排序列将失去排序的作用。

排序也使得 run-length code 的压缩率更高。

另一种思路是，既然分布式数据库需要将数据备份存储，就可以在不同的副本中使用不同的排序列。当数据没有丢失时，就可以在不同的列上得到性能优势。

### 列存的写操作

OLAP 常见的是只读操作，但上面的优化都会使得写操作更加复杂。一个简单的改进办法是 LSM-Tree。

### 聚合：数据 CUBE 与物化视图

将常见的聚合操作预先计算缓存起来，即物化视图。视图是指将计算逻辑固化，物化是指其将数据缓存了起来，而不仅仅保存了逻辑。

当数据发生变化时，物化视图也需要随之更新，降低写入性能。所以总的来说是否提升性能需要考虑到实际的查询情况。

数据 CUBE 是不同维度聚合的物化视图的集合。一个简单的二维数据 CUBE 就是数据透视表。事实表一般有不止两个维度，因此数据是一个高维超立方体。

# 数据编码与演化

## 数据编码格式

通常数据同时存在于内存中和文件/网络中，需要在这两种形式间互相转化，即编解码。

### Language-Specific formats

Java 有 Serializable，Ruby 有 Marshal，Python 有 Pickle，此外还有第三方的 Kryo 等。但它们的问题是：

-   仅适用于一个语言
-   经常包含能够生成一个类的实例的功能，可能带来安全问题
-   前后兼容能力一般不好
-   性能效率通常不好

### JSON、XML、CSV 与其二进制变体

-   XML 和 CSV 无法区分数字和数字字符串，遇到浮点数边界时问题尤其明显
-   不支持二进制
-   XML 有一些 Schema 规范，但都很复杂，正确实现其解码比较困难
-   CSV 没有模式，在格式变化时的前后兼容很难实现，很多实现也没有很好处理转义

XML 和 JSON 都有一些二进制变体，如 BSON，MessagePack，其中一些扩展了其数字和二进制的能力，但都没有规定模式，因此字段名仍然需要保存在编码后的每一条数据中。

### Thrift 与 ProtoBuf

Thrift 和 ProtoBuf 的 IDL 和二进制都比较相似。共同特点是二进制数据中有字段类型、字段编号和字段长度，但没有字段名，字段名由 IDL 和基于 IDL 生成的各种语言的编解码代码确定。字段都区分 Optional 和 Required，通过字段编号来支持前后兼容和 Schema 变化。

当旧代码读取新数据时，会直接忽略新的字段。当新代码读取旧数据时，不能缺少 required 字段，但可以缺少 optional 字段。

当数据类型变化时，可能造成精度损失。

Thrift 支持列表和列表嵌套。

Protobuf 不支持列表，只能将字段标为 Repeated。如果一个字段从非 Repeated 变成了 Repeated，那么读取旧数据的新代码只能看到一个数据，读取新数据的旧代码只能看到最后一个数据。

### Avro

Avro 解决的是 Thrift 和 Protobuf 不适合 Hadoop 使用的问题，IDL 可以用 JSON 表示以方便机器读取。Avro 没有字段类型和编号的标记，完全由读写模式确定。读写模式不必完全一样，只需要互相兼容。读取数据时，同时提供读模式和写模式，用写模式将数据取出，再转换为读模式，二者之间用字段名关联，从而允许字段位置变化或增减字段。

```json
{
    "type" : "record",
    "name" : "userInfo",
    "namespace" : "my.example",
    "fields" : [{"name" : "username", 
                "type" : "string", 
                "default" : "NONE"},

                {"name" : "age", 
                "type" : "int", 
                "default" : -1},

                {"name" : "state_province", 
                "type" : "string", 
                "default" : "NONE"},

                {"name" : "country", 
                "type" : "string", 
                "default" : "NONE"},

                {"name" : "zip", 
                "type" : "string", 
                "default" : "NONE"}]
}
```

如果读模式里有某个字段，写模式中没有（即要读取的数据中没有），则要求读模式中的这个字段有默认值。可以在 schema 中指定，也可以把字段定义为 `union{null, long}` 从而用 NULL 当默认值。因此 Avro 的字段无需区分 Required 和 Optional。

总的来看：

-   如果新的 reader 增加了一个没有默认值的字段，就无法读取旧 writer 写的数据
-   如果新的 writer 删除了一个没有默认值的字段，就无用旧 reader 读这个数据
-   如果新的 writer 给 union 类型增加了分枝，就无法用旧 reader 读
-   如果新 reader 更改了字段名，可以通过 alias 解决；但如果新 writer 更改了字段名，旧 reader 并不知道新的字段名是什么，所以无法读取

可以看到，Avro 在读取数据的时候，需要额外知道 writer 使用的 schema 是什么。注意到，很多时候 schema 定义可能比一行数据本身还要大。因此，Avro 适用于：

1.  Hadoop 等场景，有数百万行 schema 相同的数据，schema 本身的大小变得不值一提，可以放在数据头部
2.  在每一行数据开头带上 writer 的版本号，reader 侧另外记录每个版本号对应的 schema。
3.  建立连接时先确定 schema，之后都用这个 schema 来传输大量文件。

Avro 同时支持代码生成和动态解析两种方式。

### 动态模式 / 模式的优点

Avro 不通过字段的编号来确定字段，而是把 schema 直接带上。这样的好处是，当数据的结构发生变化时，使用 Thrift 或 ProtoBuf 需要手动根据编号来改动 schema、再生成编解码代码、再编译，而 Avro 直接生成一个新的 schema（JSON 格式，可以比较方便地用机器生成）。并且，只要不改变字段名，就可以比较好地前后兼容。

相应地，使用代码生成再编译的方式，产生的编解码代码通常性能更好，而且可以在编译期进行检查，确保某个数据只要能够被解码，就可以正确地操作。

XML 和 JSON 有一些 schema 实现，但通常都更加复杂。例如，其中经常包括要求某个字符串字段符合某个正则表达式、要求某个整数字段在某个范围内的限制。相比之下，Thrift 这类二进制编码在这方面要简单得多。另外，数据库的 ODBC 或 JDBC Driver 经常使用自己的数据编解码格式。二进制编码的优势：

-   通常比二进制变体的 JSON 更紧凑
-   Schema 本身是有价值的文档
-   可以在部署之前检查兼容性
-   对静态类型语言+代码生成的情况，可以进行类型检查。

## 数据流格式

### 通过数据库

访问同一个数据库的不同进程可能正在运行不同版本 schema 的代码，如果已经用新 schema 写入过，旧代码再写入同一行数据，对于旧代码中不存在的字段，理想的行为是保持不变。在使用 ORM 的时候需要注意这一点。

在数据库中，数据比代码更加长久，经常可能存在数年前的数据。大部分关系数据库支持以常数代价增加一个全为空的新列，Linkedin 的文档数据库 Espresso 使用 Avro 存储并支持其演化规则。因此，虽然数据库底层可能存在各个版本的数据（例如，数年前的数据可能比现在的数据少很多个列），但从用户视角它们的模型是一样的。

归档存储时，无论数据编码是何时的形式，在归档中通常都用最新的编码。

### 通过 REST / RPC

在 SOA（Service-Oriented Architecture）或称微服务的架构下，预期每个服务可以由单独的团队维护，因此新旧版本的代码经常需要一起运行。

Web 服务不仅用于 Web：

-   客户端，浏览器，JS Web 应用程序
-   同一组织的内部调用（中间件）
-   不同组织互相调用（如支付）

REST 的基本思路是，使用 URL 来标识资源，用 HTTP 的身份认证、缓存控制、内容协商等功能，通常基于 JSON。

SOAP 是基于 XML 的协议，避免使用 HTTP 功能，而是使用 `ws-` 系列功能。因为使用 XML，所以严重依赖代码生成、IDE 等，且不同厂商的实现之间兼容性不一致。

RPC 曾有多种历史实现：Enterprise JavaBeans 和 RMI 仅限于 Java，DCOM 仅限于微软平台，CORBA 过于复杂且没有前后兼容能力。本质上，网络调用和本地调用本就存在一定的差异：

1.  本地函数是可预测的，而远程调用可能由于网络故障、远端运算速度都受影响，需要有重试、超时等机制
2.  本地函数要么返回结果、要么抛异常、要么陷入阻塞；而远程调用超时，我们无法确定远端是否收到并处理了请求，只是回复没有收到。再考虑到重试，需要提供幂等性。
3.  每次调用本地函数的时间比较稳定，远程调用则波动很大
4.  对于大对象，本地调用可以传递指针共用内存，远程调用需要编解码
5.  RPC 可以用不同语言来实现，可能带来复杂的实现，例如不同语言对大整数的处理不尽相同。

REST 其中一个吸引人之处在于，它并不试图隐藏自己是网络调用的事实。尽管如此，很多 RPC 框架仍然尝试在 REST 之上实现。

上面的例子中，Thrift 和 Avro 有 RPC 实现，ProtoBuf 有 gRPC 等。新一代的 RPC 框架一般不再试图和本地函数调用混淆，例如使用 Futures 来包装返回结果。gRPC 还支持流，一些框架还提供了服务发现。

尽管如此，因为 REST 更方便调试，常见的方式是在组织内部使用 RPC，对外 API 使用 REST。

在 RPC 的数据编码演化中，一个简化的假设是所有服务端先更新，客户端后更新。于是，请求需要向后兼容，相应需要向前兼容。对提供给外部的 API，很难强迫调用方升级，经常直接维护多个版本。标记版本可以基于 API Token+管理平台，或者在 URL 和 header 里说明。

### 通过消息队列

和直接 RPC 相比，消息队列的优势：

1.  当接收方不可用或过载，可以缓冲请求
2.  可以自动重试，避免请求丢失
3.  避免依赖固定 IP
4.  可以将一条消息发给多个接收方
5.  在逻辑上将发送方和接收方分离

相应地，消息队列一般是单向的。消费者可以把数据发送到其他队列或回复队列。消息队列本身对数据 schema 一般不会强制，可以使用任意的编解码方式。

Actor 模型原本是用于单个进程并发的模型，通过封装 Actor 和消息传递避免竞争条件、锁和死锁等问题。在分布式 Actor 中，不同的 Actor 部署在不同的节点上。无论两个 Actor 是否在同一个节点上，都采用相同的编解码方式来传递消息，模型已经假定了消息丢失的情况，无需额外考虑。不过，对 Actor 的滚动升级仍然需要考虑前后兼容性。

-   Akka 使用 Java 的内置序列化，不提供前后兼容性，但可以用 ProtoBuf 等来替代从而获得兼容
-   Orleans 同理，除了使用其他的序列化方式之外，也可以新建一个集群，将流量逐渐切换。
-   Erlang OTP 中，滚动升级很难实现。
