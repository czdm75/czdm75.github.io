#+TITLE: 5. Dynamic-Planning, Greedy

* 数据结构的扩展

在这里，数据结构的扩展指的是在原有数据结构上做出一些修改，使得其能够支持更多的特性。这些修改包括设计新的操作，以及增加可能的域。

** 动态顺序统计

为了获得一个集合里每个元素的次序，在红黑树结点的基础上增加一个域 \(size\)，用于保存以这个节点为根的子树的总结点数。即顺序统计量。定义中序遍历的顺序为这个元素的*秩*。

给定秩，寻找相应的元素。从根出发，左子树的 \(size+1\) 就是这个节点所在的位置。判断和输入的大小关系，选择子树继续寻找。

给定元素寻找秩的过程与之相反。从这个节点回溯到根，将所有的左子树 \(size+1\) 加起来，就是这个结点的秩。两种查找的复杂度均为 \(O(\log_2n)\)。

为了维护 \(size\) 域的值，在每一次插入和删除时，都需要回溯至根来修改，复杂度为 \(O(\log_2n)\)。此外，当发生旋转时，也要分别修改 \(size\)。修改的复杂度为 \(O(1)\)，所以插入和删除的复杂度不变，仍为 \(O(\log_2n)\)。

** 区间树

接下来，我们以红黑树为基础，构建一个可以保存区间对象的数据结构，以展示如何进行数据结构的扩展。

1. 基础数据结构：每个节点包含一个区间信息，并以区间的低端点作为其关键字。
2. 附加信息：每个节点额外维护一个值 \(max\)，它是以这个节点为根的子树中的所有区间端点的最大值。
3. 对信息的维护：每个结点的 \(max=\max(x.int.high, x.left.max, x.right.max)\)。于是，更新这个属性的复杂度为 \(O(\log_2n)\)
   。实际上，操作的复杂度只有 \(O(1)\)。
4. 设计新的操作：查找与指定区间相交的区间。在查找时，如果左子结点的 \(max\) 大于查找目标的左端点，说明左子树中有重叠的部分，则进入左子树继续查找。

* 动态规划

动态规划适合用来求解最优化问题。与分治法类似，通过递归地求解子问题来解决原问题。区别是，分治法可能会重复地多次解决同一个小问题，而动态规划选择将这些小问题的结果保存起来，避免重复多次地求解它们。

** 钢条切割问题

不同长度的钢条有不同的价格，求最优解。使用递归思想的算法是，长度为 \(n\) 的钢条的最优解是：

#+begin_example
CUT_ROD(prices, n)
q = 0
for i = i to n
    q = max(q, prices[i] + CUT_ROD(prices, n - i))
return q
#+end_example

将函数的每次调用作为钢条的一次切割，则最优解为所有可能的切割方法中的最大值。显然，这种方法会大量地重复计算短钢条的最优价格。每当 n 增加 1，程序所用时间差不多增加一倍。

有两种方法实现动态规划。第一种是带备忘的自顶向下法（top-down with memoization）。额外维护一个数组，记录每个子问题的解即可。另一种是自底向上法。自顶向下通常可以避免一些不需要的子问题计算，但自底向上不需要递归开销，通常具有更小的系数。两种算法的复杂度均为 \(O(n^2)\)。自底向上的算法是这样的：

#+begin_example
let r[0..n] be a new array
r[0] = 0
for j = 1 to n
    q = -1
    for i = 1 to j
        q = max(q, prices[i] + r[j - i])
    r[k] = q
return r[n]
#+end_example

除此之外，对于钢条最优解问题，还需要额外存储最优解的切割方案。

** 矩阵链乘法

由于多个矩阵相乘满足结合律，且矩阵相乘的代价和矩阵的阶相关，改变加括号的方式可能大大改变矩阵乘法的复杂度。尽量降低每一次乘法的阶数可以大大改善性能。因此，我们将矩阵链乘法问题描述为：求完全括号化方案，使得计算所需的标量乘法次数最少。暴力搜索的复杂度为 \(\Omega(2^n)\)。

与钢条问题类似，把每一次括号化作为一次递归调用。设从 \(i\) 到 \(j\) 的矩阵链的最优解为 \(m[i,j]\)，则：

\[m[i,j]=\begin{cases}0&\text{if }i=j,\\ \min_{i\leqslant k<j}\{m[i,k]+m[k+1,j]+p_{i-1}p_kp_j\}&\text{if } i<j. \end{cases}\]

于是 ，对于 \(m[i,j]\)，我们需要所有长度小于这个序列的矩阵链的最优解。对于自底向上算法，可以使用三层嵌套循环，分别代表矩阵链长度、位置和递归式中对括号化方式的的遍历操作。可以证明，递归的运行时间是 \(\Theta(n^3)\)，并需要 \(\Theta(n^2)\) 的额外空间，比暴力穷举高效得多。

** 动态规划原理

一个问题的最优解包含其子问题的最优解。比如，一个长钢条的最佳切割方案是两段钢条的最优切割方案构成的。这种性质称为*最优子结构*。具有这种性质的问题通常也适用于贪心算法。

求无权最短路径的问题是最优子结构的。这条路径必然是无环的。将路径分解成两半，那么两条路径一定分别是最优解。然而，最长简单路径问题并不符合最优子结构性质。这是因为，在最长简单路径问题中，由于简单路径不能存在环，这两个子问题实际上是相关的，而最短路径问题是无关的。实际上，最长简单路径的问题是 NP 完全的，不太可能在多项式时间内求解。

除此之外，显然，适合动态规划解决的问题还应该满足*重叠子问题*的性质。这个性质的核心是，子问题的数量应该是有限的。只有在递归过程中重复地求解同一个问题，才能体现出动态规划的优势。

另外，算法设计中还需要考虑重构最优解的问题。

** 最长公共子序列问题

注意，这个问题与最长公共子串不同：在这里，子序列可以不是连续的。这个属性更多地刻画了两个序列的相似性。

这个问题的最优子结构是这样的：设 \(X_m=\langle x_1,x_2,\cdots,x_m\rangle\) 和 \(Y_n=\langle y_1,y_2,\cdots,y_n\rangle\) 是两个序列，其最长公共子序列为 \(Z_k=\langle z_1,z_2,\cdots,z_k\rangle\)

1. 若 \(x_m=y_n\) ，则 \(z_k=x_m=y_n\) ，\(Z_k-1\) 是 \(X_{m-1}\) 和 \(Y_{n-1}\) 的最长公共子序列。
2. ​若 \(x_m\neq y_n\) ，\(z_k\neq x_m\) 意味着 \(Z\) 是 \(X_{m-1}\) 和 \(Y\) 的最长公共子序列。
3. 若 \(x_m\neq y_n\) ，\(z_k\neq y_n\) 意味着 \(Z\) 是 \(X\) 和 \(Y_{n-1}\) 的最长公共子序列。

于是，我们定义 \(c[i,j]\) 为 \(X_i\) 和 \(Y_j\) 的最大公共子序列的长度，得到递归式：

\[c[i,j]=\begin{cases}
0&\text{if $i=0$ or $j=0$}\\
c[i-1,j-1]+1&\text{if $i,j>0$ and $x_i=y_i$}\\
\max(c[i,j-1],c[i-1,j])&\text{if $i,j>0$ and $x_i\neq y_j$}
\end{cases}\]

如果递归求解这个问题，复杂度同样为指数。

使用动态规划，除了代价矩阵 \(c\) 之外，还可以另外维护一个最优解矩阵 \(b\)。\(b\) 中的元素指向算法在这一步选择的最优解。

也可以不使用 \(b\)。由于我们已经有了各个子问题的代价值和递归式，也可以根据这个位置的代价值反推选择最优解的路径。甚至，由于这个过程并不需要 \(c\) 中所有的代价值，可以进一步缩减这个操作的复杂度。

** 最优二叉树

对于已知概率的结点的查找，构建一颗二叉搜索树，使得总的访问结点树最小。这实际上就是 Huffman 树解决的问题。Huffman 编码过程属于贪心算法，如上所述，贪心算法和动态规划可以使用的范畴基本重合，动态规划也可以用于这个问题。具体实现省略。

* 贪心算法

贪心算法的基础是，不断选择当前看起来最优的解，并希望所有这些局部最优解综合起来成为全局最优解。这个性质并不一定总能保证。后面我们将讨论贪心算法的适用问题。

** 活动选择问题

有一批活动需要使用同一个资源，比如一个阶梯教室。每个活动有一定的时间区间。问题的目的是找到一个活动子集，使得所有活动兼容且集合最大。

首先从递归动态规划方向来考虑问题。有 \(n\) 个活动的集合 \(\{a_1,a_2,\cdots,aa_n\}\)，并已经按照结束时间排序好。设 \(c[i,j]\) 是最优解的大小，\(S_{ij}\) 是所有在 \(a_i\) 活动结束后开始，在 \(a_j\) 活动开始前结束的活动的集合，即所有这两个活动之间的活动的集合，则：

\[c[i,j]=\begin{cases}
0&\text{if }S_{ij}=\emptyset\\
\max_{a_k\in S_{ij}}\{c[i,k]+c[k,j]+1\}&\text{if }S_ij\neq\emptyset}
\end{cases}\]

这时我们就可以设计动态规划算法。不过，在选择最优解的过程中，直觉告诉我们，选择最先结束的活动，即 \(a_1\) 可能就是最好的选择。这样，就只剩下一个子问题需要解决，而不需要遍历各种子问题。这个选择可以被证明是最优的。于是，我们可以使用递归算法来解决这个问题，也很容易将其转化为迭代形式，变成不断加入最早结束的兼容活动的算法。

** 背包问题

0-1 背包问题这样定义：每种商品有不同的重量和价格，希望得到在限定重量下商品的最大价值。另一种变体是分数背包问题。在这里，物品不再是整数，而是可以任意分割携带。两个问题都具有最优子结构性质，但分数背包问题可以用贪心策略来完成，0-1
背包问题只能用普通的动态规划来完成。

分数背包问题的答案比较明显，根据贪心策略，只需要尽量往背包里装满平均价值最高的商品就可以了。但在 0-1 背包问题中，由于背包可能无法装满，相当于影响了商品的单位价值。因此，这个问题不适用于贪心策略。

* 摊还分析

在摊还分析中，我们求一个操作序列中所有操作的平均时间，来评价操作的代价。摊还分析并不涉及概率。我们将介绍三种摊还分析的方法：

- 聚合分析，确定一个 \(n\) 个操作的序列的总代价的上界 \(T(n)\)，则每个操作的摊还代价为 \(T(n)/n\)。
- 核算法，用来分别分析每个操作各自的摊还代价。核算法将序列中较早的操作的 “余额” 与数据结构中的特定对象相关联，在序列中随后的部分，用来为那些缴费少于书记代价的操作支付差额。
- 势能法，同样用于分析各个操作的摊还代价。与核算法的区别是，将 “势能” 作为一个整体储存起来，而不与单个对象关联分开储存。

** 聚合分析

以一个栈为例。我们为栈新定义一种操作 MUILTIPOP，弹出指定数量的元素。如果超过栈内存储的元素的量，就停止弹出而不报错。于是，对于一个长度为 \(n\) 的操作序列，原来的入栈和出栈操作的代价均为 \(O(1)\)，而新的多重出栈的最坏情况代价为 \(O(n)\)。对于整个序列，最坏情况看起来应当为 \(O(n^2)\) ，即所有操作都是参数为 \(n\) 的多重出栈操作，然而，这并不是一个确界。

下面我们利用聚合分析。虽然多重出栈的代价可能很高，但是对于一个初始为空的栈，可以执行的出栈次数最多与入栈次数相同，无论是不是多重出栈。因此，整个操作序列的最坏运行时间事实上是 \(O(n)\) ，所以三种栈操作的摊还代价都是 \(O(1)\)。

类似地，考虑一个二进制计数器。每次计数器加一时需要反转的位数是不同的。01 变成 10 需要改变 2 位，011 变成 100 需要反转 3 位。以自增操作的数量为 \(n\)，需要反转次数似乎正在随着计数器内值的大小而增长。然而实际上需要反转大量的位的情况是少见的，而且越是高位，需要反转的情况就越少见。对一个从 0 开始的计数器，需要进行的反转次数的总数为：

\[\sum_{i=0}^{k-1}\lfloor\frac n{2^i}\rfloor<n\sum_{i=0}^\infty\frac1{2^i}=2n\]

因此，最坏情况时间为 \(O(n)\) ，摊还代价为 \(O(1)\)。

如果加入多重入栈操作，就可以压入任意多的数字。或者对计数器加入自减操作，使计数器内的值有可能在需要大量改变位数的位置颠簸，如 7-8 之间，显然，复杂度又会升高到原来的水平。

** 核算法

对不同操作赋予不同的费用，称为他们的摊还代价。当摊还代价超过实际代价时，将差额存入数据结构中的特定对象，称为信用。对于后续摊还代价小于实际代价的情况，可以用信用来支付差额。

回顾前面的栈问题。可以认为，PUSH 操作的实际代价为 1 ，POP 的代价为 1，MULTIPOP 的代价是 \(\min(k,s)\) ，\(k\) 是参数，\(s\) 是栈内元素的数量。然后，我们为这些操作分别赋予摊还代价，PUSH 为 2， POP 和 MULTIPOP 为 0 。显然，PUSH 为后来的两种 POP 操作预存了代价费用。于是，长度为 \(n\) 的操作序列的总代价为 \(O(n)\)。

** 势能法

令 \(c_i\) 为第 \(i\) 个操作的实际代价，\(D_i\) 为执行第 \(i\) 个操作后得到的结果数据结构，则第 \(i\) 个操作的摊还代价 \(\hat{c_i}\) 用势函数 \(\Phi\) 定义为：

\[\hat{c_i}=c_i+\Phi(D_i)-\Phi(D_{i-1})\]

例如，对于之前的栈操作，以栈内元素的数量为势函数。于是，PUSH 操作的摊还代价为 2 ，另外两种为 0 ，结论与上一种方法相同。

又如，对于之前的二进制计数器，将计数器内 1 的个数作为势能。同样可以得出，\(n\) 个操作的最坏时间情况为 \(O(n)\)。

** 表的扩张和收缩

摊还分析适合于这一类操作：一个长度可以动态变化的线性表，如 Java 中的 ArrayList。当数组空间不足以存储所有的元素时，需要重新分配一个数组，并将目前所有的元素移动到新的数组里。虽然每一次操作的代价是不同的，将势函数定义为：

\[\Phi(T)=2T.num-T.size\]

这样定义的目的是，让每一次扩张之后，数据结构的势能为 0。如果每个元素插入、删除和移动的代价都是 1 ，那么插入操作的摊还代价为 3。也就是说，整个长度为 \(n\) 的操作序列的代价为 \(O(n)\)。

涉及到收缩的情况比较复杂。如果我们让表的容量达到 1/2 时立刻收缩，那么在特定值附近的颠簸将会使表不停地扩张和收缩，带来大量的复制和内存分配，将每个操作的代价拉回到 \(O(n)\)。所以，我们规定容量达到 1/4 时才发生收缩，使表的*装载因子*变回 1/2 。这时，就需要这样定义势能：

\[\Phi(T)=\begin{cases} 2T.num-T.size&\text{if }\alpha\geqslant\frac12\\ T.size/2-T.num&\text{if }\alpha<\frac12 \end{cases}\]

这样，就相当于分别定义了收缩情况的势能和扩张情况的势能。摊还代价收缩回 3 ，整个操作序列的代价回到 \(O(n)\)。
